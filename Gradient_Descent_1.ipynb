{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejrtks1020/Deep_Learning/blob/main/Gradient_Descent_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "21wLhYTd_Z3Z"
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IrUKyarI_Z3d"
      },
      "cell_type": "markdown",
      "source": [
        "### 보스턴 주택 가격 데이터 세트를 Peceptron 기반에서 학습 및 테스트하기 위한 데이터 로드\n",
        "* 사이킷런에서 보스턴 주택 가격 데이터 세트를 로드하고 이를 DataFrame으로 생성"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "id": "KKzepsH6_Z3e",
        "outputId": "3f599e40-b339-4e4e-e78f-40bbc2cac8c8"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "boston = load_boston()\n",
        "bostonDF = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "bostonDF['PRICE'] = boston.target\n",
        "print(bostonDF.shape)\n",
        "bostonDF.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(506, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f136c9f5-c0d9-4cfc-87db-aa2a24702987\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f136c9f5-c0d9-4cfc-87db-aa2a24702987')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f136c9f5-c0d9-4cfc-87db-aa2a24702987 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f136c9f5-c0d9-4cfc-87db-aa2a24702987');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  PRICE\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98   24.0\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14   21.6\n",
              "2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03   34.7\n",
              "3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94   33.4\n",
              "4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33   36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "gls0qBzy_Z3f"
      },
      "cell_type": "markdown",
      "source": [
        "### Weight와 Bias의 Update 값을 계산하는 함수 생성.\n",
        "* w1은 RM(방의 계수) 피처의 Weight 값\n",
        "* w2는 LSTAT(하위계층 비율) 피처의 Weight 값\n",
        "* bias는 Bias\n",
        "* N은 입력 데이터 건수\n",
        "![](https://raw.githubusercontent.com/chulminkw/CNN_PG/main/utils/images/Weight_update.png)\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4eemjo1g_Z3g"
      },
      "cell_type": "code",
      "source": [
        "# gradient_descent()함수에서 반복적으로 호출되면서 update될 weight/bias 값을 계산하는 함수. \n",
        "# rm은 RM(방 개수), lstat(하위계층 비율), target은 PRICE임. 전체 array가 다 입력됨. \n",
        "# 반환 값은 weight와 bias가 update되어야 할 값과 Mean Squared Error 값을 loss로 반환.\n",
        "def get_update_weights_value(bias, w1, w2, rm, lstat, target, learning_rate=0.01):\n",
        "    \n",
        "    # 데이터 건수\n",
        "    N = len(target)\n",
        "    # 예측 값. \n",
        "    predicted = w1 * rm + w2*lstat + bias\n",
        "    # 실제값과 예측값의 차이 \n",
        "    diff = target - predicted\n",
        "    # bias 를 array 기반으로 구하기 위해서 설정. \n",
        "    bias_factors = np.ones((N,))\n",
        "    \n",
        "    # weight와 bias를 얼마나 update할 것인지를 계산.  \n",
        "    w1_update = -(2/N)*learning_rate*(np.dot(rm.T, diff))\n",
        "    w2_update = -(2/N)*learning_rate*(np.dot(lstat.T, diff))\n",
        "    bias_update = -(2/N)*learning_rate*(np.dot(bias_factors.T, diff))\n",
        "    \n",
        "    # Mean Squared Error값을 계산. \n",
        "    mse_loss = np.mean(np.square(diff))\n",
        "    \n",
        "    # weight와 bias가 update되어야 할 값과 Mean Squared Error 값을 반환. \n",
        "    return bias_update, w1_update, w2_update, mse_loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8KokfrG_Z3h"
      },
      "cell_type": "markdown",
      "source": [
        "### Gradient Descent 를 적용하는 함수 생성\n",
        "* iter_epochs 수만큼 반복적으로 get_update_weights_value()를 호출하여 update될 weight/bias값을 구한 뒤 Weight/Bias를 Update적용. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TsxcLW-7_Z3h"
      },
      "cell_type": "code",
      "source": [
        "# RM, LSTAT feature array와 PRICE target array를 입력 받아서 iter_epochs수만큼 반복적으로 Weight와 Bias를 update적용. \n",
        "def gradient_descent(features, target, iter_epochs=1000, verbose=True):\n",
        "    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n",
        "    # bias도 1차원 array로 변환하되 초기 값은 1로 설정. \n",
        "    w1 = np.zeros((1,))\n",
        "    w2 = np.zeros((1,))\n",
        "    bias = np.zeros((1, ))\n",
        "    print('최초 w1, w2, bias:', w1, w2, bias)\n",
        "    \n",
        "    # learning_rate와 RM, LSTAT 피처 지정. 호출 시 numpy array형태로 RM과 LSTAT으로 된 2차원 feature가 입력됨.\n",
        "    learning_rate = 0.01\n",
        "    rm = features[:, 0]\n",
        "    lstat = features[:, 1]\n",
        "    \n",
        "    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행. \n",
        "    for i in range(iter_epochs):\n",
        "        # weight/bias update 값 계산 \n",
        "        bias_update, w1_update, w2_update, loss = get_update_weights_value(bias, w1, w2, rm, lstat, target, learning_rate)\n",
        "        # weight/bias의 update 적용. \n",
        "        w1 = w1 - w1_update\n",
        "        w2 = w2 - w2_update\n",
        "        bias = bias - bias_update\n",
        "        if verbose:\n",
        "          if i % 100 == 0:\n",
        "            print('Epoch:', i+1,'/', iter_epochs)\n",
        "            print('w1:', w1, 'w2:', w2, 'bias:', bias, 'loss:', loss)\n",
        "        \n",
        "    return w1, w2, bias"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ao1MINVk_Z3j"
      },
      "cell_type": "markdown",
      "source": [
        "### Gradient Descent 적용\n",
        "* 신경망은 데이터를 정규화/표준화 작업을 미리 선행해 주어야 함. \n",
        "* 이를 위해 사이킷런의 MinMaxScaler를 이용하여 개별 feature값은 0~1사이 값으로 변환후 학습 적용."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lTpg94Im_Z3j"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(bostonDF[['RM', 'LSTAT']])\n",
        "\n",
        "w1, w2, bias = gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=5000, verbose=True)\n",
        "print('##### 최종 w1, w2, bias #######')\n",
        "print(w1, w2, bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ns7fuP9n_Z3k"
      },
      "cell_type": "markdown",
      "source": [
        "### 계산된 Weight와 Bias를 이용하여 Price 예측\n",
        "* 예측 feature 역시 0~1사이의 scaled값을 이용하고 Weight와 bias를 적용하여 예측값 계산. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "j726aOPd_Z3l",
        "outputId": "7d4cd424-3e4f-49fc-d6e2-6cc4202e0b48"
      },
      "cell_type": "code",
      "source": [
        "predicted = scaled_features[:, 0]*w1 + scaled_features[:, 1]*w2 + bias\n",
        "bostonDF['PREDICTED_PRICE'] = predicted\n",
        "bostonDF.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-57ad23f8-7750-4937-b67c-8d7c442967e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "      <th>PREDICTED_PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>28.935533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>25.483093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>32.545474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>32.334142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>31.516284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.430</td>\n",
              "      <td>58.7</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.12</td>\n",
              "      <td>5.21</td>\n",
              "      <td>28.7</td>\n",
              "      <td>28.074722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.08829</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.012</td>\n",
              "      <td>66.6</td>\n",
              "      <td>5.5605</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>395.60</td>\n",
              "      <td>12.43</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.342942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.14455</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.172</td>\n",
              "      <td>96.1</td>\n",
              "      <td>5.9505</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>19.15</td>\n",
              "      <td>27.1</td>\n",
              "      <td>17.772340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.21124</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>5.631</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0821</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.63</td>\n",
              "      <td>29.93</td>\n",
              "      <td>16.5</td>\n",
              "      <td>8.129206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.17004</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.004</td>\n",
              "      <td>85.9</td>\n",
              "      <td>6.5921</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.71</td>\n",
              "      <td>17.10</td>\n",
              "      <td>18.9</td>\n",
              "      <td>18.276548</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57ad23f8-7750-4937-b67c-8d7c442967e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57ad23f8-7750-4937-b67c-8d7c442967e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57ad23f8-7750-4937-b67c-8d7c442967e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS  ...       B  LSTAT  PRICE  PREDICTED_PRICE\n",
              "0  0.00632  18.0   2.31   0.0  ...  396.90   4.98   24.0        28.935533\n",
              "1  0.02731   0.0   7.07   0.0  ...  396.90   9.14   21.6        25.483093\n",
              "2  0.02729   0.0   7.07   0.0  ...  392.83   4.03   34.7        32.545474\n",
              "3  0.03237   0.0   2.18   0.0  ...  394.63   2.94   33.4        32.334142\n",
              "4  0.06905   0.0   2.18   0.0  ...  396.90   5.33   36.2        31.516284\n",
              "5  0.02985   0.0   2.18   0.0  ...  394.12   5.21   28.7        28.074722\n",
              "6  0.08829  12.5   7.87   0.0  ...  395.60  12.43   22.9        21.342942\n",
              "7  0.14455  12.5   7.87   0.0  ...  396.90  19.15   27.1        17.772340\n",
              "8  0.21124  12.5   7.87   0.0  ...  386.63  29.93   16.5         8.129206\n",
              "9  0.17004  12.5   7.87   0.0  ...  386.71  17.10   18.9        18.276548\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "n6vWf8N3_Z3l"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras를 이용하여 보스턴 주택가격 모델 학습 및 예측\n",
        "* Dense Layer를 이용하여 퍼셉트론 구현. units는 1로 설정. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3ZGALxVa_Z3l"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    # 단 하나의 units 설정. input_shape는 2차원, 회귀이므로 activation은 설정하지 않음. \n",
        "    # weight와 bias 초기화는 kernel_inbitializer와 bias_initializer를 이용. \n",
        "    Dense(1, input_shape=(2, ), activation=None, kernel_initializer='zeros', bias_initializer='ones')\n",
        "])\n",
        "# Adam optimizer를 이용하고 Loss 함수는 Mean Squared Error, 성능 측정 역시 MSE를 이용하여 학습 수행. \n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mse'])\n",
        "model.fit(scaled_features, bostonDF['PRICE'].values, epochs=1000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MWYOhF1A_Z3m"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras로 학습된 모델을 이용하여 주택 가격 예측 수행. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "7Yu3Zfk9_Z3m",
        "outputId": "d96dee82-7b92-44f4-d051-4dd851288db8"
      },
      "cell_type": "code",
      "source": [
        "predicted = model.predict(scaled_features)\n",
        "bostonDF['KERAS_PREDICTED_PRICE'] = predicted\n",
        "bostonDF.head(10)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cd7e62d3-783a-4b13-b0ec-15cc5e54bfc1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "      <th>PREDICTED_PRICE</th>\n",
              "      <th>KERAS_PREDICTED_PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>28.935533</td>\n",
              "      <td>28.981525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>25.483093</td>\n",
              "      <td>25.506231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>32.545474</td>\n",
              "      <td>32.637917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>32.334142</td>\n",
              "      <td>32.416267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>31.516284</td>\n",
              "      <td>31.602312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.430</td>\n",
              "      <td>58.7</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.12</td>\n",
              "      <td>5.21</td>\n",
              "      <td>28.7</td>\n",
              "      <td>28.074722</td>\n",
              "      <td>28.109661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.08829</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.012</td>\n",
              "      <td>66.6</td>\n",
              "      <td>5.5605</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>395.60</td>\n",
              "      <td>12.43</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.342942</td>\n",
              "      <td>21.327406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.14455</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.172</td>\n",
              "      <td>96.1</td>\n",
              "      <td>5.9505</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>19.15</td>\n",
              "      <td>27.1</td>\n",
              "      <td>17.772340</td>\n",
              "      <td>17.749207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.21124</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>5.631</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0821</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.63</td>\n",
              "      <td>29.93</td>\n",
              "      <td>16.5</td>\n",
              "      <td>8.129206</td>\n",
              "      <td>8.036671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.17004</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.004</td>\n",
              "      <td>85.9</td>\n",
              "      <td>6.5921</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.71</td>\n",
              "      <td>17.10</td>\n",
              "      <td>18.9</td>\n",
              "      <td>18.276548</td>\n",
              "      <td>18.247183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd7e62d3-783a-4b13-b0ec-15cc5e54bfc1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd7e62d3-783a-4b13-b0ec-15cc5e54bfc1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd7e62d3-783a-4b13-b0ec-15cc5e54bfc1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  ...  PRICE  PREDICTED_PRICE  KERAS_PREDICTED_PRICE\n",
              "0  0.00632  18.0   2.31  ...   24.0        28.935533              28.981525\n",
              "1  0.02731   0.0   7.07  ...   21.6        25.483093              25.506231\n",
              "2  0.02729   0.0   7.07  ...   34.7        32.545474              32.637917\n",
              "3  0.03237   0.0   2.18  ...   33.4        32.334142              32.416267\n",
              "4  0.06905   0.0   2.18  ...   36.2        31.516284              31.602312\n",
              "5  0.02985   0.0   2.18  ...   28.7        28.074722              28.109661\n",
              "6  0.08829  12.5   7.87  ...   22.9        21.342942              21.327406\n",
              "7  0.14455  12.5   7.87  ...   27.1        17.772340              17.749207\n",
              "8  0.21124  12.5   7.87  ...   16.5         8.129206               8.036671\n",
              "9  0.17004  12.5   7.87  ...   18.9        18.276548              18.247183\n",
              "\n",
              "[10 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "lwnkLwyH_Z3n"
      },
      "cell_type": "markdown",
      "source": [
        "### Stochastic Gradient Descent와 Mini Batch Gradient Descent 구현\n",
        "* SGD 는 전체 데이터에서 한건만 임의로 선택하여 Gradient Descent 로 Weight/Bias Update 계산한 뒤 Weight/Bias 적용\n",
        "* Mini Batch GD는 전체 데이터에서 Batch 건수만큼 데이터를 선택하여 Gradient Descent로 Weight/Bias Update 계산한 뒤 Weight/Bias 적용"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xF95oRDV_Z3n"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "boston = load_boston()\n",
        "bostonDF = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "bostonDF['PRICE'] = boston.target\n",
        "print(bostonDF.shape)\n",
        "bostonDF.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AS8Co_Da_Z3n"
      },
      "cell_type": "markdown",
      "source": [
        "### SGD 기반으로 Weight/Bias update 값 구하기"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pZ2Ve5UD_Z3n"
      },
      "cell_type": "code",
      "source": [
        "def get_update_weights_value_sgd(bias, w1, w2, rm_sgd, lstat_sgd, target_sgd, learning_rate=0.01):\n",
        "    \n",
        "    # 데이터 건수\n",
        "    N = target_sgd.shape[0]\n",
        "    # 예측 값. \n",
        "    predicted_sgd = w1 * rm_sgd + w2*lstat_sgd + bias\n",
        "    # 실제값과 예측값의 차이 \n",
        "    diff_sgd = target_sgd - predicted_sgd\n",
        "    # bias 를 array 기반으로 구하기 위해서 설정. \n",
        "    bias_factors = np.ones((N,))\n",
        "    \n",
        "    # weight와 bias를 얼마나 update할 것인지를 계산.  \n",
        "    w1_update = -(2/N)*learning_rate*(np.dot(rm_sgd.T, diff_sgd))\n",
        "    w2_update = -(2/N)*learning_rate*(np.dot(lstat_sgd.T, diff_sgd))\n",
        "    bias_update = -(2/N)*learning_rate*(np.dot(bias_factors.T, diff_sgd))\n",
        "    \n",
        "    # Mean Squared Error값을 계산. \n",
        "    #mse_loss = np.mean(np.square(diff))\n",
        "    \n",
        "    # weight와 bias가 update되어야 할 값 반환 \n",
        "    return bias_update, w1_update, w2_update"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOWy4u73_Z3o"
      },
      "cell_type": "markdown",
      "source": [
        "### SGD 수행하기"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "a9uKVthL_Z3o"
      },
      "cell_type": "code",
      "source": [
        "print(bostonDF['PRICE'].values.shape)\n",
        "print(np.random.choice(bostonDF['PRICE'].values.shape[0], 1))\n",
        "print(np.random.choice(506, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pluVa46Z_Z3o"
      },
      "cell_type": "code",
      "source": [
        "# RM, LSTAT feature array와 PRICE target array를 입력 받아서 iter_epochs수만큼 반복적으로 Weight와 Bias를 update적용. \n",
        "def st_gradient_descent(features, target, iter_epochs=1000, verbose=True):\n",
        "    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n",
        "    # bias도 1차원 array로 변환하되 초기 값은 1로 설정. \n",
        "    np.random.seed = 2021\n",
        "    w1 = np.zeros((1,))\n",
        "    w2 = np.zeros((1,))\n",
        "    bias = np.zeros((1, ))\n",
        "    print('최초 w1, w2, bias:', w1, w2, bias)\n",
        "    \n",
        "    # learning_rate와 RM, LSTAT 피처 지정. 호출 시 numpy array형태로 RM과 LSTAT으로 된 2차원 feature가 입력됨.\n",
        "    learning_rate = 0.01\n",
        "    rm = features[:, 0]\n",
        "    lstat = features[:, 1]\n",
        "    \n",
        "    \n",
        "    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행. \n",
        "    for i in range(iter_epochs):\n",
        "        # iteration 시마다 stochastic gradient descent 를 수행할 데이터를 한개만 추출. 추출할 데이터의 인덱스를 random.choice() 로 선택. \n",
        "        stochastic_index = np.random.choice(target.shape[0], 1)\n",
        "        rm_sgd = rm[stochastic_index]\n",
        "        lstat_sgd = lstat[stochastic_index]\n",
        "        target_sgd = target[stochastic_index]\n",
        "        # SGD 기반으로 Weight/Bias의 Update를 구함.  \n",
        "        bias_update, w1_update, w2_update = get_update_weights_value_sgd(bias, w1, w2, rm_sgd, lstat_sgd, target_sgd, learning_rate)\n",
        "        \n",
        "        # SGD로 구한 weight/bias의 update 적용. \n",
        "        w1 = w1 - w1_update\n",
        "        w2 = w2 - w2_update\n",
        "        bias = bias - bias_update\n",
        "        if verbose:\n",
        "            print('Epoch:', i+1,'/', iter_epochs)\n",
        "            # Loss는 전체 학습 데이터 기반으로 구해야 함.\n",
        "            predicted = w1 * rm + w2*lstat + bias\n",
        "            diff = target - predicted\n",
        "            mse_loss = np.mean(np.square(diff))\n",
        "            print('w1:', w1, 'w2:', w2, 'bias:', bias, 'loss:', mse_loss)\n",
        "        \n",
        "    return w1, w2, bias"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "84ExrXFp_Z3o"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(bostonDF[['RM', 'LSTAT']])\n",
        "\n",
        "w1, w2, bias = st_gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=1000, verbose=True)\n",
        "print('##### 최종 w1, w2, bias #######')\n",
        "print(w1, w2, bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fcZ8nAEU_Z3p"
      },
      "cell_type": "code",
      "source": [
        "predicted = scaled_features[:, 0]*w1 + scaled_features[:, 1]*w2 + bias\n",
        "bostonDF['PREDICTED_PRICE_SGD'] = predicted\n",
        "bostonDF.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tqo2qmRv_Z3p"
      },
      "cell_type": "markdown",
      "source": [
        "### iteration시마다 일정한 batch 크기만큼의 데이터를 random하게 가져와서 GD를 수행하는 Mini-Batch GD 수행"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hRpJFPXj_Z3p"
      },
      "cell_type": "code",
      "source": [
        "def get_update_weights_value_batch(bias, w1, w2, rm_batch, lstat_batch, target_batch, learning_rate=0.01):\n",
        "    \n",
        "    # 데이터 건수\n",
        "    N = target_batch.shape[0]\n",
        "    # 예측 값. \n",
        "    predicted_batch = w1 * rm_batch+ w2 * lstat_batch + bias\n",
        "    # 실제값과 예측값의 차이 \n",
        "    diff_batch = target_batch - predicted_batch\n",
        "    # bias 를 array 기반으로 구하기 위해서 설정. \n",
        "    bias_factors = np.ones((N,))\n",
        "    \n",
        "    # weight와 bias를 얼마나 update할 것인지를 계산.  \n",
        "    w1_update = -(2/N)*learning_rate*(np.dot(rm_batch.T, diff_batch))\n",
        "    w2_update = -(2/N)*learning_rate*(np.dot(lstat_batch.T, diff_batch))\n",
        "    bias_update = -(2/N)*learning_rate*(np.dot(bias_factors.T, diff_batch))\n",
        "    \n",
        "    # Mean Squared Error값을 계산. \n",
        "    #mse_loss = np.mean(np.square(diff))\n",
        "    \n",
        "    # weight와 bias가 update되어야 할 값 반환 \n",
        "    return bias_update, w1_update, w2_update"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7qBxcKT_Z3p",
        "outputId": "0fd25e60-84b0-4c84-c041-a2a5a3cff36d"
      },
      "cell_type": "code",
      "source": [
        "batch_indexes = np.random.choice(506, 30)\n",
        "print(batch_indexes)\n",
        "\n",
        "bostonDF['RM'].values[batch_indexes]\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[476 261 465  14 100 154 356 500 468 337 427 313  72 340 400 434 188  33\n",
            " 393 337 218 177 193 218 364  36 368  51  63 318]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.484, 7.52 , 5.759, 6.096, 6.727, 6.129, 6.212, 6.027, 5.926,\n",
              "       5.895, 6.202, 6.266, 6.065, 5.968, 5.987, 6.208, 6.556, 5.701,\n",
              "       6.193, 5.895, 5.951, 6.315, 6.8  , 5.951, 8.78 , 5.841, 4.97 ,\n",
              "       6.115, 6.762, 6.382])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Auk8B2j0_Z3q"
      },
      "cell_type": "code",
      "source": [
        "# batch_gradient_descent()는 인자로 batch_size(배치 크기)를 입력 받음. \n",
        "def batch_random_gradient_descent(features, target, iter_epochs=1000, batch_size=30, verbose=True):\n",
        "    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n",
        "    # bias도 1차원 array로 변환하되 초기 값은 1로 설정. \n",
        "    np.random.seed = 2021\n",
        "    w1 = np.zeros((1,))\n",
        "    w2 = np.zeros((1,))\n",
        "    bias = np.zeros((1, ))\n",
        "    print('최초 w1, w2, bias:', w1, w2, bias)\n",
        "    \n",
        "    # learning_rate와 RM, LSTAT 피처 지정. 호출 시 numpy array형태로 RM과 LSTAT으로 된 2차원 feature가 입력됨.\n",
        "    learning_rate = 0.01\n",
        "    rm = features[:, 0]\n",
        "    lstat = features[:, 1]\n",
        "    \n",
        "    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행. \n",
        "    for i in range(iter_epochs):\n",
        "        # batch_size 갯수만큼 데이터를 임의로 선택. \n",
        "        batch_indexes = np.random.choice(target.shape[0], batch_size)\n",
        "        rm_batch = rm[batch_indexes]\n",
        "        lstat_batch = lstat[batch_indexes]\n",
        "        target_batch = target[batch_indexes]\n",
        "        # Batch GD 기반으로 Weight/Bias의 Update를 구함. \n",
        "        bias_update, w1_update, w2_update = get_update_weights_value_batch(bias, w1, w2, rm_batch, lstat_batch, target_batch, learning_rate)\n",
        "        \n",
        "        # Batch GD로 구한 weight/bias의 update 적용. \n",
        "        w1 = w1 - w1_update\n",
        "        w2 = w2 - w2_update\n",
        "        bias = bias - bias_update\n",
        "        if verbose:\n",
        "            print('Epoch:', i+1,'/', iter_epochs)\n",
        "            # Loss는 전체 학습 데이터 기반으로 구해야 함.\n",
        "            predicted = w1 * rm + w2*lstat + bias\n",
        "            diff = target - predicted\n",
        "            mse_loss = np.mean(np.square(diff))\n",
        "            print('w1:', w1, 'w2:', w2, 'bias:', bias, 'loss:', mse_loss)\n",
        "        \n",
        "    return w1, w2, bias"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbuKQCHK_Z3q",
        "outputId": "d9fb3435-9081-4602-d382-5cff3ad83214"
      },
      "cell_type": "code",
      "source": [
        "w1, w2, bias = batch_random_gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=5000, batch_size=30, verbose=True)\n",
        "print('##### 최종 w1, w2, bias #######')\n",
        "print(w1, w2, bias)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch: 2502 / 5000\n",
            "w1: [23.96818387] w2: [-21.12219357] bias: [16.5618128] loss: 31.030016832023286\n",
            "Epoch: 2503 / 5000\n",
            "w1: [23.95947495] w2: [-21.13196494] bias: [16.54006685] loss: 31.019855035134473\n",
            "Epoch: 2504 / 5000\n",
            "w1: [23.98005828] w2: [-21.1317659] bias: [16.56340802] loss: 31.027352952814635\n",
            "Epoch: 2505 / 5000\n",
            "w1: [23.98477612] w2: [-21.12525791] bias: [16.57525409] loss: 31.034197786665704\n",
            "Epoch: 2506 / 5000\n",
            "w1: [23.98412871] w2: [-21.11933309] bias: [16.57749535] loss: 31.037226624806387\n",
            "Epoch: 2507 / 5000\n",
            "w1: [23.99014382] w2: [-21.12226154] bias: [16.57864404] loss: 31.036845166532608\n",
            "Epoch: 2508 / 5000\n",
            "w1: [23.99353229] w2: [-21.11681779] bias: [16.58632334] loss: 31.04219823441015\n",
            "Epoch: 2509 / 5000\n",
            "w1: [23.98374667] w2: [-21.13348445] bias: [16.56166421] loss: 31.026197795216355\n",
            "Epoch: 2510 / 5000\n",
            "w1: [23.99444984] w2: [-21.13867932] bias: [16.56733942] loss: 31.0266386319136\n",
            "Epoch: 2511 / 5000\n",
            "w1: [23.98350119] w2: [-21.14740111] bias: [16.54897728] loss: 31.01707456790012\n",
            "Epoch: 2512 / 5000\n",
            "w1: [23.98051446] w2: [-21.15740633] bias: [16.53434872] loss: 31.00935098433618\n",
            "Epoch: 2513 / 5000\n",
            "w1: [23.96324043] w2: [-21.16636352] bias: [16.50205088] loss: 30.999628050792147\n",
            "Epoch: 2514 / 5000\n",
            "w1: [23.9754659] w2: [-21.16912242] bias: [16.50688949] loss: 30.99902904166117\n",
            "Epoch: 2515 / 5000\n",
            "w1: [23.96713108] w2: [-21.18982843] bias: [16.49407159] loss: 30.990861223166615\n",
            "Epoch: 2516 / 5000\n",
            "w1: [23.96752708] w2: [-21.19240022] bias: [16.48705159] loss: 30.988972010135992\n",
            "Epoch: 2517 / 5000\n",
            "w1: [23.97099524] w2: [-21.19259582] bias: [16.4901182] loss: 30.989101477953334\n",
            "Epoch: 2518 / 5000\n",
            "w1: [23.95915786] w2: [-21.19933573] bias: [16.46540954] loss: 30.9852205965458\n",
            "Epoch: 2519 / 5000\n",
            "w1: [23.97476569] w2: [-21.1933749] bias: [16.49160539] loss: 30.988818329169366\n",
            "Epoch: 2520 / 5000\n",
            "w1: [23.95218215] w2: [-21.20514665] bias: [16.45430172] loss: 30.983662001653126\n",
            "Epoch: 2521 / 5000\n",
            "w1: [23.95290331] w2: [-21.20471133] bias: [16.45102485] loss: 30.98349352720081\n",
            "Epoch: 2522 / 5000\n",
            "w1: [23.95754947] w2: [-21.20692499] bias: [16.45470093] loss: 30.982517553660735\n",
            "Epoch: 2523 / 5000\n",
            "w1: [23.96914629] w2: [-21.21394064] bias: [16.46124836] loss: 30.979706688652048\n",
            "Epoch: 2524 / 5000\n",
            "w1: [23.9742156] w2: [-21.21265343] bias: [16.46740306] loss: 30.980078694899415\n",
            "Epoch: 2525 / 5000\n",
            "w1: [23.96988132] w2: [-21.21179675] bias: [16.45862481] loss: 30.979978626394303\n",
            "Epoch: 2526 / 5000\n",
            "w1: [23.97578826] w2: [-21.21186193] bias: [16.46944584] loss: 30.980352511157907\n",
            "Epoch: 2527 / 5000\n",
            "w1: [23.98228271] w2: [-21.21065682] bias: [16.47994467] loss: 30.98138058550975\n",
            "Epoch: 2528 / 5000\n",
            "w1: [23.98382884] w2: [-21.21165926] bias: [16.48798968] loss: 30.9821496131671\n",
            "Epoch: 2529 / 5000\n",
            "w1: [23.99107284] w2: [-21.20579622] bias: [16.5144171] loss: 30.988441101215297\n",
            "Epoch: 2530 / 5000\n",
            "w1: [23.98777782] w2: [-21.2079886] bias: [16.51441723] loss: 30.98791670940171\n",
            "Epoch: 2531 / 5000\n",
            "w1: [23.98163892] w2: [-21.20929223] bias: [16.50138343] loss: 30.985279517704576\n",
            "Epoch: 2532 / 5000\n",
            "w1: [23.98890848] w2: [-21.19942636] bias: [16.51904632] loss: 30.991577819911978\n",
            "Epoch: 2533 / 5000\n",
            "w1: [23.9981455] w2: [-21.19834992] bias: [16.52845174] loss: 30.99392616213663\n",
            "Epoch: 2534 / 5000\n",
            "w1: [24.0128325] w2: [-21.20049397] bias: [16.54187794] loss: 30.996774826006927\n",
            "Epoch: 2535 / 5000\n",
            "w1: [24.00600623] w2: [-21.20919888] bias: [16.52645597] loss: 30.989701164125027\n",
            "Epoch: 2536 / 5000\n",
            "w1: [24.01628734] w2: [-21.19656288] bias: [16.54659352] loss: 30.99956193414961\n",
            "Epoch: 2537 / 5000\n",
            "w1: [24.04190895] w2: [-21.19085129] bias: [16.59405965] loss: 31.02057105493053\n",
            "Epoch: 2538 / 5000\n",
            "w1: [24.03958668] w2: [-21.19154801] bias: [16.59104864] loss: 31.018833805601606\n",
            "Epoch: 2539 / 5000\n",
            "w1: [24.05027284] w2: [-21.19595089] bias: [16.59932168] loss: 31.02162749883372\n",
            "Epoch: 2540 / 5000\n",
            "w1: [24.05985903] w2: [-21.1954131] bias: [16.61080934] loss: 31.02813320223387\n",
            "Epoch: 2541 / 5000\n",
            "w1: [24.05577444] w2: [-21.19904347] bias: [16.60187948] loss: 31.02207586958876\n",
            "Epoch: 2542 / 5000\n",
            "w1: [24.04505119] w2: [-21.20863837] bias: [16.57562426] loss: 31.006434329481188\n",
            "Epoch: 2543 / 5000\n",
            "w1: [24.04282596] w2: [-21.2114591] bias: [16.57553294] loss: 31.00527192120636\n",
            "Epoch: 2544 / 5000\n",
            "w1: [24.04076843] w2: [-21.22056265] bias: [16.56055686] loss: 30.996353300580957\n",
            "Epoch: 2545 / 5000\n",
            "w1: [24.05174725] w2: [-21.22422613] bias: [16.57180601] loss: 30.99961978004168\n",
            "Epoch: 2546 / 5000\n",
            "w1: [24.05805184] w2: [-21.22083892] bias: [16.57933016] loss: 31.004163932936596\n",
            "Epoch: 2547 / 5000\n",
            "w1: [24.07044407] w2: [-21.21697672] bias: [16.60124755] loss: 31.01615462630269\n",
            "Epoch: 2548 / 5000\n",
            "w1: [24.05677731] w2: [-21.22767892] bias: [16.57267194] loss: 30.998943962757917\n",
            "Epoch: 2549 / 5000\n",
            "w1: [24.0541388] w2: [-21.2269615] bias: [16.57225043] loss: 30.998916825099815\n",
            "Epoch: 2550 / 5000\n",
            "w1: [24.07269301] w2: [-21.2313526] bias: [16.58967749] loss: 31.00562545021728\n",
            "Epoch: 2551 / 5000\n",
            "w1: [24.08025223] w2: [-21.218192] bias: [16.6049674] loss: 31.018366699079703\n",
            "Epoch: 2552 / 5000\n",
            "w1: [24.08974759] w2: [-21.22108999] bias: [16.60740306] loss: 31.019389332293585\n",
            "Epoch: 2553 / 5000\n",
            "w1: [24.09317263] w2: [-21.22701254] bias: [16.62628197] loss: 31.027226259821845\n",
            "Epoch: 2554 / 5000\n",
            "w1: [24.09572146] w2: [-21.22697676] bias: [16.6272727] loss: 31.028094380816732\n",
            "Epoch: 2555 / 5000\n",
            "w1: [24.08333626] w2: [-21.23711811] bias: [16.60248521] loss: 31.0101690493386\n",
            "Epoch: 2556 / 5000\n",
            "w1: [24.09104982] w2: [-21.2475416] bias: [16.60196665] loss: 31.006640101101425\n",
            "Epoch: 2557 / 5000\n",
            "w1: [24.10025634] w2: [-21.25417723] bias: [16.61719297] loss: 31.012505273735584\n",
            "Epoch: 2558 / 5000\n",
            "w1: [24.09223638] w2: [-21.25753608] bias: [16.60383273] loss: 31.00382356228354\n",
            "Epoch: 2559 / 5000\n",
            "w1: [24.08472658] w2: [-21.26385554] bias: [16.58470002] loss: 30.99229661019382\n",
            "Epoch: 2560 / 5000\n",
            "w1: [24.06564719] w2: [-21.26884232] bias: [16.55682231] loss: 30.97897510209845\n",
            "Epoch: 2561 / 5000\n",
            "w1: [24.08384262] w2: [-21.28005892] bias: [16.57555119] loss: 30.982663411988145\n",
            "Epoch: 2562 / 5000\n",
            "w1: [24.09389655] w2: [-21.28273228] bias: [16.58206314] loss: 30.98491303460877\n",
            "Epoch: 2563 / 5000\n",
            "w1: [24.09368021] w2: [-21.2889267] bias: [16.56862765] loss: 30.977302492799684\n",
            "Epoch: 2564 / 5000\n",
            "w1: [24.08981786] w2: [-21.29112744] bias: [16.56362088] loss: 30.97447732365564\n",
            "Epoch: 2565 / 5000\n",
            "w1: [24.092631] w2: [-21.28932545] bias: [16.56622063] loss: 30.976194523753026\n",
            "Epoch: 2566 / 5000\n",
            "w1: [24.08183929] w2: [-21.29391268] bias: [16.55294087] loss: 30.969496399670433\n",
            "Epoch: 2567 / 5000\n",
            "w1: [24.09496362] w2: [-21.30654714] bias: [16.55738919] loss: 30.96709515680718\n",
            "Epoch: 2568 / 5000\n",
            "w1: [24.08260014] w2: [-21.31987594] bias: [16.52947891] loss: 30.953775127415287\n",
            "Epoch: 2569 / 5000\n",
            "w1: [24.07948093] w2: [-21.32701575] bias: [16.51265598] loss: 30.947304225508386\n",
            "Epoch: 2570 / 5000\n",
            "w1: [24.07192389] w2: [-21.34045972] bias: [16.49462292] loss: 30.939877030388832\n",
            "Epoch: 2571 / 5000\n",
            "w1: [24.09331275] w2: [-21.33147244] bias: [16.54191776] loss: 30.953667912089387\n",
            "Epoch: 2572 / 5000\n",
            "w1: [24.09182638] w2: [-21.33772884] bias: [16.53582295] loss: 30.94983984162938\n",
            "Epoch: 2573 / 5000\n",
            "w1: [24.09518086] w2: [-21.33087009] bias: [16.54537367] loss: 30.954954978490257\n",
            "Epoch: 2574 / 5000\n",
            "w1: [24.09234797] w2: [-21.31915893] bias: [16.55010576] loss: 30.96030095198828\n",
            "Epoch: 2575 / 5000\n",
            "w1: [24.07905175] w2: [-21.33528457] bias: [16.52217636] loss: 30.94709981280096\n",
            "Epoch: 2576 / 5000\n",
            "w1: [24.0888629] w2: [-21.34419873] bias: [16.52080935] loss: 30.943793558444597\n",
            "Epoch: 2577 / 5000\n",
            "w1: [24.09411267] w2: [-21.35217124] bias: [16.52383681] loss: 30.942007623679128\n",
            "Epoch: 2578 / 5000\n",
            "w1: [24.09650291] w2: [-21.36107152] bias: [16.51483693] loss: 30.93700602568993\n",
            "Epoch: 2579 / 5000\n",
            "w1: [24.11194099] w2: [-21.36117014] bias: [16.53044287] loss: 30.940807934819027\n",
            "Epoch: 2580 / 5000\n",
            "w1: [24.12913408] w2: [-21.35220606] bias: [16.55810183] loss: 30.95300695634462\n",
            "Epoch: 2581 / 5000\n",
            "w1: [24.12130398] w2: [-21.34943547] bias: [16.55152242] loss: 30.951354098486824\n",
            "Epoch: 2582 / 5000\n",
            "w1: [24.12787942] w2: [-21.35092967] bias: [16.56350202] loss: 30.955381642762532\n",
            "Epoch: 2583 / 5000\n",
            "w1: [24.10992065] w2: [-21.36383236] bias: [16.52615506] loss: 30.938792054775128\n",
            "Epoch: 2584 / 5000\n",
            "w1: [24.08794636] w2: [-21.37587453] bias: [16.49072912] loss: 30.928157159819893\n",
            "Epoch: 2585 / 5000\n",
            "w1: [24.07307518] w2: [-21.38465086] bias: [16.46053851] loss: 30.923099757356376\n",
            "Epoch: 2586 / 5000\n",
            "w1: [24.06694771] w2: [-21.3861738] bias: [16.4491464] loss: 30.922553331820158\n",
            "Epoch: 2587 / 5000\n",
            "w1: [24.07648468] w2: [-21.36520492] bias: [16.47718797] loss: 30.92982350779094\n",
            "Epoch: 2588 / 5000\n",
            "w1: [24.092957] w2: [-21.36862014] bias: [16.49028952] loss: 30.92982241330723\n",
            "Epoch: 2589 / 5000\n",
            "w1: [24.08189257] w2: [-21.37624366] bias: [16.46630488] loss: 30.925010576530653\n",
            "Epoch: 2590 / 5000\n",
            "w1: [24.06781675] w2: [-21.38176326] bias: [16.44389085] loss: 30.923232553833152\n",
            "Epoch: 2591 / 5000\n",
            "w1: [24.09580826] w2: [-21.37306457] bias: [16.48530105] loss: 30.927521129283303\n",
            "Epoch: 2592 / 5000\n",
            "w1: [24.09505007] w2: [-21.38035982] bias: [16.48560295] loss: 30.925583466509863\n",
            "Epoch: 2593 / 5000\n",
            "w1: [24.10143152] w2: [-21.38458803] bias: [16.49572933] loss: 30.92582223384941\n",
            "Epoch: 2594 / 5000\n",
            "w1: [24.08180386] w2: [-21.39657457] bias: [16.467611] loss: 30.919842661273115\n",
            "Epoch: 2595 / 5000\n",
            "w1: [24.0742905] w2: [-21.40437136] bias: [16.45556817] loss: 30.91759810065141\n",
            "Epoch: 2596 / 5000\n",
            "w1: [24.06628754] w2: [-21.41157197] bias: [16.44303069] loss: 30.91621823085229\n",
            "Epoch: 2597 / 5000\n",
            "w1: [24.06292995] w2: [-21.41729639] bias: [16.4320505] loss: 30.915176786344425\n",
            "Epoch: 2598 / 5000\n",
            "w1: [24.07388901] w2: [-21.40854867] bias: [16.45241508] loss: 30.916409868160805\n",
            "Epoch: 2599 / 5000\n",
            "w1: [24.06797083] w2: [-21.4108656] bias: [16.44252941] loss: 30.91614186616676\n",
            "Epoch: 2600 / 5000\n",
            "w1: [24.07214263] w2: [-21.39859854] bias: [16.45747277] loss: 30.91941953916081\n",
            "Epoch: 2601 / 5000\n",
            "w1: [24.07863407] w2: [-21.40093569] bias: [16.46267786] loss: 30.918554087003496\n",
            "Epoch: 2602 / 5000\n",
            "w1: [24.07551177] w2: [-21.40378499] bias: [16.45648039] loss: 30.917669239225713\n",
            "Epoch: 2603 / 5000\n",
            "w1: [24.07112602] w2: [-21.40405772] bias: [16.4482311] loss: 30.91760830999136\n",
            "Epoch: 2604 / 5000\n",
            "w1: [24.06719188] w2: [-21.40671338] bias: [16.44736326] loss: 30.917423589193305\n",
            "Epoch: 2605 / 5000\n",
            "w1: [24.07091074] w2: [-21.4119217] bias: [16.44816655] loss: 30.91573078037828\n",
            "Epoch: 2606 / 5000\n",
            "w1: [24.07119657] w2: [-21.40814312] bias: [16.44945828] loss: 30.916671823906988\n",
            "Epoch: 2607 / 5000\n",
            "w1: [24.05415404] w2: [-21.42776288] bias: [16.4118252] loss: 30.914836563953266\n",
            "Epoch: 2608 / 5000\n",
            "w1: [24.04930266] w2: [-21.43236203] bias: [16.4014845] loss: 30.915490827408295\n",
            "Epoch: 2609 / 5000\n",
            "w1: [24.06475448] w2: [-21.43849451] bias: [16.41528035] loss: 30.910541894077834\n",
            "Epoch: 2610 / 5000\n",
            "w1: [24.04840962] w2: [-21.44756699] bias: [16.37880877] loss: 30.91522568477765\n",
            "Epoch: 2611 / 5000\n",
            "w1: [24.05967304] w2: [-21.44140228] bias: [16.40035428] loss: 30.91175900110202\n",
            "Epoch: 2612 / 5000\n",
            "w1: [24.04291886] w2: [-21.45275067] bias: [16.36886206] loss: 30.917066185210945\n",
            "Epoch: 2613 / 5000\n",
            "w1: [24.03762652] w2: [-21.46316527] bias: [16.35180113] loss: 30.91986175462008\n",
            "Epoch: 2614 / 5000\n",
            "w1: [24.03546196] w2: [-21.47029589] bias: [16.35223787] loss: 30.919204817280065\n",
            "Epoch: 2615 / 5000\n",
            "w1: [24.06382833] w2: [-21.44893892] bias: [16.41369141] loss: 30.90858146193153\n",
            "Epoch: 2616 / 5000\n",
            "w1: [24.06276266] w2: [-21.46058965] bias: [16.40551227] loss: 30.906921295046164\n",
            "Epoch: 2617 / 5000\n",
            "w1: [24.06008284] w2: [-21.46428724] bias: [16.40437056] loss: 30.906792028927647\n",
            "Epoch: 2618 / 5000\n",
            "w1: [24.07139761] w2: [-21.47097639] bias: [16.40948047] loss: 30.90293440613035\n",
            "Epoch: 2619 / 5000\n",
            "w1: [24.07365666] w2: [-21.48157052] bias: [16.40510076] loss: 30.900709102813646\n",
            "Epoch: 2620 / 5000\n",
            "w1: [24.07925997] w2: [-21.48293098] bias: [16.41069048] loss: 30.899002971092333\n",
            "Epoch: 2621 / 5000\n",
            "w1: [24.10152969] w2: [-21.48420899] bias: [16.4397178] loss: 30.894529292673536\n",
            "Epoch: 2622 / 5000\n",
            "w1: [24.10608784] w2: [-21.48368564] bias: [16.43975272] loss: 30.894022543571516\n",
            "Epoch: 2623 / 5000\n",
            "w1: [24.09705522] w2: [-21.48688536] bias: [16.43126686] loss: 30.89452525225614\n",
            "Epoch: 2624 / 5000\n",
            "w1: [24.09443981] w2: [-21.49174446] bias: [16.41973876] loss: 30.894119797723036\n",
            "Epoch: 2625 / 5000\n",
            "w1: [24.07318739] w2: [-21.48498523] bias: [16.41164692] loss: 30.89963968526225\n",
            "Epoch: 2626 / 5000\n",
            "w1: [24.06860932] w2: [-21.481315] bias: [16.40687775] loss: 30.9015820854385\n",
            "Epoch: 2627 / 5000\n",
            "w1: [24.07922235] w2: [-21.47976603] bias: [16.42960235] loss: 30.898869397989984\n",
            "Epoch: 2628 / 5000\n",
            "w1: [24.09194243] w2: [-21.48340769] bias: [16.43785] loss: 30.896051501747966\n",
            "Epoch: 2629 / 5000\n",
            "w1: [24.09850677] w2: [-21.49163294] bias: [16.43793714] loss: 30.893274360047474\n",
            "Epoch: 2630 / 5000\n",
            "w1: [24.10879572] w2: [-21.50358082] bias: [16.43997677] loss: 30.88918030501636\n",
            "Epoch: 2631 / 5000\n",
            "w1: [24.10173391] w2: [-21.49557919] bias: [16.43283849] loss: 30.891918877076872\n",
            "Epoch: 2632 / 5000\n",
            "w1: [24.09248983] w2: [-21.4939715] bias: [16.42007738] loss: 30.89396711878208\n",
            "Epoch: 2633 / 5000\n",
            "w1: [24.07916338] w2: [-21.50351043] bias: [16.39623136] loss: 30.89620483070088\n",
            "Epoch: 2634 / 5000\n",
            "w1: [24.108132] w2: [-21.50121931] bias: [16.44493122] loss: 30.889901184556496\n",
            "Epoch: 2635 / 5000\n",
            "w1: [24.11741161] w2: [-21.51038185] bias: [16.45932298] loss: 30.887229381944234\n",
            "Epoch: 2636 / 5000\n",
            "w1: [24.10939517] w2: [-21.51910172] bias: [16.44674904] loss: 30.885755834291416\n",
            "Epoch: 2637 / 5000\n",
            "w1: [24.09689193] w2: [-21.51795748] bias: [16.42928339] loss: 30.887938526844312\n",
            "Epoch: 2638 / 5000\n",
            "w1: [24.10897447] w2: [-21.50841836] bias: [16.45426267] loss: 30.88845811194247\n",
            "Epoch: 2639 / 5000\n",
            "w1: [24.11095726] w2: [-21.51129248] bias: [16.44721826] loss: 30.887307885189824\n",
            "Epoch: 2640 / 5000\n",
            "w1: [24.11386959] w2: [-21.48889465] bias: [16.46276419] loss: 30.89297913813908\n",
            "Epoch: 2641 / 5000\n",
            "w1: [24.12795678] w2: [-21.49610041] bias: [16.4702958] loss: 30.89043667817489\n",
            "Epoch: 2642 / 5000\n",
            "w1: [24.11715828] w2: [-21.49686616] bias: [16.45085122] loss: 30.889968299803243\n",
            "Epoch: 2643 / 5000\n",
            "w1: [24.11815555] w2: [-21.50017344] bias: [16.44836024] loss: 30.888961531129464\n",
            "Epoch: 2644 / 5000\n",
            "w1: [24.11763976] w2: [-21.49748453] bias: [16.46012596] loss: 30.890310736768026\n",
            "Epoch: 2645 / 5000\n",
            "w1: [24.1168799] w2: [-21.50665874] bias: [16.4642653] loss: 30.88848935669663\n",
            "Epoch: 2646 / 5000\n",
            "w1: [24.10924923] w2: [-21.51083023] bias: [16.45032166] loss: 30.887728747602665\n",
            "Epoch: 2647 / 5000\n",
            "w1: [24.10023645] w2: [-21.50344199] bias: [16.4393716] loss: 30.890424654837197\n",
            "Epoch: 2648 / 5000\n",
            "w1: [24.08893018] w2: [-21.50706391] bias: [16.42108827] loss: 30.89182291585272\n",
            "Epoch: 2649 / 5000\n",
            "w1: [24.08820754] w2: [-21.51599313] bias: [16.40867754] loss: 30.890928513977926\n",
            "Epoch: 2650 / 5000\n",
            "w1: [24.08810875] w2: [-21.5240102] bias: [16.39674953] loss: 30.890509820937698\n",
            "Epoch: 2651 / 5000\n",
            "w1: [24.0798565] w2: [-21.51079861] bias: [16.40344867] loss: 30.89397829489649\n",
            "Epoch: 2652 / 5000\n",
            "w1: [24.07062472] w2: [-21.51413575] bias: [16.38441126] loss: 30.89754246478946\n",
            "Epoch: 2653 / 5000\n",
            "w1: [24.06828359] w2: [-21.51710676] bias: [16.37847202] loss: 30.898453421613308\n",
            "Epoch: 2654 / 5000\n",
            "w1: [24.07716668] w2: [-21.51713881] bias: [16.38613419] loss: 30.895331096143664\n",
            "Epoch: 2655 / 5000\n",
            "w1: [24.06686951] w2: [-21.52597971] bias: [16.36228086] loss: 30.900220402114844\n",
            "Epoch: 2656 / 5000\n",
            "w1: [24.04975723] w2: [-21.52459787] bias: [16.34108563] loss: 30.909823339005708\n",
            "Epoch: 2657 / 5000\n",
            "w1: [24.06434034] w2: [-21.51768503] bias: [16.37120163] loss: 30.900510067260985\n",
            "Epoch: 2658 / 5000\n",
            "w1: [24.07343037] w2: [-21.52331385] bias: [16.37577696] loss: 30.89663758706573\n",
            "Epoch: 2659 / 5000\n",
            "w1: [24.06623238] w2: [-21.52627952] bias: [16.36928357] loss: 30.898991385641196\n",
            "Epoch: 2660 / 5000\n",
            "w1: [24.07503601] w2: [-21.5274803] bias: [16.37874612] loss: 30.89508534495387\n",
            "Epoch: 2661 / 5000\n",
            "w1: [24.07897786] w2: [-21.52925169] bias: [16.37934924] loss: 30.893787883529182\n",
            "Epoch: 2662 / 5000\n",
            "w1: [24.09274434] w2: [-21.53067442] bias: [16.38946984] loss: 30.889152544510324\n",
            "Epoch: 2663 / 5000\n",
            "w1: [24.08749166] w2: [-21.53453645] bias: [16.37863984] loss: 30.89106332846522\n",
            "Epoch: 2664 / 5000\n",
            "w1: [24.09465753] w2: [-21.53319375] bias: [16.39332778] loss: 30.887853887179087\n",
            "Epoch: 2665 / 5000\n",
            "w1: [24.11523643] w2: [-21.5314851] bias: [16.42493805] loss: 30.882282500624868\n",
            "Epoch: 2666 / 5000\n",
            "w1: [24.10080491] w2: [-21.53999862] bias: [16.39887691] loss: 30.884781693304397\n",
            "Epoch: 2667 / 5000\n",
            "w1: [24.10328467] w2: [-21.54393299] bias: [16.39332811] loss: 30.88413149597709\n",
            "Epoch: 2668 / 5000\n",
            "w1: [24.08838866] w2: [-21.55101868] bias: [16.36788652] loss: 30.889874273801553\n",
            "Epoch: 2669 / 5000\n",
            "w1: [24.10399463] w2: [-21.5494933] bias: [16.37891403] loss: 30.884784722656512\n",
            "Epoch: 2670 / 5000\n",
            "w1: [24.1024717] w2: [-21.54528304] bias: [16.37850392] loss: 30.885903773864623\n",
            "Epoch: 2671 / 5000\n",
            "w1: [24.11336875] w2: [-21.55273434] bias: [16.38791913] loss: 30.881080181843416\n",
            "Epoch: 2672 / 5000\n",
            "w1: [24.09756882] w2: [-21.56252464] bias: [16.36624851] loss: 30.886118237399153\n",
            "Epoch: 2673 / 5000\n",
            "w1: [24.09042989] w2: [-21.55871188] bias: [16.35504258] loss: 30.89064723987874\n",
            "Epoch: 2674 / 5000\n",
            "w1: [24.07964682] w2: [-21.56004337] bias: [16.3391419] loss: 30.89697043168505\n",
            "Epoch: 2675 / 5000\n",
            "w1: [24.07699761] w2: [-21.56213705] bias: [16.33139339] loss: 30.89945759596661\n",
            "Epoch: 2676 / 5000\n",
            "w1: [24.07766544] w2: [-21.57185274] bias: [16.32537405] loss: 30.899679754984707\n",
            "Epoch: 2677 / 5000\n",
            "w1: [24.06462244] w2: [-21.56837764] bias: [16.30860844] loss: 30.90933172598804\n",
            "Epoch: 2678 / 5000\n",
            "w1: [24.07415305] w2: [-21.56306485] bias: [16.32625597] loss: 30.901592299238082\n",
            "Epoch: 2679 / 5000\n",
            "w1: [24.06928752] w2: [-21.57155325] bias: [16.31267587] loss: 30.906149881726233\n",
            "Epoch: 2680 / 5000\n",
            "w1: [24.06062286] w2: [-21.58389604] bias: [16.28714751] loss: 30.916792962010234\n",
            "Epoch: 2681 / 5000\n",
            "w1: [24.07347274] w2: [-21.59048654] bias: [16.29803689] loss: 30.907673185760284\n",
            "Epoch: 2682 / 5000\n",
            "w1: [24.06633534] w2: [-21.60105508] bias: [16.27863367] loss: 30.916589840509708\n",
            "Epoch: 2683 / 5000\n",
            "w1: [24.07026561] w2: [-21.60416787] bias: [16.27406616] loss: 30.916789098019354\n",
            "Epoch: 2684 / 5000\n",
            "w1: [24.06709293] w2: [-21.60059748] bias: [16.27443496] loss: 30.918095974145082\n",
            "Epoch: 2685 / 5000\n",
            "w1: [24.07750292] w2: [-21.5979957] bias: [16.28390944] loss: 30.91081475825767\n",
            "Epoch: 2686 / 5000\n",
            "w1: [24.08980785] w2: [-21.59522071] bias: [16.29802675] loss: 30.901802052546888\n",
            "Epoch: 2687 / 5000\n",
            "w1: [24.0906018] w2: [-21.60226795] bias: [16.30233783] loss: 30.89930828169823\n",
            "Epoch: 2688 / 5000\n",
            "w1: [24.09754898] w2: [-21.60381562] bias: [16.30988724] loss: 30.894461655550803\n",
            "Epoch: 2689 / 5000\n",
            "w1: [24.08626724] w2: [-21.60677713] bias: [16.28972439] loss: 30.90475005686134\n",
            "Epoch: 2690 / 5000\n",
            "w1: [24.10181635] w2: [-21.60618243] bias: [16.30742067] loss: 30.89364987415908\n",
            "Epoch: 2691 / 5000\n",
            "w1: [24.10969726] w2: [-21.59100668] bias: [16.32702064] loss: 30.887478653830062\n",
            "Epoch: 2692 / 5000\n",
            "w1: [24.10170791] w2: [-21.59858523] bias: [16.30641767] loss: 30.894875696343433\n",
            "Epoch: 2693 / 5000\n",
            "w1: [24.09066223] w2: [-21.60748177] bias: [16.28456375] loss: 30.90511802127979\n",
            "Epoch: 2694 / 5000\n",
            "w1: [24.11574064] w2: [-21.60257632] bias: [16.32570702] loss: 30.88460231952646\n",
            "Epoch: 2695 / 5000\n",
            "w1: [24.11957961] w2: [-21.60001915] bias: [16.33863241] loss: 30.880656351576032\n",
            "Epoch: 2696 / 5000\n",
            "w1: [24.10920611] w2: [-21.61162046] bias: [16.31884542] loss: 30.887270607672434\n",
            "Epoch: 2697 / 5000\n",
            "w1: [24.12854853] w2: [-21.60130257] bias: [16.34724684] loss: 30.876234236776963\n",
            "Epoch: 2698 / 5000\n",
            "w1: [24.13170071] w2: [-21.60887786] bias: [16.34359992] loss: 30.875107359953162\n",
            "Epoch: 2699 / 5000\n",
            "w1: [24.14654262] w2: [-21.6094541] bias: [16.35704263] loss: 30.86873730186999\n",
            "Epoch: 2700 / 5000\n",
            "w1: [24.1499022] w2: [-21.61822886] bias: [16.34769245] loss: 30.868331573587216\n",
            "Epoch: 2701 / 5000\n",
            "w1: [24.14076711] w2: [-21.63166316] bias: [16.33101616] loss: 30.872485246798842\n",
            "Epoch: 2702 / 5000\n",
            "w1: [24.15523538] w2: [-21.62881787] bias: [16.35196254] loss: 30.864635287737322\n",
            "Epoch: 2703 / 5000\n",
            "w1: [24.1540241] w2: [-21.62382736] bias: [16.35136093] loss: 30.865790459495454\n",
            "Epoch: 2704 / 5000\n",
            "w1: [24.13562254] w2: [-21.62681272] bias: [16.33713396] loss: 30.873039449969273\n",
            "Epoch: 2705 / 5000\n",
            "w1: [24.1322069] w2: [-21.63089726] bias: [16.32660368] loss: 30.87607253365255\n",
            "Epoch: 2706 / 5000\n",
            "w1: [24.15310571] w2: [-21.63366417] bias: [16.3578165] loss: 30.863327591320566\n",
            "Epoch: 2707 / 5000\n",
            "w1: [24.14659011] w2: [-21.64166905] bias: [16.33828222] loss: 30.867843454397264\n",
            "Epoch: 2708 / 5000\n",
            "w1: [24.15695979] w2: [-21.641723] bias: [16.35793004] loss: 30.86117496690303\n",
            "Epoch: 2709 / 5000\n",
            "w1: [24.17033302] w2: [-21.64193686] bias: [16.37456276] loss: 30.855508891922526\n",
            "Epoch: 2710 / 5000\n",
            "w1: [24.17871087] w2: [-21.63502577] bias: [16.38188993] loss: 30.854078794673843\n",
            "Epoch: 2711 / 5000\n",
            "w1: [24.18961289] w2: [-21.63535485] bias: [16.39389639] loss: 30.850896545706085\n",
            "Epoch: 2712 / 5000\n",
            "w1: [24.21030609] w2: [-21.63078878] bias: [16.41559182] loss: 30.847633178295602\n",
            "Epoch: 2713 / 5000\n",
            "w1: [24.22957141] w2: [-21.62158744] bias: [16.44781349] loss: 30.848654299826865\n",
            "Epoch: 2714 / 5000\n",
            "w1: [24.21104139] w2: [-21.62548365] bias: [16.423221] loss: 30.848667222822325\n",
            "Epoch: 2715 / 5000\n",
            "w1: [24.22764434] w2: [-21.6158603] bias: [16.44945833] loss: 30.850307110543906\n",
            "Epoch: 2716 / 5000\n",
            "w1: [24.24681984] w2: [-21.62151807] bias: [16.46251006] loss: 30.84886147601319\n",
            "Epoch: 2717 / 5000\n",
            "w1: [24.24122585] w2: [-21.63694777] bias: [16.43932638] loss: 30.84334565796013\n",
            "Epoch: 2718 / 5000\n",
            "w1: [24.23460661] w2: [-21.64507718] bias: [16.41865133] loss: 30.84141682583258\n",
            "Epoch: 2719 / 5000\n",
            "w1: [24.26028355] w2: [-21.62870033] bias: [16.4605489] loss: 30.845927655015267\n",
            "Epoch: 2720 / 5000\n",
            "w1: [24.25146894] w2: [-21.63315041] bias: [16.44162825] loss: 30.843407960482033\n",
            "Epoch: 2721 / 5000\n",
            "w1: [24.25536515] w2: [-21.63861251] bias: [16.43729609] loss: 30.841424761876812\n",
            "Epoch: 2722 / 5000\n",
            "w1: [24.26684939] w2: [-21.64323791] bias: [16.44717354] loss: 30.84029187728582\n",
            "Epoch: 2723 / 5000\n",
            "w1: [24.26730897] w2: [-21.64592841] bias: [16.43975111] loss: 30.83886925915511\n",
            "Epoch: 2724 / 5000\n",
            "w1: [24.28912232] w2: [-21.64406308] bias: [16.46534193] loss: 30.84120222008426\n",
            "Epoch: 2725 / 5000\n",
            "w1: [24.29218767] w2: [-21.63868007] bias: [16.47512557] loss: 30.84423828645266\n",
            "Epoch: 2726 / 5000\n",
            "w1: [24.28769444] w2: [-21.64505504] bias: [16.46412219] loss: 30.840819353636807\n",
            "Epoch: 2727 / 5000\n",
            "w1: [24.29991472] w2: [-21.63894262] bias: [16.47870892] loss: 30.844659678452672\n",
            "Epoch: 2728 / 5000\n",
            "w1: [24.29828898] w2: [-21.64330538] bias: [16.47442272] loss: 30.842688169658423\n",
            "Epoch: 2729 / 5000\n",
            "w1: [24.29341664] w2: [-21.6449009] bias: [16.46169955] loss: 30.840171312198343\n",
            "Epoch: 2730 / 5000\n",
            "w1: [24.30921153] w2: [-21.6403775] bias: [16.48200843] loss: 30.84478895421466\n",
            "Epoch: 2731 / 5000\n",
            "w1: [24.3321381] w2: [-21.62823796] bias: [16.52515253] loss: 30.860838259950217\n",
            "Epoch: 2732 / 5000\n",
            "w1: [24.34192918] w2: [-21.61999737] bias: [16.55503348] loss: 30.875438711341737\n",
            "Epoch: 2733 / 5000\n",
            "w1: [24.34812318] w2: [-21.61853879] bias: [16.56985755] loss: 30.882971465852656\n",
            "Epoch: 2734 / 5000\n",
            "w1: [24.33182725] w2: [-21.61818973] bias: [16.54670202] loss: 30.871882380033128\n",
            "Epoch: 2735 / 5000\n",
            "w1: [24.3346096] w2: [-21.62260557] bias: [16.54364798] loss: 30.869472568647137\n",
            "Epoch: 2736 / 5000\n",
            "w1: [24.34927648] w2: [-21.62113827] bias: [16.56511641] loss: 30.880075935028774\n",
            "Epoch: 2737 / 5000\n",
            "w1: [24.37434744] w2: [-21.61373076] bias: [16.60866099] loss: 30.907865472610215\n",
            "Epoch: 2738 / 5000\n",
            "w1: [24.38922965] w2: [-21.61330112] bias: [16.63331409] loss: 30.925341881592203\n",
            "Epoch: 2739 / 5000\n",
            "w1: [24.38947474] w2: [-21.61135426] bias: [16.63475894] loss: 30.927060885783874\n",
            "Epoch: 2740 / 5000\n",
            "w1: [24.40319451] w2: [-21.59934199] bias: [16.6592162] loss: 30.951166969114187\n",
            "Epoch: 2741 / 5000\n",
            "w1: [24.39004179] w2: [-21.61427873] bias: [16.62958735] loss: 30.922790541729402\n",
            "Epoch: 2742 / 5000\n",
            "w1: [24.40379743] w2: [-21.61925668] bias: [16.64200691] loss: 30.931524463743536\n",
            "Epoch: 2743 / 5000\n",
            "w1: [24.41287085] w2: [-21.62593218] bias: [16.64142301] loss: 30.93039985688268\n",
            "Epoch: 2744 / 5000\n",
            "w1: [24.40265947] w2: [-21.61514239] bias: [16.63404429] loss: 30.927744210395687\n",
            "Epoch: 2745 / 5000\n",
            "w1: [24.40814221] w2: [-21.61711316] bias: [16.64291711] loss: 30.93390188452699\n",
            "Epoch: 2746 / 5000\n",
            "w1: [24.41041863] w2: [-21.6139324] bias: [16.64558276] loss: 30.937456875923523\n",
            "Epoch: 2747 / 5000\n",
            "w1: [24.41466825] w2: [-21.61344241] bias: [16.64580483] loss: 30.938741669484195\n",
            "Epoch: 2748 / 5000\n",
            "w1: [24.41242423] w2: [-21.619667] bias: [16.63204613] loss: 30.926659407486813\n",
            "Epoch: 2749 / 5000\n",
            "w1: [24.43968015] w2: [-21.61384976] bias: [16.6628402] loss: 30.956610553223847\n",
            "Epoch: 2750 / 5000\n",
            "w1: [24.43737888] w2: [-21.62121673] bias: [16.64831322] loss: 30.94249995409474\n",
            "Epoch: 2751 / 5000\n",
            "w1: [24.42665831] w2: [-21.63433234] bias: [16.61781456] loss: 30.914741786767472\n",
            "Epoch: 2752 / 5000\n",
            "w1: [24.42863003] w2: [-21.6391041] bias: [16.61249243] loss: 30.909999036744896\n",
            "Epoch: 2753 / 5000\n",
            "w1: [24.40667093] w2: [-21.64993025] bias: [16.57430927] loss: 30.88117489393974\n",
            "Epoch: 2754 / 5000\n",
            "w1: [24.41015739] w2: [-21.64755946] bias: [16.57928991] loss: 30.885043132161265\n",
            "Epoch: 2755 / 5000\n",
            "w1: [24.41384049] w2: [-21.6511228] bias: [16.57935736] loss: 30.8843336250618\n",
            "Epoch: 2756 / 5000\n",
            "w1: [24.41768271] w2: [-21.65021386] bias: [16.57660891] loss: 30.88376175087527\n",
            "Epoch: 2757 / 5000\n",
            "w1: [24.42559257] w2: [-21.65989507] bias: [16.57954357] loss: 30.883004277462945\n",
            "Epoch: 2758 / 5000\n",
            "w1: [24.41048432] w2: [-21.66594419] bias: [16.55596346] loss: 30.867251761972582\n",
            "Epoch: 2759 / 5000\n",
            "w1: [24.39353624] w2: [-21.68388854] bias: [16.52966645] loss: 30.848805240511513\n",
            "Epoch: 2760 / 5000\n",
            "w1: [24.39593075] w2: [-21.68569891] bias: [16.52432877] loss: 30.846386130969048\n",
            "Epoch: 2761 / 5000\n",
            "w1: [24.40854714] w2: [-21.68595942] bias: [16.53986041] loss: 30.85339969426851\n",
            "Epoch: 2762 / 5000\n",
            "w1: [24.39653964] w2: [-21.70452709] bias: [16.50905026] loss: 30.835371703170672\n",
            "Epoch: 2763 / 5000\n",
            "w1: [24.39096848] w2: [-21.71952128] bias: [16.48361056] loss: 30.823368663262443\n",
            "Epoch: 2764 / 5000\n",
            "w1: [24.3973269] w2: [-21.72388975] bias: [16.48809074] loss: 30.823471972413724\n",
            "Epoch: 2765 / 5000\n",
            "w1: [24.39776977] w2: [-21.72983591] bias: [16.4812101] loss: 30.81998787422353\n",
            "Epoch: 2766 / 5000\n",
            "w1: [24.38880786] w2: [-21.72258986] bias: [16.47414586] loss: 30.820123756019246\n",
            "Epoch: 2767 / 5000\n",
            "w1: [24.41114501] w2: [-21.71986268] bias: [16.4991331] loss: 30.828270994245887\n",
            "Epoch: 2768 / 5000\n",
            "w1: [24.41387925] w2: [-21.71361736] bias: [16.50576493] loss: 30.832378717757425\n",
            "Epoch: 2769 / 5000\n",
            "w1: [24.41163955] w2: [-21.7139414] bias: [16.50147292] loss: 30.830757540578638\n",
            "Epoch: 2770 / 5000\n",
            "w1: [24.41279587] w2: [-21.70925649] bias: [16.50403034] loss: 30.83302511846769\n",
            "Epoch: 2771 / 5000\n",
            "w1: [24.38733455] w2: [-21.71769011] bias: [16.46674179] loss: 30.819673125107194\n",
            "Epoch: 2772 / 5000\n",
            "w1: [24.39244829] w2: [-21.71446034] bias: [16.47387665] loss: 30.822223881105298\n",
            "Epoch: 2773 / 5000\n",
            "w1: [24.38174337] w2: [-21.71977176] bias: [16.45231987] loss: 30.81619136428858\n",
            "Epoch: 2774 / 5000\n",
            "w1: [24.38899491] w2: [-21.71272457] bias: [16.4671003] loss: 30.821047150981023\n",
            "Epoch: 2775 / 5000\n",
            "w1: [24.36739824] w2: [-21.71499904] bias: [16.44028801] loss: 30.81580780586797\n",
            "Epoch: 2776 / 5000\n",
            "w1: [24.39841117] w2: [-21.71278864] bias: [16.47392514] loss: 30.822704518612394\n",
            "Epoch: 2777 / 5000\n",
            "w1: [24.41849414] w2: [-21.69017871] bias: [16.51100219] loss: 30.84149224706498\n",
            "Epoch: 2778 / 5000\n",
            "w1: [24.39646272] w2: [-21.71304076] bias: [16.46782455] loss: 30.821098845302956\n",
            "Epoch: 2779 / 5000\n",
            "w1: [24.39773434] w2: [-21.70657733] bias: [16.4818604] loss: 30.82652796505912\n",
            "Epoch: 2780 / 5000\n",
            "w1: [24.39482317] w2: [-21.71401147] bias: [16.47267992] loss: 30.82204569677892\n",
            "Epoch: 2781 / 5000\n",
            "w1: [24.37284676] w2: [-21.72862804] bias: [16.4300308] loss: 30.810779310445614\n",
            "Epoch: 2782 / 5000\n",
            "w1: [24.35481835] w2: [-21.74409221] bias: [16.3945722] loss: 30.805938656216476\n",
            "Epoch: 2783 / 5000\n",
            "w1: [24.37046867] w2: [-21.74526806] bias: [16.41064691] loss: 30.805099307090973\n",
            "Epoch: 2784 / 5000\n",
            "w1: [24.37537132] w2: [-21.74187486] bias: [16.43198612] loss: 30.80781477277807\n",
            "Epoch: 2785 / 5000\n",
            "w1: [24.36129456] w2: [-21.75276385] bias: [16.40592043] loss: 30.80401698577503\n",
            "Epoch: 2786 / 5000\n",
            "w1: [24.38251323] w2: [-21.74247079] bias: [16.4480852] loss: 30.809781174371196\n",
            "Epoch: 2787 / 5000\n",
            "w1: [24.37600589] w2: [-21.74835009] bias: [16.43545652] loss: 30.806746855719155\n",
            "Epoch: 2788 / 5000\n",
            "w1: [24.3802996] w2: [-21.73570903] bias: [16.46215993] loss: 30.81416896802538\n",
            "Epoch: 2789 / 5000\n",
            "w1: [24.38572807] w2: [-21.7403666] bias: [16.46295213] loss: 30.813028529755666\n",
            "Epoch: 2790 / 5000\n",
            "w1: [24.35076002] w2: [-21.75850049] bias: [16.40696368] loss: 30.803962808251903\n",
            "Epoch: 2791 / 5000\n",
            "w1: [24.35918021] w2: [-21.76357769] bias: [16.41341612] loss: 30.802431807226377\n",
            "Epoch: 2792 / 5000\n",
            "w1: [24.35124939] w2: [-21.779999] bias: [16.38622099] loss: 30.79925979427358\n",
            "Epoch: 2793 / 5000\n",
            "w1: [24.35253237] w2: [-21.7687477] bias: [16.39583737] loss: 30.801325596554822\n",
            "Epoch: 2794 / 5000\n",
            "w1: [24.33476977] w2: [-21.76496446] bias: [16.37453732] loss: 30.804605706861484\n",
            "Epoch: 2795 / 5000\n",
            "w1: [24.33009682] w2: [-21.7671716] bias: [16.3657581] loss: 30.805385880465607\n",
            "Epoch: 2796 / 5000\n",
            "w1: [24.32635345] w2: [-21.77446385] bias: [16.36532359] loss: 30.804790266423183\n",
            "Epoch: 2797 / 5000\n",
            "w1: [24.32287053] w2: [-21.77895591] bias: [16.36303988] loss: 30.804807250979408\n",
            "Epoch: 2798 / 5000\n",
            "w1: [24.33047787] w2: [-21.77165614] bias: [16.380835] loss: 30.80381965178107\n",
            "Epoch: 2799 / 5000\n",
            "w1: [24.31634448] w2: [-21.78221393] bias: [16.35259156] loss: 30.80647265749303\n",
            "Epoch: 2800 / 5000\n",
            "w1: [24.3054678] w2: [-21.79196237] bias: [16.33214712] loss: 30.81012466843927\n",
            "Epoch: 2801 / 5000\n",
            "w1: [24.32146828] w2: [-21.79357553] bias: [16.35260463] loss: 30.803734377601643\n",
            "Epoch: 2802 / 5000\n",
            "w1: [24.34339886] w2: [-21.78788615] bias: [16.3802273] loss: 30.799022403887882\n",
            "Epoch: 2803 / 5000\n",
            "w1: [24.3408643] w2: [-21.79825199] bias: [16.36689919] loss: 30.79826964417873\n",
            "Epoch: 2804 / 5000\n",
            "w1: [24.34391455] w2: [-21.79447286] bias: [16.36962186] loss: 30.79825091470172\n",
            "Epoch: 2805 / 5000\n",
            "w1: [24.33398215] w2: [-21.80127991] bias: [16.35644904] loss: 30.79981371261101\n",
            "Epoch: 2806 / 5000\n",
            "w1: [24.33270913] w2: [-21.80089607] bias: [16.35492405] loss: 30.800255546913586\n",
            "Epoch: 2807 / 5000\n",
            "w1: [24.34751624] w2: [-21.79369133] bias: [16.37380517] loss: 30.797619845094513\n",
            "Epoch: 2808 / 5000\n",
            "w1: [24.34137682] w2: [-21.80595453] bias: [16.35814874] loss: 30.79759621545254\n",
            "Epoch: 2809 / 5000\n",
            "w1: [24.3341725] w2: [-21.81133849] bias: [16.34689405] loss: 30.799265963971475\n",
            "Epoch: 2810 / 5000\n",
            "w1: [24.32544732] w2: [-21.82251105] bias: [16.34012538] loss: 30.800309146350116\n",
            "Epoch: 2811 / 5000\n",
            "w1: [24.34142535] w2: [-21.81394252] bias: [16.36298664] loss: 30.795885869670844\n",
            "Epoch: 2812 / 5000\n",
            "w1: [24.3190722] w2: [-21.82231448] bias: [16.34660523] loss: 30.80069597665425\n",
            "Epoch: 2813 / 5000\n",
            "w1: [24.30288186] w2: [-21.82730706] bias: [16.32469652] loss: 30.80748434674515\n",
            "Epoch: 2814 / 5000\n",
            "w1: [24.30404961] w2: [-21.82608735] bias: [16.32647293] loss: 30.806994682483367\n",
            "Epoch: 2815 / 5000\n",
            "w1: [24.27837595] w2: [-21.83711831] bias: [16.28615341] loss: 30.82309592813288\n",
            "Epoch: 2816 / 5000\n",
            "w1: [24.28285747] w2: [-21.84728567] bias: [16.28330382] loss: 30.821762592861784\n",
            "Epoch: 2817 / 5000\n",
            "w1: [24.27319613] w2: [-21.85210369] bias: [16.27171671] loss: 30.828308952618414\n",
            "Epoch: 2818 / 5000\n",
            "w1: [24.26364343] w2: [-21.86452725] bias: [16.24517106] loss: 30.84119629431359\n",
            "Epoch: 2819 / 5000\n",
            "w1: [24.27713963] w2: [-21.85545449] bias: [16.26800028] loss: 30.828142041526572\n",
            "Epoch: 2820 / 5000\n",
            "w1: [24.27067586] w2: [-21.85598843] bias: [16.26486412] loss: 30.83136600929136\n",
            "Epoch: 2821 / 5000\n",
            "w1: [24.27706824] w2: [-21.84380505] bias: [16.28488423] loss: 30.823291143937766\n",
            "Epoch: 2822 / 5000\n",
            "w1: [24.28731667] w2: [-21.8395938] bias: [16.30908523] loss: 30.81368216350782\n",
            "Epoch: 2823 / 5000\n",
            "w1: [24.29418705] w2: [-21.83348774] bias: [16.31953442] loss: 30.81000208378329\n",
            "Epoch: 2824 / 5000\n",
            "w1: [24.30295292] w2: [-21.83397418] bias: [16.33027628] loss: 30.805492862758896\n",
            "Epoch: 2825 / 5000\n",
            "w1: [24.30542661] w2: [-21.82634954] bias: [16.34243574] loss: 30.803676082004632\n",
            "Epoch: 2826 / 5000\n",
            "w1: [24.30300899] w2: [-21.82654236] bias: [16.34896641] loss: 30.80309768229283\n",
            "Epoch: 2827 / 5000\n",
            "w1: [24.31135486] w2: [-21.82538151] bias: [16.35598146] loss: 30.800503407688826\n",
            "Epoch: 2828 / 5000\n",
            "w1: [24.32323128] w2: [-21.82387412] bias: [16.37573589] loss: 30.79636085655152\n",
            "Epoch: 2829 / 5000\n",
            "w1: [24.32718116] w2: [-21.82417022] bias: [16.37905332] loss: 30.79538485020569\n",
            "Epoch: 2830 / 5000\n",
            "w1: [24.35624561] w2: [-21.81293918] bias: [16.43366032] loss: 30.793795854743735\n",
            "Epoch: 2831 / 5000\n",
            "w1: [24.36397804] w2: [-21.82099546] bias: [16.4322204] loss: 30.791320379933836\n",
            "Epoch: 2832 / 5000\n",
            "w1: [24.35966607] w2: [-21.83682668] bias: [16.42567615] loss: 30.788120925940536\n",
            "Epoch: 2833 / 5000\n",
            "w1: [24.33318168] w2: [-21.83912494] bias: [16.39314269] loss: 30.791078569812765\n",
            "Epoch: 2834 / 5000\n",
            "w1: [24.33155105] w2: [-21.84155072] bias: [16.39500356] loss: 30.7908265297373\n",
            "Epoch: 2835 / 5000\n",
            "w1: [24.31828227] w2: [-21.84312344] bias: [16.37884049] loss: 30.793888964586266\n",
            "Epoch: 2836 / 5000\n",
            "w1: [24.31310871] w2: [-21.85161237] bias: [16.37103887] loss: 30.79437693945482\n",
            "Epoch: 2837 / 5000\n",
            "w1: [24.31270275] w2: [-21.85425062] bias: [16.36685379] loss: 30.794590113128436\n",
            "Epoch: 2838 / 5000\n",
            "w1: [24.3227296] w2: [-21.8558798] bias: [16.38238964] loss: 30.790777913739316\n",
            "Epoch: 2839 / 5000\n",
            "w1: [24.3311499] w2: [-21.85072168] bias: [16.39319906] loss: 30.78943049131547\n",
            "Epoch: 2840 / 5000\n",
            "w1: [24.34184982] w2: [-21.85396192] bias: [16.40221275] loss: 30.78689096245638\n",
            "Epoch: 2841 / 5000\n",
            "w1: [24.36593184] w2: [-21.84838779] bias: [16.44526001] loss: 30.786489422698182\n",
            "Epoch: 2842 / 5000\n",
            "w1: [24.36872637] w2: [-21.85754504] bias: [16.44084996] loss: 30.784003323541523\n",
            "Epoch: 2843 / 5000\n",
            "w1: [24.37360215] w2: [-21.86090407] bias: [16.44579648] loss: 30.783299971097907\n",
            "Epoch: 2844 / 5000\n",
            "w1: [24.38066262] w2: [-21.85889655] bias: [16.4495618] loss: 30.7835439280917\n",
            "Epoch: 2845 / 5000\n",
            "w1: [24.38603146] w2: [-21.85185989] bias: [16.4590271] loss: 30.78584558324099\n",
            "Epoch: 2846 / 5000\n",
            "w1: [24.39146061] w2: [-21.83567] bias: [16.48602383] loss: 30.793918596564488\n",
            "Epoch: 2847 / 5000\n",
            "w1: [24.37799886] w2: [-21.82495565] bias: [16.4764427] loss: 30.795076750841076\n",
            "Epoch: 2848 / 5000\n",
            "w1: [24.36984598] w2: [-21.83220862] bias: [16.45474721] loss: 30.790643621383854\n",
            "Epoch: 2849 / 5000\n",
            "w1: [24.35817317] w2: [-21.83743761] bias: [16.43827928] loss: 30.78888388080328\n",
            "Epoch: 2850 / 5000\n",
            "w1: [24.34039458] w2: [-21.84558162] bias: [16.40573827] loss: 30.788494195608287\n",
            "Epoch: 2851 / 5000\n",
            "w1: [24.33220823] w2: [-21.84887779] bias: [16.38685746] loss: 30.789954277692306\n",
            "Epoch: 2852 / 5000\n",
            "w1: [24.31880545] w2: [-21.84889256] bias: [16.37503182] loss: 30.79327569003929\n",
            "Epoch: 2853 / 5000\n",
            "w1: [24.35048839] w2: [-21.84590592] bias: [16.41750901] loss: 30.787125939881406\n",
            "Epoch: 2854 / 5000\n",
            "w1: [24.35812086] w2: [-21.84871494] bias: [16.4239063] loss: 30.785879541322636\n",
            "Epoch: 2855 / 5000\n",
            "w1: [24.36716972] w2: [-21.84608767] bias: [16.43392867] loss: 30.785994684122493\n",
            "Epoch: 2856 / 5000\n",
            "w1: [24.36209528] w2: [-21.84675291] bias: [16.42537669] loss: 30.785895339173127\n",
            "Epoch: 2857 / 5000\n",
            "w1: [24.35244904] w2: [-21.85439438] bias: [16.41353171] loss: 30.78526168154264\n",
            "Epoch: 2858 / 5000\n",
            "w1: [24.34746892] w2: [-21.85884185] bias: [16.39383285] loss: 30.785526588159282\n",
            "Epoch: 2859 / 5000\n",
            "w1: [24.34747011] w2: [-21.86794509] bias: [16.38532579] loss: 30.78446861212827\n",
            "Epoch: 2860 / 5000\n",
            "w1: [24.32846974] w2: [-21.88153998] bias: [16.34777742] loss: 30.790417744333624\n",
            "Epoch: 2861 / 5000\n",
            "w1: [24.33114542] w2: [-21.87111812] bias: [16.36299791] loss: 30.789044651734766\n",
            "Epoch: 2862 / 5000\n",
            "w1: [24.32936814] w2: [-21.8762308] bias: [16.35991207] loss: 30.789083797609415\n",
            "Epoch: 2863 / 5000\n",
            "w1: [24.32136402] w2: [-21.88369757] bias: [16.34605268] loss: 30.79198970445849\n",
            "Epoch: 2864 / 5000\n",
            "w1: [24.32875985] w2: [-21.87186581] bias: [16.36904208] loss: 30.78864514243541\n",
            "Epoch: 2865 / 5000\n",
            "w1: [24.35388428] w2: [-21.86965252] bias: [16.40098172] loss: 30.782484747189827\n",
            "Epoch: 2866 / 5000\n",
            "w1: [24.35245602] w2: [-21.87491194] bias: [16.41163326] loss: 30.78154615104171\n",
            "Epoch: 2867 / 5000\n",
            "w1: [24.34830491] w2: [-21.88281319] bias: [16.39542785] loss: 30.781305161059645\n",
            "Epoch: 2868 / 5000\n",
            "w1: [24.37168445] w2: [-21.87062539] bias: [16.4461226] loss: 30.78147415756442\n",
            "Epoch: 2869 / 5000\n",
            "w1: [24.40409424] w2: [-21.86945381] bias: [16.47865548] loss: 30.784097944012736\n",
            "Epoch: 2870 / 5000\n",
            "w1: [24.4119103] w2: [-21.8786185] bias: [16.48128156] loss: 30.78220101747282\n",
            "Epoch: 2871 / 5000\n",
            "w1: [24.39940857] w2: [-21.88701653] bias: [16.45386525] loss: 30.776733351620734\n",
            "Epoch: 2872 / 5000\n",
            "w1: [24.40888757] w2: [-21.87880702] bias: [16.47572877] loss: 30.781245280718032\n",
            "Epoch: 2873 / 5000\n",
            "w1: [24.40855285] w2: [-21.88777377] bias: [16.46512583] loss: 30.777525645016702\n",
            "Epoch: 2874 / 5000\n",
            "w1: [24.39146064] w2: [-21.8897649] bias: [16.45281651] loss: 30.77657580880937\n",
            "Epoch: 2875 / 5000\n",
            "w1: [24.40323312] w2: [-21.86496671] bias: [16.48509184] loss: 30.786389430115808\n",
            "Epoch: 2876 / 5000\n",
            "w1: [24.40966315] w2: [-21.85457246] bias: [16.50306351] loss: 30.792823092937216\n",
            "Epoch: 2877 / 5000\n",
            "w1: [24.42506759] w2: [-21.85307214] bias: [16.52995554] loss: 30.801037566965885\n",
            "Epoch: 2878 / 5000\n",
            "w1: [24.41054063] w2: [-21.85391378] bias: [16.5092933] loss: 30.79455673075444\n",
            "Epoch: 2879 / 5000\n",
            "w1: [24.41976129] w2: [-21.85241318] bias: [16.52296088] loss: 30.798904542109245\n",
            "Epoch: 2880 / 5000\n",
            "w1: [24.42522628] w2: [-21.85931656] bias: [16.52290073] loss: 30.797185918201667\n",
            "Epoch: 2881 / 5000\n",
            "w1: [24.41037297] w2: [-21.86369426] bias: [16.49548328] loss: 30.788758638509155\n",
            "Epoch: 2882 / 5000\n",
            "w1: [24.42899551] w2: [-21.86529441] bias: [16.51235715] loss: 30.79267107287513\n",
            "Epoch: 2883 / 5000\n",
            "w1: [24.4358403] w2: [-21.86565366] bias: [16.52389251] loss: 30.79611927641144\n",
            "Epoch: 2884 / 5000\n",
            "w1: [24.42934051] w2: [-21.86608774] bias: [16.51423] loss: 30.792989138320642\n",
            "Epoch: 2885 / 5000\n",
            "w1: [24.427804] w2: [-21.87186854] bias: [16.50809026] loss: 30.789790926784004\n",
            "Epoch: 2886 / 5000\n",
            "w1: [24.43667564] w2: [-21.86825562] bias: [16.51757035] loss: 30.793553793074636\n",
            "Epoch: 2887 / 5000\n",
            "w1: [24.44634397] w2: [-21.8704724] bias: [16.52917088] loss: 30.7968902938173\n",
            "Epoch: 2888 / 5000\n",
            "w1: [24.44845318] w2: [-21.86864092] bias: [16.53015852] loss: 30.797821293100874\n",
            "Epoch: 2889 / 5000\n",
            "w1: [24.43992595] w2: [-21.87814284] bias: [16.51142424] loss: 30.789266047831468\n",
            "Epoch: 2890 / 5000\n",
            "w1: [24.4466456] w2: [-21.87906063] bias: [16.53231112] loss: 30.79555069684523\n",
            "Epoch: 2891 / 5000\n",
            "w1: [24.45436506] w2: [-21.87988653] bias: [16.5457242] loss: 30.80035227336857\n",
            "Epoch: 2892 / 5000\n",
            "w1: [24.45603651] w2: [-21.88401539] bias: [16.54594493] loss: 30.799359250968813\n",
            "Epoch: 2893 / 5000\n",
            "w1: [24.4619719] w2: [-21.88699808] bias: [16.54650143] loss: 30.799103290135477\n",
            "Epoch: 2894 / 5000\n",
            "w1: [24.4552147] w2: [-21.88560664] bias: [16.54269288] loss: 30.797697578906504\n",
            "Epoch: 2895 / 5000\n",
            "w1: [24.48320084] w2: [-21.86717934] bias: [16.59962295] loss: 30.830593267166826\n",
            "Epoch: 2896 / 5000\n",
            "w1: [24.46721072] w2: [-21.87634012] bias: [16.56987711] loss: 30.811927172614773\n",
            "Epoch: 2897 / 5000\n",
            "w1: [24.46855335] w2: [-21.88116826] bias: [16.56237545] loss: 30.80747318333392\n",
            "Epoch: 2898 / 5000\n",
            "w1: [24.47493213] w2: [-21.88495369] bias: [16.56398609] loss: 30.807587339095058\n",
            "Epoch: 2899 / 5000\n",
            "w1: [24.46984485] w2: [-21.89734749] bias: [16.5468574] loss: 30.796810019016636\n",
            "Epoch: 2900 / 5000\n",
            "w1: [24.46545827] w2: [-21.90526962] bias: [16.52892603] loss: 30.78814002189207\n",
            "Epoch: 2901 / 5000\n",
            "w1: [24.45294099] w2: [-21.91133683] bias: [16.50630269] loss: 30.779553663588928\n",
            "Epoch: 2902 / 5000\n",
            "w1: [24.46348416] w2: [-21.91589971] bias: [16.53564736] loss: 30.787327109967915\n",
            "Epoch: 2903 / 5000\n",
            "w1: [24.45353745] w2: [-21.92179453] bias: [16.5185849] loss: 30.780203145458437\n",
            "Epoch: 2904 / 5000\n",
            "w1: [24.46350787] w2: [-21.9289924] bias: [16.52871494] loss: 30.781598411753134\n",
            "Epoch: 2905 / 5000\n",
            "w1: [24.48267162] w2: [-21.93481938] bias: [16.54699724] loss: 30.78710671054124\n",
            "Epoch: 2906 / 5000\n",
            "w1: [24.46725442] w2: [-21.95102145] bias: [16.51216261] loss: 30.771290250007706\n",
            "Epoch: 2907 / 5000\n",
            "w1: [24.47215321] w2: [-21.93609037] bias: [16.5289904] loss: 30.78014370674537\n",
            "Epoch: 2908 / 5000\n",
            "w1: [24.48012374] w2: [-21.94322506] bias: [16.52926047] loss: 30.778671482187384\n",
            "Epoch: 2909 / 5000\n",
            "w1: [24.47235648] w2: [-21.95212045] bias: [16.50718613] loss: 30.769799662266273\n",
            "Epoch: 2910 / 5000\n",
            "w1: [24.46796363] w2: [-21.96052868] bias: [16.48821088] loss: 30.76330131613246\n",
            "Epoch: 2911 / 5000\n",
            "w1: [24.46191485] w2: [-21.97130144] bias: [16.48512289] loss: 30.760273819098533\n",
            "Epoch: 2912 / 5000\n",
            "w1: [24.47561017] w2: [-21.9682284] bias: [16.50545583] loss: 30.76541817067681\n",
            "Epoch: 2913 / 5000\n",
            "w1: [24.47996328] w2: [-21.96649566] bias: [16.51152427] loss: 30.767476649556453\n",
            "Epoch: 2914 / 5000\n",
            "w1: [24.48350469] w2: [-21.95443686] bias: [16.53635572] loss: 30.7781051140526\n",
            "Epoch: 2915 / 5000\n",
            "w1: [24.49884827] w2: [-21.94974995] bias: [16.55592899] loss: 30.787399658569292\n",
            "Epoch: 2916 / 5000\n",
            "w1: [24.4852055] w2: [-21.95690634] bias: [16.53193385] loss: 30.776099638763355\n",
            "Epoch: 2917 / 5000\n",
            "w1: [24.4982228] w2: [-21.96491954] bias: [16.53235061] loss: 30.774738445025466\n",
            "Epoch: 2918 / 5000\n",
            "w1: [24.51438203] w2: [-21.96628781] bias: [16.55000242] loss: 30.78167745043333\n",
            "Epoch: 2919 / 5000\n",
            "w1: [24.50233164] w2: [-21.97808389] bias: [16.5169625] loss: 30.76667657391167\n",
            "Epoch: 2920 / 5000\n",
            "w1: [24.49003956] w2: [-21.98163812] bias: [16.49645228] loss: 30.760092564600207\n",
            "Epoch: 2921 / 5000\n",
            "w1: [24.48204492] w2: [-21.97436304] bias: [16.49734591] loss: 30.762013336396045\n",
            "Epoch: 2922 / 5000\n",
            "w1: [24.48564353] w2: [-21.97672056] bias: [16.5152867] loss: 30.76604995400622\n",
            "Epoch: 2923 / 5000\n",
            "w1: [24.48811326] w2: [-21.97041582] bias: [16.52315608] loss: 30.76997394361486\n",
            "Epoch: 2924 / 5000\n",
            "w1: [24.47127078] w2: [-21.98826332] bias: [16.48684563] loss: 30.75657012547264\n",
            "Epoch: 2925 / 5000\n",
            "w1: [24.4536208] w2: [-22.00019479] bias: [16.45822677] loss: 30.750300718325768\n",
            "Epoch: 2926 / 5000\n",
            "w1: [24.46460002] w2: [-22.00330255] bias: [16.46852498] loss: 30.7503922413077\n",
            "Epoch: 2927 / 5000\n",
            "w1: [24.45407646] w2: [-22.00926579] bias: [16.45723628] loss: 30.748343023050463\n",
            "Epoch: 2928 / 5000\n",
            "w1: [24.44543612] w2: [-22.01845839] bias: [16.43982597] loss: 30.745845415750555\n",
            "Epoch: 2929 / 5000\n",
            "w1: [24.44620396] w2: [-22.02114988] bias: [16.44435589] loss: 30.745549996608833\n",
            "Epoch: 2930 / 5000\n",
            "w1: [24.44695493] w2: [-22.01994779] bias: [16.44512415] loss: 30.74576146709123\n",
            "Epoch: 2931 / 5000\n",
            "w1: [24.44225096] w2: [-22.02857192] bias: [16.43062346] loss: 30.74395391310986\n",
            "Epoch: 2932 / 5000\n",
            "w1: [24.43962237] w2: [-22.02935822] bias: [16.42417322] loss: 30.743975503083163\n",
            "Epoch: 2933 / 5000\n",
            "w1: [24.42868789] w2: [-22.01785554] bias: [16.41955937] loss: 30.747166930676396\n",
            "Epoch: 2934 / 5000\n",
            "w1: [24.42919812] w2: [-22.02027494] bias: [16.41546079] loss: 30.746730381611513\n",
            "Epoch: 2935 / 5000\n",
            "w1: [24.45237261] w2: [-22.02419682] bias: [16.43232581] loss: 30.74378585301056\n",
            "Epoch: 2936 / 5000\n",
            "w1: [24.46273719] w2: [-22.03129967] bias: [16.45220887] loss: 30.742945976350285\n",
            "Epoch: 2937 / 5000\n",
            "w1: [24.46256404] w2: [-22.03820036] bias: [16.44179502] loss: 30.740841617956875\n",
            "Epoch: 2938 / 5000\n",
            "w1: [24.46551254] w2: [-22.03930338] bias: [16.4493609] loss: 30.740964959833775\n",
            "Epoch: 2939 / 5000\n",
            "w1: [24.44241316] w2: [-22.04311319] bias: [16.41814323] loss: 30.741335177004043\n",
            "Epoch: 2940 / 5000\n",
            "w1: [24.43216283] w2: [-22.0436699] bias: [16.3998891] loss: 30.743156580891483\n",
            "Epoch: 2941 / 5000\n",
            "w1: [24.42754193] w2: [-22.03900574] bias: [16.39487473] loss: 30.74483596791182\n",
            "Epoch: 2942 / 5000\n",
            "w1: [24.43571124] w2: [-22.04558243] bias: [16.39926598] loss: 30.74238610200057\n",
            "Epoch: 2943 / 5000\n",
            "w1: [24.42609971] w2: [-22.05486368] bias: [16.37178666] loss: 30.74506891428272\n",
            "Epoch: 2944 / 5000\n",
            "w1: [24.42629842] w2: [-22.0414473] bias: [16.38170817] loss: 30.7457409693958\n",
            "Epoch: 2945 / 5000\n",
            "w1: [24.42353355] w2: [-22.0466932] bias: [16.36767928] loss: 30.747099951142214\n",
            "Epoch: 2946 / 5000\n",
            "w1: [24.42782949] w2: [-22.04556146] bias: [16.37311165] loss: 30.745812466811092\n",
            "Epoch: 2947 / 5000\n",
            "w1: [24.42975214] w2: [-22.04577846] bias: [16.37407247] loss: 30.745338911077734\n",
            "Epoch: 2948 / 5000\n",
            "w1: [24.43037584] w2: [-22.05537853] bias: [16.36827126] loss: 30.744658005069684\n",
            "Epoch: 2949 / 5000\n",
            "w1: [24.43411523] w2: [-22.0586243] bias: [16.36992336] loss: 30.743359920282995\n",
            "Epoch: 2950 / 5000\n",
            "w1: [24.45174867] w2: [-22.05550162] bias: [16.39369868] loss: 30.738874178696033\n",
            "Epoch: 2951 / 5000\n",
            "w1: [24.43936812] w2: [-22.06074655] bias: [16.38000154] loss: 30.741076794773164\n",
            "Epoch: 2952 / 5000\n",
            "w1: [24.41818364] w2: [-22.07079101] bias: [16.35120425] loss: 30.747870465238634\n",
            "Epoch: 2953 / 5000\n",
            "w1: [24.42316229] w2: [-22.0741431] bias: [16.3525861] loss: 30.746204019046676\n",
            "Epoch: 2954 / 5000\n",
            "w1: [24.43226147] w2: [-22.07679289] bias: [16.36163586] loss: 30.74258731065228\n",
            "Epoch: 2955 / 5000\n",
            "w1: [24.43178687] w2: [-22.07994142] bias: [16.36916746] loss: 30.741220556953458\n",
            "Epoch: 2956 / 5000\n",
            "w1: [24.43460129] w2: [-22.07225245] bias: [16.37730221] loss: 30.740654719439025\n",
            "Epoch: 2957 / 5000\n",
            "w1: [24.43872728] w2: [-22.07559758] bias: [16.37811859] loss: 30.73940695074789\n",
            "Epoch: 2958 / 5000\n",
            "w1: [24.42819012] w2: [-22.08014537] bias: [16.35627722] loss: 30.743861094523645\n",
            "Epoch: 2959 / 5000\n",
            "w1: [24.43021374] w2: [-22.08009183] bias: [16.35647283] loss: 30.743423019545546\n",
            "Epoch: 2960 / 5000\n",
            "w1: [24.42157829] w2: [-22.08629588] bias: [16.33815199] loss: 30.748088633536717\n",
            "Epoch: 2961 / 5000\n",
            "w1: [24.41952879] w2: [-22.08455708] bias: [16.33511205] loss: 30.74939111057253\n",
            "Epoch: 2962 / 5000\n",
            "w1: [24.42069777] w2: [-22.08974643] bias: [16.3284761] loss: 30.750141999216233\n",
            "Epoch: 2963 / 5000\n",
            "w1: [24.42177754] w2: [-22.09098439] bias: [16.33487206] loss: 30.748303627059798\n",
            "Epoch: 2964 / 5000\n",
            "w1: [24.42292966] w2: [-22.09856679] bias: [16.33181676] loss: 30.748017150110897\n",
            "Epoch: 2965 / 5000\n",
            "w1: [24.43076496] w2: [-22.09721012] bias: [16.33492832] loss: 30.745613409644122\n",
            "Epoch: 2966 / 5000\n",
            "w1: [24.4304427] w2: [-22.10188284] bias: [16.32815527] loss: 30.74677773848867\n",
            "Epoch: 2967 / 5000\n",
            "w1: [24.43360638] w2: [-22.10746404] bias: [16.32583961] loss: 30.74606467899938\n",
            "Epoch: 2968 / 5000\n",
            "w1: [24.44752872] w2: [-22.1075113] bias: [16.34137098] loss: 30.739531501149518\n",
            "Epoch: 2969 / 5000\n",
            "w1: [24.46573846] w2: [-22.10820393] bias: [16.36919193] loss: 30.73154162290549\n",
            "Epoch: 2970 / 5000\n",
            "w1: [24.49460082] w2: [-22.09973632] bias: [16.41503958] loss: 30.726087176076437\n",
            "Epoch: 2971 / 5000\n",
            "w1: [24.50140474] w2: [-22.10554205] bias: [16.41823503] loss: 30.724454506458738\n",
            "Epoch: 2972 / 5000\n",
            "w1: [24.50995529] w2: [-22.10398583] bias: [16.43514895] loss: 30.72460720608474\n",
            "Epoch: 2973 / 5000\n",
            "w1: [24.51337548] w2: [-22.07080525] bias: [16.46649496] loss: 30.734056627775917\n",
            "Epoch: 2974 / 5000\n",
            "w1: [24.50058627] w2: [-22.08347286] bias: [16.43693742] loss: 30.729149345655912\n",
            "Epoch: 2975 / 5000\n",
            "w1: [24.51110809] w2: [-22.0788738] bias: [16.44815191] loss: 30.730245013519628\n",
            "Epoch: 2976 / 5000\n",
            "w1: [24.51482843] w2: [-22.08008801] bias: [16.45950182] loss: 30.731141100735744\n",
            "Epoch: 2977 / 5000\n",
            "w1: [24.52581756] w2: [-22.09201129] bias: [16.46115543] loss: 30.728496271143932\n",
            "Epoch: 2978 / 5000\n",
            "w1: [24.51932883] w2: [-22.09734565] bias: [16.44646741] loss: 30.726059156711564\n",
            "Epoch: 2979 / 5000\n",
            "w1: [24.5228969] w2: [-22.10098118] bias: [16.44804114] loss: 30.7253141534608\n",
            "Epoch: 2980 / 5000\n",
            "w1: [24.49847952] w2: [-22.11756883] bias: [16.40352901] loss: 30.722912752396066\n",
            "Epoch: 2981 / 5000\n",
            "w1: [24.50049395] w2: [-22.12317923] bias: [16.40708811] loss: 30.721745548392818\n",
            "Epoch: 2982 / 5000\n",
            "w1: [24.52518673] w2: [-22.11224291] bias: [16.44732798] loss: 30.722984605477766\n",
            "Epoch: 2983 / 5000\n",
            "w1: [24.51802522] w2: [-22.11360407] bias: [16.43559986] loss: 30.722285389969826\n",
            "Epoch: 2984 / 5000\n",
            "w1: [24.52442386] w2: [-22.11996303] bias: [16.43487195] loss: 30.720610511460194\n",
            "Epoch: 2985 / 5000\n",
            "w1: [24.53077588] w2: [-22.1129498] bias: [16.46192169] loss: 30.724226001697698\n",
            "Epoch: 2986 / 5000\n",
            "w1: [24.53681748] w2: [-22.11555561] bias: [16.46471762] loss: 30.72384600975902\n",
            "Epoch: 2987 / 5000\n",
            "w1: [24.53995857] w2: [-22.11462775] bias: [16.46462866] loss: 30.723903161959566\n",
            "Epoch: 2988 / 5000\n",
            "w1: [24.52896522] w2: [-22.11727776] bias: [16.4475443] loss: 30.721833475708117\n",
            "Epoch: 2989 / 5000\n",
            "w1: [24.5302112] w2: [-22.11660321] bias: [16.44500663] loss: 30.7216362650428\n",
            "Epoch: 2990 / 5000\n",
            "w1: [24.52624054] w2: [-22.11046913] bias: [16.44479049] loss: 30.723006253552633\n",
            "Epoch: 2991 / 5000\n",
            "w1: [24.52605565] w2: [-22.11270345] bias: [16.4365728] loss: 30.721907859700366\n",
            "Epoch: 2992 / 5000\n",
            "w1: [24.52102974] w2: [-22.12294876] bias: [16.41923899] loss: 30.719634199962886\n",
            "Epoch: 2993 / 5000\n",
            "w1: [24.5234312] w2: [-22.13409606] bias: [16.41314613] loss: 30.717440625643203\n",
            "Epoch: 2994 / 5000\n",
            "w1: [24.51682687] w2: [-22.14194276] bias: [16.39444953] loss: 30.71721866617135\n",
            "Epoch: 2995 / 5000\n",
            "w1: [24.50647647] w2: [-22.1484536] bias: [16.38942224] loss: 30.71795519322649\n",
            "Epoch: 2996 / 5000\n",
            "w1: [24.49348021] w2: [-22.16026179] bias: [16.36058908] loss: 30.721463253818435\n",
            "Epoch: 2997 / 5000\n",
            "w1: [24.4868309] w2: [-22.16469394] bias: [16.35065702] loss: 30.723778557180598\n",
            "Epoch: 2998 / 5000\n",
            "w1: [24.49515567] w2: [-22.16210026] bias: [16.36058062] loss: 30.720947869408796\n",
            "Epoch: 2999 / 5000\n",
            "w1: [24.49659767] w2: [-22.16745548] bias: [16.35304535] loss: 30.721185742625185\n",
            "Epoch: 3000 / 5000\n",
            "w1: [24.51543972] w2: [-22.16570092] bias: [16.37862643] loss: 30.715095295889288\n",
            "Epoch: 3001 / 5000\n",
            "w1: [24.53024486] w2: [-22.14960272] bias: [16.4103745] loss: 30.71423500988687\n",
            "Epoch: 3002 / 5000\n",
            "w1: [24.56017518] w2: [-22.14995635] bias: [16.4502131] loss: 30.714269989229464\n",
            "Epoch: 3003 / 5000\n",
            "w1: [24.56588309] w2: [-22.14345684] bias: [16.46537315] loss: 30.717391478304183\n",
            "Epoch: 3004 / 5000\n",
            "w1: [24.5569678] w2: [-22.15605804] bias: [16.43820236] loss: 30.71211541894105\n",
            "Epoch: 3005 / 5000\n",
            "w1: [24.54281803] w2: [-22.17129105] bias: [16.40872984] loss: 30.70950910128024\n",
            "Epoch: 3006 / 5000\n",
            "w1: [24.55323825] w2: [-22.17564266] bias: [16.41499827] loss: 30.70784119068497\n",
            "Epoch: 3007 / 5000\n",
            "w1: [24.53453648] w2: [-22.18852007] bias: [16.37483213] loss: 30.709563488223257\n",
            "Epoch: 3008 / 5000\n",
            "w1: [24.54353473] w2: [-22.17976258] bias: [16.39029778] loss: 30.70850807015704\n",
            "Epoch: 3009 / 5000\n",
            "w1: [24.53222284] w2: [-22.18205765] bias: [16.37292294] loss: 30.710897089463803\n",
            "Epoch: 3010 / 5000\n",
            "w1: [24.52394974] w2: [-22.18260896] bias: [16.3597527] loss: 30.7135603745268\n",
            "Epoch: 3011 / 5000\n",
            "w1: [24.55112129] w2: [-22.16229146] bias: [16.41315886] loss: 30.7101331778864\n",
            "Epoch: 3012 / 5000\n",
            "w1: [24.55552227] w2: [-22.16510595] bias: [16.41631339] loss: 30.709359847944373\n",
            "Epoch: 3013 / 5000\n",
            "w1: [24.54421539] w2: [-22.17649401] bias: [16.39022903] loss: 30.708882408626035\n",
            "Epoch: 3014 / 5000\n",
            "w1: [24.53937412] w2: [-22.1819935] bias: [16.38512632] loss: 30.708998165533355\n",
            "Epoch: 3015 / 5000\n",
            "w1: [24.53094842] w2: [-22.18657311] bias: [16.3684337] loss: 30.710956859649567\n",
            "Epoch: 3016 / 5000\n",
            "w1: [24.53500371] w2: [-22.17879455] bias: [16.37777949] loss: 30.7105107884004\n",
            "Epoch: 3017 / 5000\n",
            "w1: [24.53970947] w2: [-22.17944199] bias: [16.38093109] loss: 30.709535933491907\n",
            "Epoch: 3018 / 5000\n",
            "w1: [24.52825743] w2: [-22.19604896] bias: [16.35119028] loss: 30.712417580470717\n",
            "Epoch: 3019 / 5000\n",
            "w1: [24.54876102] w2: [-22.19836706] bias: [16.37419651] loss: 30.70621753824685\n",
            "Epoch: 3020 / 5000\n",
            "w1: [24.53594329] w2: [-22.20602077] bias: [16.35329115] loss: 30.709643644615188\n",
            "Epoch: 3021 / 5000\n",
            "w1: [24.55343621] w2: [-22.20550202] bias: [16.37679011] loss: 30.704428965687825\n",
            "Epoch: 3022 / 5000\n",
            "w1: [24.5552847] w2: [-22.1914817] bias: [16.39906345] loss: 30.70514614367125\n",
            "Epoch: 3023 / 5000\n",
            "w1: [24.53542098] w2: [-22.20300457] bias: [16.36186579] loss: 30.708984239801186\n",
            "Epoch: 3024 / 5000\n",
            "w1: [24.53861631] w2: [-22.19900051] bias: [16.36895905] loss: 30.708162829927772\n",
            "Epoch: 3025 / 5000\n",
            "w1: [24.54572305] w2: [-22.19604677] bias: [16.37902463] loss: 30.706612097460138\n",
            "Epoch: 3026 / 5000\n",
            "w1: [24.51857156] w2: [-22.20786402] bias: [16.3364242] loss: 30.715575732544256\n",
            "Epoch: 3027 / 5000\n",
            "w1: [24.5155275] w2: [-22.21458918] bias: [16.3244071] loss: 30.71810054359329\n",
            "Epoch: 3028 / 5000\n",
            "w1: [24.49999398] w2: [-22.21479433] bias: [16.30086481] loss: 30.72777055321997\n",
            "Epoch: 3029 / 5000\n",
            "w1: [24.51480787] w2: [-22.2134887] bias: [16.31388073] loss: 30.720785546131893\n",
            "Epoch: 3030 / 5000\n",
            "w1: [24.5216874] w2: [-22.22097381] bias: [16.31392125] loss: 30.718582543330275\n",
            "Epoch: 3031 / 5000\n",
            "w1: [24.52193658] w2: [-22.22558225] bias: [16.31016633] loss: 30.719090764202818\n",
            "Epoch: 3032 / 5000\n",
            "w1: [24.53300111] w2: [-22.22302981] bias: [16.32514042] loss: 30.7133754623654\n",
            "Epoch: 3033 / 5000\n",
            "w1: [24.55685386] w2: [-22.22190249] bias: [16.35863635] loss: 30.703578417448664\n",
            "Epoch: 3034 / 5000\n",
            "w1: [24.55813422] w2: [-22.22532643] bias: [16.36378957] loss: 30.7024149956306\n",
            "Epoch: 3035 / 5000\n",
            "w1: [24.56299956] w2: [-22.21605246] bias: [16.37155376] loss: 30.702077346906318\n",
            "Epoch: 3036 / 5000\n",
            "w1: [24.57553653] w2: [-22.21122301] bias: [16.39068532] loss: 30.700078785343088\n",
            "Epoch: 3037 / 5000\n",
            "w1: [24.57453129] w2: [-22.22453249] bias: [16.37369738] loss: 30.699182058250422\n",
            "Epoch: 3038 / 5000\n",
            "w1: [24.58522472] w2: [-22.22120897] bias: [16.38676657] loss: 30.697611976034736\n",
            "Epoch: 3039 / 5000\n",
            "w1: [24.56638864] w2: [-22.23181163] bias: [16.35087143] loss: 30.7017785754475\n",
            "Epoch: 3040 / 5000\n",
            "w1: [24.58467978] w2: [-22.22957764] bias: [16.37510731] loss: 30.69703974156513\n",
            "Epoch: 3041 / 5000\n",
            "w1: [24.59440057] w2: [-22.21630184] bias: [16.39537531] loss: 30.69717536063781\n",
            "Epoch: 3042 / 5000\n",
            "w1: [24.61466881] w2: [-22.2065092] bias: [16.42181872] loss: 30.698170726842577\n",
            "Epoch: 3043 / 5000\n",
            "w1: [24.63654214] w2: [-22.20774661] bias: [16.4446545] loss: 30.699625642592665\n",
            "Epoch: 3044 / 5000\n",
            "w1: [24.63112918] w2: [-22.21271411] bias: [16.42889425] loss: 30.696849080889663\n",
            "Epoch: 3045 / 5000\n",
            "w1: [24.61280887] w2: [-22.21659844] bias: [16.40495873] loss: 30.69559285126482\n",
            "Epoch: 3046 / 5000\n",
            "w1: [24.6122506] w2: [-22.21579839] bias: [16.40900143] loss: 30.6959492684253\n",
            "Epoch: 3047 / 5000\n",
            "w1: [24.60748491] w2: [-22.21271502] bias: [16.40330699] loss: 30.696605302751834\n",
            "Epoch: 3048 / 5000\n",
            "w1: [24.59648683] w2: [-22.22651874] bias: [16.37772403] loss: 30.69578300875689\n",
            "Epoch: 3049 / 5000\n",
            "w1: [24.60009599] w2: [-22.22325791] bias: [16.38123346] loss: 30.695685231526753\n",
            "Epoch: 3050 / 5000\n",
            "w1: [24.60341305] w2: [-22.21305434] bias: [16.39359016] loss: 30.69671885035725\n",
            "Epoch: 3051 / 5000\n",
            "w1: [24.60667774] w2: [-22.21814453] bias: [16.39248992] loss: 30.695614667072622\n",
            "Epoch: 3052 / 5000\n",
            "w1: [24.60108339] w2: [-22.21921214] bias: [16.38243035] loss: 30.696112681322763\n",
            "Epoch: 3053 / 5000\n",
            "w1: [24.59833018] w2: [-22.22294471] bias: [16.37336232] loss: 30.696200445230595\n",
            "Epoch: 3054 / 5000\n",
            "w1: [24.59090116] w2: [-22.22739721] bias: [16.36315385] loss: 30.69721029421067\n",
            "Epoch: 3055 / 5000\n",
            "w1: [24.60627961] w2: [-22.23165764] bias: [16.38449229] loss: 30.693724585615453\n",
            "Epoch: 3056 / 5000\n",
            "w1: [24.5961096] w2: [-22.24946852] bias: [16.35155546] loss: 30.6948043227836\n",
            "Epoch: 3057 / 5000\n",
            "w1: [24.61751411] w2: [-22.25221671] bias: [16.37111118] loss: 30.68997218569506\n",
            "Epoch: 3058 / 5000\n",
            "w1: [24.6253923] w2: [-22.24949716] bias: [16.38251977] loss: 30.689099860119292\n",
            "Epoch: 3059 / 5000\n",
            "w1: [24.60537858] w2: [-22.256438] bias: [16.34757001] loss: 30.692953630628338\n",
            "Epoch: 3060 / 5000\n",
            "w1: [24.60229969] w2: [-22.262383] bias: [16.33698558] loss: 30.69409388152702\n",
            "Epoch: 3061 / 5000\n",
            "w1: [24.60163693] w2: [-22.2663821] bias: [16.33035805] loss: 30.69474890762251\n",
            "Epoch: 3062 / 5000\n",
            "w1: [24.60965654] w2: [-22.26338384] bias: [16.35412195] loss: 30.69084800174732\n",
            "Epoch: 3063 / 5000\n",
            "w1: [24.61784727] w2: [-22.26514205] bias: [16.36642534] loss: 30.68852059413192\n",
            "Epoch: 3064 / 5000\n",
            "w1: [24.63099169] w2: [-22.26479997] bias: [16.38508836] loss: 30.68632046636155\n",
            "Epoch: 3065 / 5000\n",
            "w1: [24.60427892] w2: [-22.26750338] bias: [16.35388782] loss: 30.69123454445725\n",
            "Epoch: 3066 / 5000\n",
            "w1: [24.61151701] w2: [-22.26619642] bias: [16.36133084] loss: 30.689629892264456\n",
            "Epoch: 3067 / 5000\n",
            "w1: [24.61345737] w2: [-22.25794372] bias: [16.37469343] loss: 30.689586293495626\n",
            "Epoch: 3068 / 5000\n",
            "w1: [24.61557998] w2: [-22.26743812] bias: [16.36560921] loss: 30.688598345434837\n",
            "Epoch: 3069 / 5000\n",
            "w1: [24.61558041] w2: [-22.27009261] bias: [16.36328783] loss: 30.688433974470104\n",
            "Epoch: 3070 / 5000\n",
            "w1: [24.61824255] w2: [-22.27354804] bias: [16.3600147] loss: 30.68788362736626\n",
            "Epoch: 3071 / 5000\n",
            "w1: [24.62039555] w2: [-22.27229513] bias: [16.37059891] loss: 30.687047316148107\n",
            "Epoch: 3072 / 5000\n",
            "w1: [24.64250384] w2: [-22.27333001] bias: [16.41869629] loss: 30.684967961840684\n",
            "Epoch: 3073 / 5000\n",
            "w1: [24.64747817] w2: [-22.28500537] bias: [16.40943924] loss: 30.682252127835937\n",
            "Epoch: 3074 / 5000\n",
            "w1: [24.64263429] w2: [-22.28852804] bias: [16.3986664] loss: 30.681815926257443\n",
            "Epoch: 3075 / 5000\n",
            "w1: [24.66522279] w2: [-22.29706062] bias: [16.42051062] loss: 30.67979030806441\n",
            "Epoch: 3076 / 5000\n",
            "w1: [24.65041314] w2: [-22.31406042] bias: [16.38544542] loss: 30.677484748269197\n",
            "Epoch: 3077 / 5000\n",
            "w1: [24.64566694] w2: [-22.325712] bias: [16.36551179] loss: 30.67748937628929\n",
            "Epoch: 3078 / 5000\n",
            "w1: [24.65792191] w2: [-22.3180038] bias: [16.38196326] loss: 30.676195244960436\n",
            "Epoch: 3079 / 5000\n",
            "w1: [24.66118695] w2: [-22.30366117] bias: [16.39893649] loss: 30.677933229474608\n",
            "Epoch: 3080 / 5000\n",
            "w1: [24.6848274] w2: [-22.29036926] bias: [16.44472949] loss: 30.682919585761656\n",
            "Epoch: 3081 / 5000\n",
            "w1: [24.69429023] w2: [-22.28064789] bias: [16.47391202] loss: 30.690291153409955\n",
            "Epoch: 3082 / 5000\n",
            "w1: [24.69173756] w2: [-22.28165085] bias: [16.46510725] loss: 30.688165633267726\n",
            "Epoch: 3083 / 5000\n",
            "w1: [24.67415807] w2: [-22.29110642] bias: [16.44531749] loss: 30.683137353464193\n",
            "Epoch: 3084 / 5000\n",
            "w1: [24.66058807] w2: [-22.29352845] bias: [16.43019829] loss: 30.68147462148327\n",
            "Epoch: 3085 / 5000\n",
            "w1: [24.65414668] w2: [-22.30416976] bias: [16.41100839] loss: 30.678868888935238\n",
            "Epoch: 3086 / 5000\n",
            "w1: [24.65013596] w2: [-22.30711886] bias: [16.40422072] loss: 30.678538993280608\n",
            "Epoch: 3087 / 5000\n",
            "w1: [24.64717271] w2: [-22.30802077] bias: [16.39679678] loss: 30.678579633516435\n",
            "Epoch: 3088 / 5000\n",
            "w1: [24.65698005] w2: [-22.31570179] bias: [16.4005521] loss: 30.676603402090286\n",
            "Epoch: 3089 / 5000\n",
            "w1: [24.66870432] w2: [-22.30180333] bias: [16.43416297] loss: 30.68007820402403\n",
            "Epoch: 3090 / 5000\n",
            "w1: [24.6501407] w2: [-22.30547783] bias: [16.40741948] loss: 30.678867964304267\n",
            "Epoch: 3091 / 5000\n",
            "w1: [24.64049892] w2: [-22.31720707] bias: [16.39083402] loss: 30.67807208857347\n",
            "Epoch: 3092 / 5000\n",
            "w1: [24.6676699] w2: [-22.30765654] bias: [16.43721235] loss: 30.679455214090275\n",
            "Epoch: 3093 / 5000\n",
            "w1: [24.67322327] w2: [-22.30753044] bias: [16.44929517] loss: 30.680758341673563\n",
            "Epoch: 3094 / 5000\n",
            "w1: [24.68118419] w2: [-22.31584708] bias: [16.45285206] loss: 30.679561954926477\n",
            "Epoch: 3095 / 5000\n",
            "w1: [24.67134157] w2: [-22.31013838] bias: [16.44226145] loss: 30.679452603382234\n",
            "Epoch: 3096 / 5000\n",
            "w1: [24.67748196] w2: [-22.30801024] bias: [16.44902791] loss: 30.68051608894984\n",
            "Epoch: 3097 / 5000\n",
            "w1: [24.67029144] w2: [-22.29390521] bias: [16.44933258] loss: 30.683305009074388\n",
            "Epoch: 3098 / 5000\n",
            "w1: [24.65522249] w2: [-22.29617917] bias: [16.42242423] loss: 30.680701107524037\n",
            "Epoch: 3099 / 5000\n",
            "w1: [24.65293984] w2: [-22.29703133] bias: [16.41469812] loss: 30.68023630682429\n",
            "Epoch: 3100 / 5000\n",
            "w1: [24.67380882] w2: [-22.28118612] bias: [16.44887704] loss: 30.685491613002384\n",
            "Epoch: 3101 / 5000\n",
            "w1: [24.68809511] w2: [-22.27595772] bias: [16.4752845] loss: 30.691470811279597\n",
            "Epoch: 3102 / 5000\n",
            "w1: [24.67711588] w2: [-22.2901474] bias: [16.44877091] loss: 30.683743383493383\n",
            "Epoch: 3103 / 5000\n",
            "w1: [24.66925276] w2: [-22.29398302] bias: [16.44126625] loss: 30.682238000444457\n",
            "Epoch: 3104 / 5000\n",
            "w1: [24.66629233] w2: [-22.29801578] bias: [16.43288159] loss: 30.680699836280542\n",
            "Epoch: 3105 / 5000\n",
            "w1: [24.67327087] w2: [-22.29912202] bias: [16.43829133] loss: 30.680819298438113\n",
            "Epoch: 3106 / 5000\n",
            "w1: [24.65887963] w2: [-22.30526439] bias: [16.41209628] loss: 30.678387450336484\n",
            "Epoch: 3107 / 5000\n",
            "w1: [24.64996585] w2: [-22.3116502] bias: [16.40277999] loss: 30.677869035269737\n",
            "Epoch: 3108 / 5000\n",
            "w1: [24.65597949] w2: [-22.29768756] bias: [16.42443582] loss: 30.68055925783186\n",
            "Epoch: 3109 / 5000\n",
            "w1: [24.64881816] w2: [-22.30523338] bias: [16.40567696] loss: 30.678968074337252\n",
            "Epoch: 3110 / 5000\n",
            "w1: [24.66746037] w2: [-22.30870619] bias: [16.4262787] loss: 30.67823475491319\n",
            "Epoch: 3111 / 5000\n",
            "w1: [24.68212885] w2: [-22.30497593] bias: [16.44506716] loss: 30.680377635426822\n",
            "Epoch: 3112 / 5000\n",
            "w1: [24.67479602] w2: [-22.31210538] bias: [16.42546937] loss: 30.67720143116643\n",
            "Epoch: 3113 / 5000\n",
            "w1: [24.67826447] w2: [-22.3065442] bias: [16.44128077] loss: 30.67970974608364\n",
            "Epoch: 3114 / 5000\n",
            "w1: [24.69559288] w2: [-22.31210037] bias: [16.45615278] loss: 30.680546611732193\n",
            "Epoch: 3115 / 5000\n",
            "w1: [24.7190986] w2: [-22.31049002] bias: [16.48739585] loss: 30.687941207349066\n",
            "Epoch: 3116 / 5000\n",
            "w1: [24.72270952] w2: [-22.29789568] bias: [16.50363873] loss: 30.695485976350056\n",
            "Epoch: 3117 / 5000\n",
            "w1: [24.7297381] w2: [-22.28865597] bias: [16.51663097] loss: 30.702344329926845\n",
            "Epoch: 3118 / 5000\n",
            "w1: [24.71599853] w2: [-22.30058895] bias: [16.48790603] loss: 30.690090742810515\n",
            "Epoch: 3119 / 5000\n",
            "w1: [24.73520411] w2: [-22.2939245] bias: [16.51802897] loss: 30.702000607282574\n",
            "Epoch: 3120 / 5000\n",
            "w1: [24.72490271] w2: [-22.29964907] bias: [16.49474544] loss: 30.692579725320964\n",
            "Epoch: 3121 / 5000\n",
            "w1: [24.73327159] w2: [-22.29353545] bias: [16.505617] loss: 30.697788341941273\n",
            "Epoch: 3122 / 5000\n",
            "w1: [24.74202617] w2: [-22.28647686] bias: [16.52045165] loss: 30.705277074125522\n",
            "Epoch: 3123 / 5000\n",
            "w1: [24.7424894] w2: [-22.28747602] bias: [16.5163828] loss: 30.703605436913175\n",
            "Epoch: 3124 / 5000\n",
            "w1: [24.73519484] w2: [-22.29539262] bias: [16.50092068] loss: 30.69599392881546\n",
            "Epoch: 3125 / 5000\n",
            "w1: [24.74809859] w2: [-22.28863656] bias: [16.51717441] loss: 30.704104334133763\n",
            "Epoch: 3126 / 5000\n",
            "w1: [24.72277616] w2: [-22.29589117] bias: [16.48808578] loss: 30.691440310104767\n",
            "Epoch: 3127 / 5000\n",
            "w1: [24.70644243] w2: [-22.30533172] bias: [16.46304173] loss: 30.68311439423343\n",
            "Epoch: 3128 / 5000\n",
            "w1: [24.70678985] w2: [-22.29351185] bias: [16.47397736] loss: 30.687873460265763\n",
            "Epoch: 3129 / 5000\n",
            "w1: [24.72058212] w2: [-22.29321053] bias: [16.4909484] loss: 30.692725216331347\n",
            "Epoch: 3130 / 5000\n",
            "w1: [24.74917567] w2: [-22.29033369] bias: [16.52715297] loss: 30.707510155386053\n",
            "Epoch: 3131 / 5000\n",
            "w1: [24.73817756] w2: [-22.3041769] bias: [16.49747546] loss: 30.693102978286852\n",
            "Epoch: 3132 / 5000\n",
            "w1: [24.74139617] w2: [-22.30383506] bias: [16.50320529] loss: 30.695173372916308\n",
            "Epoch: 3133 / 5000\n",
            "w1: [24.75548231] w2: [-22.30547423] bias: [16.52371472] loss: 30.703050826003544\n",
            "Epoch: 3134 / 5000\n",
            "w1: [24.75669544] w2: [-22.3041755] bias: [16.53577024] loss: 30.708169285905512\n",
            "Epoch: 3135 / 5000\n",
            "w1: [24.75252095] w2: [-22.30883335] bias: [16.53893735] loss: 30.707783476874983\n",
            "Epoch: 3136 / 5000\n",
            "w1: [24.74092179] w2: [-22.31736747] bias: [16.51704003] loss: 30.696516546609995\n",
            "Epoch: 3137 / 5000\n",
            "w1: [24.77549936] w2: [-22.30025282] bias: [16.59070513] loss: 30.73758497365618\n",
            "Epoch: 3138 / 5000\n",
            "w1: [24.79313693] w2: [-22.28585699] bias: [16.63473498] loss: 30.771752503125057\n",
            "Epoch: 3139 / 5000\n",
            "w1: [24.8072576] w2: [-22.28728237] bias: [16.64628279] loss: 30.782494859418104\n",
            "Epoch: 3140 / 5000\n",
            "w1: [24.80541311] w2: [-22.28895705] bias: [16.63390457] loss: 30.77316815521017\n",
            "Epoch: 3141 / 5000\n",
            "w1: [24.78634531] w2: [-22.29798436] bias: [16.60616974] loss: 30.74891173757758\n",
            "Epoch: 3142 / 5000\n",
            "w1: [24.80119621] w2: [-22.28132185] bias: [16.63657915] loss: 30.776437633830422\n",
            "Epoch: 3143 / 5000\n",
            "w1: [24.80668527] w2: [-22.28281437] bias: [16.63846866] loss: 30.778570747728416\n",
            "Epoch: 3144 / 5000\n",
            "w1: [24.80468712] w2: [-22.28758222] bias: [16.6288697] loss: 30.770167318490603\n",
            "Epoch: 3145 / 5000\n",
            "w1: [24.81273787] w2: [-22.28915126] bias: [16.6367667] loss: 30.776827552167422\n",
            "Epoch: 3146 / 5000\n",
            "w1: [24.813218] w2: [-22.28399377] bias: [16.64239969] loss: 30.782511726973645\n",
            "Epoch: 3147 / 5000\n",
            "w1: [24.82783563] w2: [-22.28708102] bias: [16.65973666] loss: 30.797718272939235\n",
            "Epoch: 3148 / 5000\n",
            "w1: [24.8133851] w2: [-22.29559329] bias: [16.62939701] loss: 30.769972221229295\n",
            "Epoch: 3149 / 5000\n",
            "w1: [24.80998784] w2: [-22.30105442] bias: [16.61774569] loss: 30.759974626798325\n",
            "Epoch: 3150 / 5000\n",
            "w1: [24.8177774] w2: [-22.28971552] bias: [16.64643209] loss: 30.78453243518088\n",
            "Epoch: 3151 / 5000\n",
            "w1: [24.81897325] w2: [-22.29346276] bias: [16.65058544] loss: 30.786459417846352\n",
            "Epoch: 3152 / 5000\n",
            "w1: [24.81788605] w2: [-22.29938033] bias: [16.63658396] loss: 30.774574133685856\n",
            "Epoch: 3153 / 5000\n",
            "w1: [24.82746954] w2: [-22.31146183] bias: [16.63543576] loss: 30.772194213845456\n",
            "Epoch: 3154 / 5000\n",
            "w1: [24.80529903] w2: [-22.32809547] bias: [16.59717245] loss: 30.73843451391506\n",
            "Epoch: 3155 / 5000\n",
            "w1: [24.79074179] w2: [-22.34074546] bias: [16.57101292] loss: 30.71856541797463\n",
            "Epoch: 3156 / 5000\n",
            "w1: [24.7895043] w2: [-22.34800926] bias: [16.57321514] loss: 30.717426535290244\n",
            "Epoch: 3157 / 5000\n",
            "w1: [24.78542673] w2: [-22.35808949] bias: [16.55723948] loss: 30.706741248565926\n",
            "Epoch: 3158 / 5000\n",
            "w1: [24.79252292] w2: [-22.36126326] bias: [16.5634174] loss: 30.709665943454905\n",
            "Epoch: 3159 / 5000\n",
            "w1: [24.79972873] w2: [-22.35467656] bias: [16.57600265] loss: 30.718574855479577\n",
            "Epoch: 3160 / 5000\n",
            "w1: [24.80150484] w2: [-22.34989265] bias: [16.57829526] loss: 30.721357376890328\n",
            "Epoch: 3161 / 5000\n",
            "w1: [24.82706978] w2: [-22.33909233] bias: [16.61305161] loss: 30.74888059321885\n",
            "Epoch: 3162 / 5000\n",
            "w1: [24.8356131] w2: [-22.33885551] bias: [16.62220405] loss: 30.75659978794325\n",
            "Epoch: 3163 / 5000\n",
            "w1: [24.84993864] w2: [-22.33729608] bias: [16.63303817] loss: 30.767725500489746\n",
            "Epoch: 3164 / 5000\n",
            "w1: [24.86708683] w2: [-22.34723002] bias: [16.65231364] loss: 30.78243968000657\n",
            "Epoch: 3165 / 5000\n",
            "w1: [24.86331509] w2: [-22.3441121] bias: [16.64887516] loss: 30.779982559082253\n",
            "Epoch: 3166 / 5000\n",
            "w1: [24.84538755] w2: [-22.34636041] bias: [16.61529658] loss: 30.75214784327697\n",
            "Epoch: 3167 / 5000\n",
            "w1: [24.8326785] w2: [-22.35744137] bias: [16.59229925] loss: 30.732348152973923\n",
            "Epoch: 3168 / 5000\n",
            "w1: [24.84492391] w2: [-22.34827089] bias: [16.6155613] loss: 30.751598787841374\n",
            "Epoch: 3169 / 5000\n",
            "w1: [24.83864116] w2: [-22.36471008] bias: [16.58963297] loss: 30.729885396338997\n",
            "Epoch: 3170 / 5000\n",
            "w1: [24.84018193] w2: [-22.36406235] bias: [16.58987486] loss: 30.730517480160927\n",
            "Epoch: 3171 / 5000\n",
            "w1: [24.84430097] w2: [-22.3604326] bias: [16.59383411] loss: 30.734679005005773\n",
            "Epoch: 3172 / 5000\n",
            "w1: [24.84801482] w2: [-22.35054306] bias: [16.606602] loss: 30.746061784137915\n",
            "Epoch: 3173 / 5000\n",
            "w1: [24.86848626] w2: [-22.34365374] bias: [16.64263412] loss: 30.777144510862875\n",
            "Epoch: 3174 / 5000\n",
            "w1: [24.86674235] w2: [-22.34202495] bias: [16.63724454] loss: 30.773444386632733\n",
            "Epoch: 3175 / 5000\n",
            "w1: [24.85965708] w2: [-22.32861068] bias: [16.63552689] loss: 30.774886378450837\n",
            "Epoch: 3176 / 5000\n",
            "w1: [24.8512027] w2: [-22.33842476] bias: [16.61546714] loss: 30.75616635995427\n",
            "Epoch: 3177 / 5000\n",
            "w1: [24.8480351] w2: [-22.33522804] bias: [16.6101778] loss: 30.753101443523622\n",
            "Epoch: 3178 / 5000\n",
            "w1: [24.85177652] w2: [-22.33364075] bias: [16.61257509] loss: 30.756000445294493\n",
            "Epoch: 3179 / 5000\n",
            "w1: [24.81558539] w2: [-22.35529192] bias: [16.54806423] loss: 30.707565252390445\n",
            "Epoch: 3180 / 5000\n",
            "w1: [24.81357764] w2: [-22.34759286] bias: [16.56086256] loss: 30.715357180549695\n",
            "Epoch: 3181 / 5000\n",
            "w1: [24.80360587] w2: [-22.33658289] bias: [16.55538739] loss: 30.71423593752553\n",
            "Epoch: 3182 / 5000\n",
            "w1: [24.80424106] w2: [-22.34163548] bias: [16.54749571] loss: 30.709339112609516\n",
            "Epoch: 3183 / 5000\n",
            "w1: [24.80199758] w2: [-22.33691639] bias: [16.54698898] loss: 30.71005549265029\n",
            "Epoch: 3184 / 5000\n",
            "w1: [24.80337979] w2: [-22.33522374] bias: [16.54867653] loss: 30.71146805542443\n",
            "Epoch: 3185 / 5000\n",
            "w1: [24.79636133] w2: [-22.34541626] bias: [16.52870345] loss: 30.699339462421516\n",
            "Epoch: 3186 / 5000\n",
            "w1: [24.78334907] w2: [-22.3496049] bias: [16.5035037] loss: 30.687755408047273\n",
            "Epoch: 3187 / 5000\n",
            "w1: [24.78612384] w2: [-22.3476275] bias: [16.50904202] loss: 30.690353884754703\n",
            "Epoch: 3188 / 5000\n",
            "w1: [24.79158349] w2: [-22.35618649] bias: [16.52619013] loss: 30.69513701047979\n",
            "Epoch: 3189 / 5000\n",
            "w1: [24.79550327] w2: [-22.34930161] bias: [16.53493615] loss: 30.70079230219907\n",
            "Epoch: 3190 / 5000\n",
            "w1: [24.78490542] w2: [-22.35624226] bias: [16.51669293] loss: 30.690916962095393\n",
            "Epoch: 3191 / 5000\n",
            "w1: [24.79824027] w2: [-22.35687793] bias: [16.53943252] loss: 30.701059555339498\n",
            "Epoch: 3192 / 5000\n",
            "w1: [24.78434301] w2: [-22.3489561] bias: [16.51806601] loss: 30.693111162844584\n",
            "Epoch: 3193 / 5000\n",
            "w1: [24.77790975] w2: [-22.36099636] bias: [16.49886984] loss: 30.683244167691996\n",
            "Epoch: 3194 / 5000\n",
            "w1: [24.7576314] w2: [-22.35854735] bias: [16.46917923] loss: 30.674648786211993\n",
            "Epoch: 3195 / 5000\n",
            "w1: [24.7640411] w2: [-22.36464268] bias: [16.47375599] loss: 30.674705287090514\n",
            "Epoch: 3196 / 5000\n",
            "w1: [24.75058238] w2: [-22.37624185] bias: [16.45086663] loss: 30.66734271954039\n",
            "Epoch: 3197 / 5000\n",
            "w1: [24.74354868] w2: [-22.38617668] bias: [16.4401918] loss: 30.663902350792323\n",
            "Epoch: 3198 / 5000\n",
            "w1: [24.73185611] w2: [-22.39488729] bias: [16.41571261] loss: 30.660161660092054\n",
            "Epoch: 3199 / 5000\n",
            "w1: [24.71529951] w2: [-22.40778982] bias: [16.38775091] loss: 30.65851805367481\n",
            "Epoch: 3200 / 5000\n",
            "w1: [24.71193015] w2: [-22.41087245] bias: [16.38175465] loss: 30.658535812919805\n",
            "Epoch: 3201 / 5000\n",
            "w1: [24.68896281] w2: [-22.42546728] bias: [16.34410795] loss: 30.66282429349432\n",
            "Epoch: 3202 / 5000\n",
            "w1: [24.66902314] w2: [-22.4381463] bias: [16.31481027] loss: 30.670556647215015\n",
            "Epoch: 3203 / 5000\n",
            "w1: [24.68269289] w2: [-22.44065597] bias: [16.34420111] loss: 30.662538580303682\n",
            "Epoch: 3204 / 5000\n",
            "w1: [24.67180996] w2: [-22.44580531] bias: [16.3258469] loss: 30.667236125102683\n",
            "Epoch: 3205 / 5000\n",
            "w1: [24.68784587] w2: [-22.4384343] bias: [16.35140947] loss: 30.66093004392382\n",
            "Epoch: 3206 / 5000\n",
            "w1: [24.68792915] w2: [-22.4413441] bias: [16.3432724] loss: 30.661722829687047\n",
            "Epoch: 3207 / 5000\n",
            "w1: [24.70422309] w2: [-22.43282248] bias: [16.37003596] loss: 30.657399104933468\n",
            "Epoch: 3208 / 5000\n",
            "w1: [24.72187369] w2: [-22.43246631] bias: [16.38611304] loss: 30.654787165088102\n",
            "Epoch: 3209 / 5000\n",
            "w1: [24.73229548] w2: [-22.40318793] bias: [16.4217977] loss: 30.659369309874588\n",
            "Epoch: 3210 / 5000\n",
            "w1: [24.7405206] w2: [-22.40086845] bias: [16.43196994] loss: 30.66042955313149\n",
            "Epoch: 3211 / 5000\n",
            "w1: [24.74228571] w2: [-22.40603067] bias: [16.45054886] loss: 30.66202772285119\n",
            "Epoch: 3212 / 5000\n",
            "w1: [24.76440399] w2: [-22.38883055] bias: [16.49882623] loss: 30.676309987741135\n",
            "Epoch: 3213 / 5000\n",
            "w1: [24.75903338] w2: [-22.39732188] bias: [16.4820302] loss: 30.669948063546208\n",
            "Epoch: 3214 / 5000\n",
            "w1: [24.78658655] w2: [-22.3907322] bias: [16.51921352] loss: 30.683844848649812\n",
            "Epoch: 3215 / 5000\n",
            "w1: [24.80310075] w2: [-22.3871798] bias: [16.54255459] loss: 30.695265787462706\n",
            "Epoch: 3216 / 5000\n",
            "w1: [24.79195535] w2: [-22.39701315] bias: [16.51441135] loss: 30.681210330017073\n",
            "Epoch: 3217 / 5000\n",
            "w1: [24.79763181] w2: [-22.39051753] bias: [16.52838554] loss: 30.68824997298096\n",
            "Epoch: 3218 / 5000\n",
            "w1: [24.80970759] w2: [-22.38242815] bias: [16.54316791] loss: 30.697545940743385\n",
            "Epoch: 3219 / 5000\n",
            "w1: [24.82738816] w2: [-22.3859296] bias: [16.57448811] loss: 30.71372006022518\n",
            "Epoch: 3220 / 5000\n",
            "w1: [24.81459184] w2: [-22.38882044] bias: [16.55305147] loss: 30.700832687678634\n",
            "Epoch: 3221 / 5000\n",
            "w1: [24.81274543] w2: [-22.3929883] bias: [16.55480119] loss: 30.70026861587957\n",
            "Epoch: 3222 / 5000\n",
            "w1: [24.81262303] w2: [-22.40210212] bias: [16.54337823] loss: 30.693026573920886\n",
            "Epoch: 3223 / 5000\n",
            "w1: [24.80502139] w2: [-22.41538473] bias: [16.52529207] loss: 30.681941625041123\n",
            "Epoch: 3224 / 5000\n",
            "w1: [24.81287898] w2: [-22.41541269] bias: [16.53178086] loss: 30.685159106709165\n",
            "Epoch: 3225 / 5000\n",
            "w1: [24.82171196] w2: [-22.41556676] bias: [16.53636408] loss: 30.68791857850147\n",
            "Epoch: 3226 / 5000\n",
            "w1: [24.83610893] w2: [-22.42136046] bias: [16.54634213] loss: 30.692457779098792\n",
            "Epoch: 3227 / 5000\n",
            "w1: [24.83127403] w2: [-22.42493767] bias: [16.5307197] loss: 30.68449472570325\n",
            "Epoch: 3228 / 5000\n",
            "w1: [24.83749113] w2: [-22.42969421] bias: [16.52726726] loss: 30.682696693184432\n",
            "Epoch: 3229 / 5000\n",
            "w1: [24.82682123] w2: [-22.43668322] bias: [16.50150608] loss: 30.67083107267783\n",
            "Epoch: 3230 / 5000\n",
            "w1: [24.83282553] w2: [-22.43048289] bias: [16.51293213] loss: 30.67665153510371\n",
            "Epoch: 3231 / 5000\n",
            "w1: [24.83905151] w2: [-22.41867862] bias: [16.5365794] loss: 30.689359665338674\n",
            "Epoch: 3232 / 5000\n",
            "w1: [24.83458192] w2: [-22.42884674] bias: [16.53362125] loss: 30.685086033563504\n",
            "Epoch: 3233 / 5000\n",
            "w1: [24.83329775] w2: [-22.43863771] bias: [16.51866173] loss: 30.67688007786214\n",
            "Epoch: 3234 / 5000\n",
            "w1: [24.81938064] w2: [-22.45357301] bias: [16.49063217] loss: 30.66339310164164\n",
            "Epoch: 3235 / 5000\n",
            "w1: [24.80045061] w2: [-22.45879334] bias: [16.46283717] loss: 30.654831746710908\n",
            "Epoch: 3236 / 5000\n",
            "w1: [24.80175051] w2: [-22.46548971] bias: [16.45716379] loss: 30.652499609686167\n",
            "Epoch: 3237 / 5000\n",
            "w1: [24.80105484] w2: [-22.46125541] bias: [16.46187215] loss: 30.654191409881324\n",
            "Epoch: 3238 / 5000\n",
            "w1: [24.81806982] w2: [-22.45332413] bias: [16.48764576] loss: 30.66253013692409\n",
            "Epoch: 3239 / 5000\n",
            "w1: [24.84187269] w2: [-22.44895029] bias: [16.51215696] loss: 30.673001157928624\n",
            "Epoch: 3240 / 5000\n",
            "w1: [24.84029284] w2: [-22.45124884] bias: [16.50877381] loss: 30.6711522850421\n",
            "Epoch: 3241 / 5000\n",
            "w1: [24.83262903] w2: [-22.45482342] bias: [16.50784811] loss: 30.669378673842374\n",
            "Epoch: 3242 / 5000\n",
            "w1: [24.83416773] w2: [-22.45569628] bias: [16.50620447] loss: 30.668768195071145\n",
            "Epoch: 3243 / 5000\n",
            "w1: [24.82459957] w2: [-22.45153161] bias: [16.49523225] loss: 30.665494136824794\n",
            "Epoch: 3244 / 5000\n",
            "w1: [24.82140118] w2: [-22.45466087] bias: [16.48786696] loss: 30.66250028959385\n",
            "Epoch: 3245 / 5000\n",
            "w1: [24.81685144] w2: [-22.45662302] bias: [16.4762551] loss: 30.658790277007018\n",
            "Epoch: 3246 / 5000\n",
            "w1: [24.8256852] w2: [-22.44710933] bias: [16.49293233] loss: 30.66581317846515\n",
            "Epoch: 3247 / 5000\n",
            "w1: [24.81224168] w2: [-22.45346581] bias: [16.47746907] loss: 30.659533134089816\n",
            "Epoch: 3248 / 5000\n",
            "w1: [24.80569464] w2: [-22.4385292] bias: [16.48601425] loss: 30.664475403567096\n",
            "Epoch: 3249 / 5000\n",
            "w1: [24.80115823] w2: [-22.44166263] bias: [16.46985465] loss: 30.659614571704907\n",
            "Epoch: 3250 / 5000\n",
            "w1: [24.78085205] w2: [-22.45984639] bias: [16.42551367] loss: 30.64889942898445\n",
            "Epoch: 3251 / 5000\n",
            "w1: [24.79205668] w2: [-22.45719859] bias: [16.44121169] loss: 30.651171050769587\n",
            "Epoch: 3252 / 5000\n",
            "w1: [24.79459449] w2: [-22.45455308] bias: [16.44406386] loss: 30.65206024673736\n",
            "Epoch: 3253 / 5000\n",
            "w1: [24.78359856] w2: [-22.45486314] bias: [16.42456126] loss: 30.649480491930188\n",
            "Epoch: 3254 / 5000\n",
            "w1: [24.78450986] w2: [-22.44803999] bias: [16.44222848] loss: 30.65296339821404\n",
            "Epoch: 3255 / 5000\n",
            "w1: [24.77996659] w2: [-22.44642096] bias: [16.43687999] loss: 30.652512074194963\n",
            "Epoch: 3256 / 5000\n",
            "w1: [24.7800171] w2: [-22.44585517] bias: [16.43927667] loss: 30.65294918978506\n",
            "Epoch: 3257 / 5000\n",
            "w1: [24.78512072] w2: [-22.44389458] bias: [16.44470574] loss: 30.654062429345313\n",
            "Epoch: 3258 / 5000\n",
            "w1: [24.79279769] w2: [-22.44116933] bias: [16.46617237] loss: 30.658677332215795\n",
            "Epoch: 3259 / 5000\n",
            "w1: [24.81421588] w2: [-22.44056746] bias: [16.48935762] loss: 30.66543784423092\n",
            "Epoch: 3260 / 5000\n",
            "w1: [24.81228417] w2: [-22.44541793] bias: [16.48074184] loss: 30.661982839275506\n",
            "Epoch: 3261 / 5000\n",
            "w1: [24.80203143] w2: [-22.45529214] bias: [16.46127912] loss: 30.655180506428703\n",
            "Epoch: 3262 / 5000\n",
            "w1: [24.79875555] w2: [-22.4601471] bias: [16.44767875] loss: 30.651692630237154\n",
            "Epoch: 3263 / 5000\n",
            "w1: [24.79218149] w2: [-22.465053] bias: [16.43842416] loss: 30.649436650480244\n",
            "Epoch: 3264 / 5000\n",
            "w1: [24.79510782] w2: [-22.47296325] bias: [16.43277336] loss: 30.647306936056538\n",
            "Epoch: 3265 / 5000\n",
            "w1: [24.80141645] w2: [-22.47331532] bias: [16.43609141] loss: 30.64759395283294\n",
            "Epoch: 3266 / 5000\n",
            "w1: [24.81219213] w2: [-22.47491078] bias: [16.44566474] loss: 30.648781733084032\n",
            "Epoch: 3267 / 5000\n",
            "w1: [24.8119278] w2: [-22.47300807] bias: [16.45102149] loss: 30.650080718086166\n",
            "Epoch: 3268 / 5000\n",
            "w1: [24.81354361] w2: [-22.47950201] bias: [16.44499521] loss: 30.647875249208642\n",
            "Epoch: 3269 / 5000\n",
            "w1: [24.808365] w2: [-22.47470934] bias: [16.44000133] loss: 30.6478811535968\n",
            "Epoch: 3270 / 5000\n",
            "w1: [24.79176559] w2: [-22.49132717] bias: [16.4032235] loss: 30.64188370740251\n",
            "Epoch: 3271 / 5000\n",
            "w1: [24.77073878] w2: [-22.49994915] bias: [16.36745679] loss: 30.642299415025672\n",
            "Epoch: 3272 / 5000\n",
            "w1: [24.77760741] w2: [-22.49452513] bias: [16.37408794] loss: 30.64198991774278\n",
            "Epoch: 3273 / 5000\n",
            "w1: [24.77813052] w2: [-22.49865221] bias: [16.36756347] loss: 30.641626699179\n",
            "Epoch: 3274 / 5000\n",
            "w1: [24.77958366] w2: [-22.50196599] bias: [16.36438455] loss: 30.64121806470382\n",
            "Epoch: 3275 / 5000\n",
            "w1: [24.77358251] w2: [-22.49531679] bias: [16.36199906] loss: 30.642703924112077\n",
            "Epoch: 3276 / 5000\n",
            "w1: [24.75870786] w2: [-22.5098154] bias: [16.32790927] loss: 30.646548400159034\n",
            "Epoch: 3277 / 5000\n",
            "w1: [24.73114155] w2: [-22.52271161] bias: [16.28470149] loss: 30.659770181530952\n",
            "Epoch: 3278 / 5000\n",
            "w1: [24.74231] w2: [-22.52354713] bias: [16.29729336] loss: 30.654245500947948\n",
            "Epoch: 3279 / 5000\n",
            "w1: [24.71697701] w2: [-22.53015493] bias: [16.25771399] loss: 30.67106775708104\n",
            "Epoch: 3280 / 5000\n",
            "w1: [24.73917752] w2: [-22.51206109] bias: [16.29994461] loss: 30.654916725327062\n",
            "Epoch: 3281 / 5000\n",
            "w1: [24.74790248] w2: [-22.48591508] bias: [16.33579716] loss: 30.649203692839695\n",
            "Epoch: 3282 / 5000\n",
            "w1: [24.75819314] w2: [-22.47763937] bias: [16.35337418] loss: 30.646888369365215\n",
            "Epoch: 3283 / 5000\n",
            "w1: [24.7556297] w2: [-22.48254378] bias: [16.3483071] loss: 30.64712507136615\n",
            "Epoch: 3284 / 5000\n",
            "w1: [24.76074996] w2: [-22.48324876] bias: [16.35691486] loss: 30.645766320208555\n",
            "Epoch: 3285 / 5000\n",
            "w1: [24.77314842] w2: [-22.4820173] bias: [16.3661379] loss: 30.644049199372326\n",
            "Epoch: 3286 / 5000\n",
            "w1: [24.76522761] w2: [-22.49231982] bias: [16.34313694] loss: 30.645331054170498\n",
            "Epoch: 3287 / 5000\n",
            "w1: [24.78521048] w2: [-22.47667348] bias: [16.37461783] loss: 30.643380899119084\n",
            "Epoch: 3288 / 5000\n",
            "w1: [24.81203259] w2: [-22.47236683] bias: [16.41272258] loss: 30.644501715093032\n",
            "Epoch: 3289 / 5000\n",
            "w1: [24.80957378] w2: [-22.47635675] bias: [16.41694303] loss: 30.64443915696231\n",
            "Epoch: 3290 / 5000\n",
            "w1: [24.81467165] w2: [-22.45522573] bias: [16.43455467] loss: 30.650271252096594\n",
            "Epoch: 3291 / 5000\n",
            "w1: [24.82912675] w2: [-22.4516338] bias: [16.4566916] loss: 30.655481959161058\n",
            "Epoch: 3292 / 5000\n",
            "w1: [24.82233267] w2: [-22.45799245] bias: [16.43873267] loss: 30.650520694566975\n",
            "Epoch: 3293 / 5000\n",
            "w1: [24.829738] w2: [-22.46025443] bias: [16.44462304] loss: 30.65130911367704\n",
            "Epoch: 3294 / 5000\n",
            "w1: [24.82057657] w2: [-22.45424555] bias: [16.43714151] loss: 30.650885680160588\n",
            "Epoch: 3295 / 5000\n",
            "w1: [24.82195865] w2: [-22.46087403] bias: [16.43706625] loss: 30.649717142999663\n",
            "Epoch: 3296 / 5000\n",
            "w1: [24.84559795] w2: [-22.45695273] bias: [16.46886561] loss: 30.658102617376414\n",
            "Epoch: 3297 / 5000\n",
            "w1: [24.84410813] w2: [-22.45103264] bias: [16.46713579] loss: 30.65875843684571\n",
            "Epoch: 3298 / 5000\n",
            "w1: [24.8404375] w2: [-22.44643093] bias: [16.46486926] loss: 30.658912711525534\n",
            "Epoch: 3299 / 5000\n",
            "w1: [24.84217669] w2: [-22.44537178] bias: [16.46673803] loss: 30.65969839250368\n",
            "Epoch: 3300 / 5000\n",
            "w1: [24.82287118] w2: [-22.45866078] bias: [16.42766324] loss: 30.648514030900582\n",
            "Epoch: 3301 / 5000\n",
            "w1: [24.82196485] w2: [-22.45662841] bias: [16.42603496] loss: 30.64860661932796\n",
            "Epoch: 3302 / 5000\n",
            "w1: [24.85446467] w2: [-22.44815716] bias: [16.47034837] loss: 30.660782730698504\n",
            "Epoch: 3303 / 5000\n",
            "w1: [24.85516468] w2: [-22.43841772] bias: [16.47311025] loss: 30.663661320491507\n",
            "Epoch: 3304 / 5000\n",
            "w1: [24.8727898] w2: [-22.42885377] bias: [16.51051758] loss: 30.680367201998504\n",
            "Epoch: 3305 / 5000\n",
            "w1: [24.88498518] w2: [-22.432609] bias: [16.52915302] loss: 30.688831831788107\n",
            "Epoch: 3306 / 5000\n",
            "w1: [24.89469424] w2: [-22.43088627] bias: [16.56166111] loss: 30.706514659355534\n",
            "Epoch: 3307 / 5000\n",
            "w1: [24.89917142] w2: [-22.42842524] bias: [16.55969411] loss: 30.70699284245441\n",
            "Epoch: 3308 / 5000\n",
            "w1: [24.88773834] w2: [-22.43407706] bias: [16.53392022] loss: 30.690996364045922\n",
            "Epoch: 3309 / 5000\n",
            "w1: [24.87905863] w2: [-22.4325309] bias: [16.52193955] loss: 30.684917674170556\n",
            "Epoch: 3310 / 5000\n",
            "w1: [24.8814618] w2: [-22.43679889] bias: [16.52245343] loss: 30.68439048787251\n",
            "Epoch: 3311 / 5000\n",
            "w1: [24.91448116] w2: [-22.43137861] bias: [16.58247922] loss: 30.72176704394471\n",
            "Epoch: 3312 / 5000\n",
            "w1: [24.91513529] w2: [-22.43538352] bias: [16.58546713] loss: 30.722467449836078\n",
            "Epoch: 3313 / 5000\n",
            "w1: [24.90790293] w2: [-22.43027456] bias: [16.58105692] loss: 30.719871296572027\n",
            "Epoch: 3314 / 5000\n",
            "w1: [24.88637891] w2: [-22.44190433] bias: [16.54740569] loss: 30.69502037272177\n",
            "Epoch: 3315 / 5000\n",
            "w1: [24.87989508] w2: [-22.44625942] bias: [16.53515344] loss: 30.687298482670567\n",
            "Epoch: 3316 / 5000\n",
            "w1: [24.89667959] w2: [-22.44045983] bias: [16.55326641] loss: 30.699968725071585\n",
            "Epoch: 3317 / 5000\n",
            "w1: [24.88672536] w2: [-22.44429468] bias: [16.53221987] loss: 30.68746951237955\n",
            "Epoch: 3318 / 5000\n",
            "w1: [24.8902734] w2: [-22.43777072] bias: [16.53992527] loss: 30.693190709039513\n",
            "Epoch: 3319 / 5000\n",
            "w1: [24.88566983] w2: [-22.44223942] bias: [16.54579121] loss: 30.694055393343955\n",
            "Epoch: 3320 / 5000\n",
            "w1: [24.88207405] w2: [-22.43871527] bias: [16.54201103] loss: 30.69265453076261\n",
            "Epoch: 3321 / 5000\n",
            "w1: [24.87926662] w2: [-22.43507331] bias: [16.5337289] loss: 30.68942099014097\n",
            "Epoch: 3322 / 5000\n",
            "w1: [24.87007986] w2: [-22.44852233] bias: [16.52172403] loss: 30.679773622849385\n",
            "Epoch: 3323 / 5000\n",
            "w1: [24.87168366] w2: [-22.45171156] bias: [16.52287222] loss: 30.679661619918985\n",
            "Epoch: 3324 / 5000\n",
            "w1: [24.84917137] w2: [-22.4683814] bias: [16.47683446] loss: 30.658158645698435\n",
            "Epoch: 3325 / 5000\n",
            "w1: [24.84966326] w2: [-22.4638335] bias: [16.48323346] loss: 30.66096818587475\n",
            "Epoch: 3326 / 5000\n",
            "w1: [24.88206369] w2: [-22.45662977] bias: [16.54467052] loss: 30.689245091270454\n",
            "Epoch: 3327 / 5000\n",
            "w1: [24.91233464] w2: [-22.43922165] bias: [16.61456764] loss: 30.73846737184004\n",
            "Epoch: 3328 / 5000\n",
            "w1: [24.9281878] w2: [-22.42338011] bias: [16.6395905] loss: 30.764739023002832\n",
            "Epoch: 3329 / 5000\n",
            "w1: [24.93563159] w2: [-22.43071601] bias: [16.64300662] loss: 30.766871021810406\n",
            "Epoch: 3330 / 5000\n",
            "w1: [24.93678337] w2: [-22.43483244] bias: [16.64643082] loss: 30.76830585286805\n",
            "Epoch: 3331 / 5000\n",
            "w1: [24.91646567] w2: [-22.44094937] bias: [16.61393046] loss: 30.73853631708225\n",
            "Epoch: 3332 / 5000\n",
            "w1: [24.92244096] w2: [-22.43979758] bias: [16.62945921] loss: 30.750680180161346\n",
            "Epoch: 3333 / 5000\n",
            "w1: [24.8963628] w2: [-22.45591981] bias: [16.57967262] loss: 30.709385425403408\n",
            "Epoch: 3334 / 5000\n",
            "w1: [24.9165317] w2: [-22.45191272] bias: [16.61650028] loss: 30.73677871794865\n",
            "Epoch: 3335 / 5000\n",
            "w1: [24.91754874] w2: [-22.45701929] bias: [16.60852674] loss: 30.73042445369447\n",
            "Epoch: 3336 / 5000\n",
            "w1: [24.91703648] w2: [-22.46017684] bias: [16.60434309] loss: 30.72676898201504\n",
            "Epoch: 3337 / 5000\n",
            "w1: [24.90775865] w2: [-22.47373135] bias: [16.57639315] loss: 30.70482999425144\n",
            "Epoch: 3338 / 5000\n",
            "w1: [24.92631687] w2: [-22.47078116] bias: [16.60573066] loss: 30.726581849368262\n",
            "Epoch: 3339 / 5000\n",
            "w1: [24.92164461] w2: [-22.47576634] bias: [16.58731831] loss: 30.713121186247804\n",
            "Epoch: 3340 / 5000\n",
            "w1: [24.92036823] w2: [-22.48130822] bias: [16.57550985] loss: 30.704697715153888\n",
            "Epoch: 3341 / 5000\n",
            "w1: [24.91433373] w2: [-22.48757471] bias: [16.57574674] loss: 30.701905267229474\n",
            "Epoch: 3342 / 5000\n",
            "w1: [24.91721735] w2: [-22.47248101] bias: [16.58772193] loss: 30.71336448015972\n",
            "Epoch: 3343 / 5000\n",
            "w1: [24.91103053] w2: [-22.48429118] bias: [16.57285819] loss: 30.700650227950582\n",
            "Epoch: 3344 / 5000\n",
            "w1: [24.89919257] w2: [-22.4943157] bias: [16.54670058] loss: 30.683138676793668\n",
            "Epoch: 3345 / 5000\n",
            "w1: [24.91639537] w2: [-22.49381892] bias: [16.56279647] loss: 30.693849505360244\n",
            "Epoch: 3346 / 5000\n",
            "w1: [24.88711737] w2: [-22.50517498] bias: [16.52209834] loss: 30.668512857475534\n",
            "Epoch: 3347 / 5000\n",
            "w1: [24.87257601] w2: [-22.50426754] bias: [16.51020615] loss: 30.662805652605147\n",
            "Epoch: 3348 / 5000\n",
            "w1: [24.87829026] w2: [-22.50874725] bias: [16.50665731] loss: 30.6611240885147\n",
            "Epoch: 3349 / 5000\n",
            "w1: [24.88011914] w2: [-22.50801823] bias: [16.50880186] loss: 30.662206612906584\n",
            "Epoch: 3350 / 5000\n",
            "w1: [24.86685886] w2: [-22.52229735] bias: [16.47795343] loss: 30.64867458127684\n",
            "Epoch: 3351 / 5000\n",
            "w1: [24.85616106] w2: [-22.53109123] bias: [16.45866403] loss: 30.641981525713444\n",
            "Epoch: 3352 / 5000\n",
            "w1: [24.85825332] w2: [-22.53249456] bias: [16.46093028] loss: 30.64227275070514\n",
            "Epoch: 3353 / 5000\n",
            "w1: [24.86096271] w2: [-22.54070244] bias: [16.45217658] loss: 30.639053428744273\n",
            "Epoch: 3354 / 5000\n",
            "w1: [24.86207981] w2: [-22.54475649] bias: [16.45124511] loss: 30.638187528008007\n",
            "Epoch: 3355 / 5000\n",
            "w1: [24.8614445] w2: [-22.54286371] bias: [16.44914291] loss: 30.63809488066051\n",
            "Epoch: 3356 / 5000\n",
            "w1: [24.86835938] w2: [-22.55138847] bias: [16.45304921] loss: 30.637512719917822\n",
            "Epoch: 3357 / 5000\n",
            "w1: [24.86434994] w2: [-22.56203176] bias: [16.43709654] loss: 30.632820111140166\n",
            "Epoch: 3358 / 5000\n",
            "w1: [24.85763197] w2: [-22.56824103] bias: [16.41663604] loss: 30.629246317295966\n",
            "Epoch: 3359 / 5000\n",
            "w1: [24.86202557] w2: [-22.56255799] bias: [16.42716447] loss: 30.631283842687143\n",
            "Epoch: 3360 / 5000\n",
            "w1: [24.87111888] w2: [-22.56620761] bias: [16.43286189] loss: 30.631466856311697\n",
            "Epoch: 3361 / 5000\n",
            "w1: [24.86238687] w2: [-22.56758444] bias: [16.41749703] loss: 30.629306766921964\n",
            "Epoch: 3362 / 5000\n",
            "w1: [24.88829723] w2: [-22.56478118] bias: [16.45110649] loss: 30.635232031750615\n",
            "Epoch: 3363 / 5000\n",
            "w1: [24.89464456] w2: [-22.55939948] bias: [16.46447524] loss: 30.639487360380627\n",
            "Epoch: 3364 / 5000\n",
            "w1: [24.87944873] w2: [-22.57082108] bias: [16.43241274] loss: 30.630643466684777\n",
            "Epoch: 3365 / 5000\n",
            "w1: [24.85351166] w2: [-22.57545529] bias: [16.3960357] loss: 30.626727529425704\n",
            "Epoch: 3366 / 5000\n",
            "w1: [24.85205317] w2: [-22.5717298] bias: [16.39890956] loss: 30.627465159599044\n",
            "Epoch: 3367 / 5000\n",
            "w1: [24.8580537] w2: [-22.55890302] bias: [16.41078475] loss: 30.62995734881972\n",
            "Epoch: 3368 / 5000\n",
            "w1: [24.86235476] w2: [-22.56285775] bias: [16.41057989] loss: 30.62923288789657\n",
            "Epoch: 3369 / 5000\n",
            "w1: [24.85954838] w2: [-22.55884364] bias: [16.40444102] loss: 30.629298626886552\n",
            "Epoch: 3370 / 5000\n",
            "w1: [24.86900975] w2: [-22.54548213] bias: [16.42993904] loss: 30.63431889943984\n",
            "Epoch: 3371 / 5000\n",
            "w1: [24.88270415] w2: [-22.54333761] bias: [16.45636497] loss: 30.640036283935025\n",
            "Epoch: 3372 / 5000\n",
            "w1: [24.87252614] w2: [-22.5403563] bias: [16.44356267] loss: 30.637607572034725\n",
            "Epoch: 3373 / 5000\n",
            "w1: [24.89166695] w2: [-22.52338809] bias: [16.48018697] loss: 30.650604903330567\n",
            "Epoch: 3374 / 5000\n",
            "w1: [24.8830798] w2: [-22.528721] bias: [16.46138805] loss: 30.6439495493089\n",
            "Epoch: 3375 / 5000\n",
            "w1: [24.87769855] w2: [-22.53626458] bias: [16.45526212] loss: 30.640904931501233\n",
            "Epoch: 3376 / 5000\n",
            "w1: [24.87506722] w2: [-22.53895253] bias: [16.45017878] loss: 30.639241857949155\n",
            "Epoch: 3377 / 5000\n",
            "w1: [24.89374294] w2: [-22.52765368] bias: [16.48530886] loss: 30.651430667835868\n",
            "Epoch: 3378 / 5000\n",
            "w1: [24.91166467] w2: [-22.52838767] bias: [16.50915637] loss: 30.661044298436696\n",
            "Epoch: 3379 / 5000\n",
            "w1: [24.91421471] w2: [-22.52780275] bias: [16.51495348] loss: 30.663674271503588\n",
            "Epoch: 3380 / 5000\n",
            "w1: [24.91497098] w2: [-22.52549446] bias: [16.52060747] loss: 30.666532822998835\n",
            "Epoch: 3381 / 5000\n",
            "w1: [24.90224937] w2: [-22.5358159] bias: [16.50052626] loss: 30.655365098405813\n",
            "Epoch: 3382 / 5000\n",
            "w1: [24.90740682] w2: [-22.54195187] bias: [16.50704742] loss: 30.656810114441544\n",
            "Epoch: 3383 / 5000\n",
            "w1: [24.8977467] w2: [-22.54421289] bias: [16.48324202] loss: 30.647720173446054\n",
            "Epoch: 3384 / 5000\n",
            "w1: [24.90637213] w2: [-22.53800833] bias: [16.50089067] loss: 30.655405725217584\n",
            "Epoch: 3385 / 5000\n",
            "w1: [24.89497252] w2: [-22.54651379] bias: [16.48123999] loss: 30.646483180774194\n",
            "Epoch: 3386 / 5000\n",
            "w1: [24.9139394] w2: [-22.54074907] bias: [16.51981018] loss: 30.66256056077034\n",
            "Epoch: 3387 / 5000\n",
            "w1: [24.91288341] w2: [-22.55613039] bias: [16.50799356] loss: 30.65460406560554\n",
            "Epoch: 3388 / 5000\n",
            "w1: [24.91388433] w2: [-22.56296367] bias: [16.49602021] loss: 30.649144010458482\n",
            "Epoch: 3389 / 5000\n",
            "w1: [24.90815765] w2: [-22.57400581] bias: [16.47407705] loss: 30.639924909206123\n",
            "Epoch: 3390 / 5000\n",
            "w1: [24.90715797] w2: [-22.57647828] bias: [16.47083026] loss: 30.638530696233406\n",
            "Epoch: 3391 / 5000\n",
            "w1: [24.91881529] w2: [-22.57343711] bias: [16.4914511] loss: 30.645918162156544\n",
            "Epoch: 3392 / 5000\n",
            "w1: [24.93106616] w2: [-22.56941828] bias: [16.50536892] loss: 30.652650887404423\n",
            "Epoch: 3393 / 5000\n",
            "w1: [24.93171123] w2: [-22.56733426] bias: [16.51684115] loss: 30.65747349297827\n",
            "Epoch: 3394 / 5000\n",
            "w1: [24.93139616] w2: [-22.56200391] bias: [16.52262934] loss: 30.660927109368693\n",
            "Epoch: 3395 / 5000\n",
            "w1: [24.9275845] w2: [-22.56281294] bias: [16.51780171] loss: 30.658376815010875\n",
            "Epoch: 3396 / 5000\n",
            "w1: [24.93432328] w2: [-22.55943109] bias: [16.53251436] loss: 30.66599751867148\n",
            "Epoch: 3397 / 5000\n",
            "w1: [24.95570525] w2: [-22.54484465] bias: [16.5739119] loss: 30.693274930049903\n",
            "Epoch: 3398 / 5000\n",
            "w1: [24.95602436] w2: [-22.55016898] bias: [16.56300174] loss: 30.68616066388605\n",
            "Epoch: 3399 / 5000\n",
            "w1: [24.94611278] w2: [-22.55577314] bias: [16.56088212] loss: 30.68182993050169\n",
            "Epoch: 3400 / 5000\n",
            "w1: [24.92563239] w2: [-22.56735318] bias: [16.51956421] loss: 30.657801795723245\n",
            "Epoch: 3401 / 5000\n",
            "w1: [24.93477465] w2: [-22.56932887] bias: [16.5279457] loss: 30.661822751511984\n",
            "Epoch: 3402 / 5000\n",
            "w1: [24.94293418] w2: [-22.57969747] bias: [16.52621618] loss: 30.659781599733307\n",
            "Epoch: 3403 / 5000\n",
            "w1: [24.92841957] w2: [-22.59301728] bias: [16.49507105] loss: 30.643882473459527\n",
            "Epoch: 3404 / 5000\n",
            "w1: [24.94609623] w2: [-22.57988355] bias: [16.53527644] loss: 30.663975406188378\n",
            "Epoch: 3405 / 5000\n",
            "w1: [24.97627565] w2: [-22.57581031] bias: [16.57017904] loss: 30.686975943731742\n",
            "Epoch: 3406 / 5000\n",
            "w1: [24.96111293] w2: [-22.58391534] bias: [16.54431573] loss: 30.669302379262394\n",
            "Epoch: 3407 / 5000\n",
            "w1: [24.96156145] w2: [-22.57141117] bias: [16.54859075] loss: 30.67449928171802\n",
            "Epoch: 3408 / 5000\n",
            "w1: [24.93467143] w2: [-22.58629841] bias: [16.49860197] loss: 30.647021633037085\n",
            "Epoch: 3409 / 5000\n",
            "w1: [24.94722391] w2: [-22.58775223] bias: [16.51389831] loss: 30.653602619427538\n",
            "Epoch: 3410 / 5000\n",
            "w1: [24.94751596] w2: [-22.59539738] bias: [16.50577408] loss: 30.648920340319247\n",
            "Epoch: 3411 / 5000\n",
            "w1: [24.95678225] w2: [-22.58535275] bias: [16.52836426] loss: 30.66123787274999\n",
            "Epoch: 3412 / 5000\n",
            "w1: [24.95665139] w2: [-22.58264797] bias: [16.53277701] loss: 30.663755252500632\n",
            "Epoch: 3413 / 5000\n",
            "w1: [24.94597908] w2: [-22.59108199] bias: [16.51133874] loss: 30.651747710628005\n",
            "Epoch: 3414 / 5000\n",
            "w1: [24.95395964] w2: [-22.58970653] bias: [16.52126437] loss: 30.656904048576877\n",
            "Epoch: 3415 / 5000\n",
            "w1: [24.92843107] w2: [-22.59560103] bias: [16.48281273] loss: 30.639555369136342\n",
            "Epoch: 3416 / 5000\n",
            "w1: [24.90469221] w2: [-22.60813955] bias: [16.44802522] loss: 30.627600454008693\n",
            "Epoch: 3417 / 5000\n",
            "w1: [24.91632147] w2: [-22.60523134] bias: [16.46599076] loss: 30.63244870247865\n",
            "Epoch: 3418 / 5000\n",
            "w1: [24.90978641] w2: [-22.60189168] bias: [16.45699629] loss: 30.63067545638212\n",
            "Epoch: 3419 / 5000\n",
            "w1: [24.90327513] w2: [-22.6079115] bias: [16.45893883] loss: 30.62985277084744\n",
            "Epoch: 3420 / 5000\n",
            "w1: [24.90139367] w2: [-22.61254313] bias: [16.45128167] loss: 30.627444511828198\n",
            "Epoch: 3421 / 5000\n",
            "w1: [24.87717794] w2: [-22.62496416] bias: [16.41201646] loss: 30.620308601962297\n",
            "Epoch: 3422 / 5000\n",
            "w1: [24.8793034] w2: [-22.63242925] bias: [16.40620337] loss: 30.61879823117416\n",
            "Epoch: 3423 / 5000\n",
            "w1: [24.87240939] w2: [-22.63131456] bias: [16.39579439] loss: 30.618704519402698\n",
            "Epoch: 3424 / 5000\n",
            "w1: [24.86813202] w2: [-22.63680031] bias: [16.38380886] loss: 30.61803792851272\n",
            "Epoch: 3425 / 5000\n",
            "w1: [24.87674273] w2: [-22.6379811] bias: [16.39165947] loss: 30.61748573346735\n",
            "Epoch: 3426 / 5000\n",
            "w1: [24.89182571] w2: [-22.63356565] bias: [16.41678] loss: 30.61911577756444\n",
            "Epoch: 3427 / 5000\n",
            "w1: [24.90512726] w2: [-22.63864035] bias: [16.43173524] loss: 30.620036793241947\n",
            "Epoch: 3428 / 5000\n",
            "w1: [24.90464936] w2: [-22.64655432] bias: [16.42882532] loss: 30.61847713402165\n",
            "Epoch: 3429 / 5000\n",
            "w1: [24.89126511] w2: [-22.65376861] bias: [16.39975238] loss: 30.615151885471484\n",
            "Epoch: 3430 / 5000\n",
            "w1: [24.8681544] w2: [-22.66585346] bias: [16.35776311] loss: 30.615791674268298\n",
            "Epoch: 3431 / 5000\n",
            "w1: [24.86406324] w2: [-22.66545777] bias: [16.35152492] loss: 30.616713156187732\n",
            "Epoch: 3432 / 5000\n",
            "w1: [24.87011578] w2: [-22.65942692] bias: [16.36233614] loss: 30.61591926721403\n",
            "Epoch: 3433 / 5000\n",
            "w1: [24.86778782] w2: [-22.65410203] bias: [16.36097806] loss: 30.61670804314691\n",
            "Epoch: 3434 / 5000\n",
            "w1: [24.88365571] w2: [-22.65607176] bias: [16.37538864] loss: 30.614702236981444\n",
            "Epoch: 3435 / 5000\n",
            "w1: [24.87806188] w2: [-22.67395345] bias: [16.34855472] loss: 30.61456132745954\n",
            "Epoch: 3436 / 5000\n",
            "w1: [24.87767645] w2: [-22.68326562] bias: [16.3418913] loss: 30.614417504539137\n",
            "Epoch: 3437 / 5000\n",
            "w1: [24.86806868] w2: [-22.69626572] bias: [16.31258462] loss: 30.618780363004163\n",
            "Epoch: 3438 / 5000\n",
            "w1: [24.89774076] w2: [-22.70130149] bias: [16.34091897] loss: 30.610632636448866\n",
            "Epoch: 3439 / 5000\n",
            "w1: [24.89086538] w2: [-22.70335064] bias: [16.32897953] loss: 30.612560206739243\n",
            "Epoch: 3440 / 5000\n",
            "w1: [24.90537351] w2: [-22.69713489] bias: [16.36204742] loss: 30.60897660874046\n",
            "Epoch: 3441 / 5000\n",
            "w1: [24.89114073] w2: [-22.69948602] bias: [16.34027803] loss: 30.61164497079729\n",
            "Epoch: 3442 / 5000\n",
            "w1: [24.89485613] w2: [-22.70188041] bias: [16.3413247] loss: 30.610911588029335\n",
            "Epoch: 3443 / 5000\n",
            "w1: [24.89372913] w2: [-22.69910349] bias: [16.33799864] loss: 30.611548505193703\n",
            "Epoch: 3444 / 5000\n",
            "w1: [24.90460061] w2: [-22.68777556] bias: [16.35739247] loss: 30.610046506252775\n",
            "Epoch: 3445 / 5000\n",
            "w1: [24.91438907] w2: [-22.68355772] bias: [16.3854055] loss: 30.609716032053495\n",
            "Epoch: 3446 / 5000\n",
            "w1: [24.91772097] w2: [-22.68876761] bias: [16.39292047] loss: 30.60925704726858\n",
            "Epoch: 3447 / 5000\n",
            "w1: [24.92013766] w2: [-22.67526369] bias: [16.40710172] loss: 30.611790386563573\n",
            "Epoch: 3448 / 5000\n",
            "w1: [24.93014278] w2: [-22.67793066] bias: [16.41213889] loss: 30.611659950782688\n",
            "Epoch: 3449 / 5000\n",
            "w1: [24.92924856] w2: [-22.65945651] bias: [16.42296585] loss: 30.61558462964373\n",
            "Epoch: 3450 / 5000\n",
            "w1: [24.92738025] w2: [-22.66032376] bias: [16.41844041] loss: 30.61487034221594\n",
            "Epoch: 3451 / 5000\n",
            "w1: [24.91997188] w2: [-22.66004266] bias: [16.4065422] loss: 30.613719785210627\n",
            "Epoch: 3452 / 5000\n",
            "w1: [24.9264655] w2: [-22.64956653] bias: [16.43999735] loss: 30.61977155444794\n",
            "Epoch: 3453 / 5000\n",
            "w1: [24.9339814] w2: [-22.65289655] bias: [16.45619823] loss: 30.622584862431765\n",
            "Epoch: 3454 / 5000\n",
            "w1: [24.9343266] w2: [-22.65443081] bias: [16.47028677] loss: 30.625569602537457\n",
            "Epoch: 3455 / 5000\n",
            "w1: [24.9239503] w2: [-22.65344798] bias: [16.45369266] loss: 30.621691702720206\n",
            "Epoch: 3456 / 5000\n",
            "w1: [24.93240555] w2: [-22.64906899] bias: [16.46599402] loss: 30.625391367173194\n",
            "Epoch: 3457 / 5000\n",
            "w1: [24.92346324] w2: [-22.64991638] bias: [16.45600373] loss: 30.62272776388873\n",
            "Epoch: 3458 / 5000\n",
            "w1: [24.92803327] w2: [-22.64330174] bias: [16.46372676] loss: 30.625682295721074\n",
            "Epoch: 3459 / 5000\n",
            "w1: [24.91655339] w2: [-22.64871805] bias: [16.4419175] loss: 30.620137101069055\n",
            "Epoch: 3460 / 5000\n",
            "w1: [24.89646375] w2: [-22.65279522] bias: [16.41903783] loss: 30.616612379454114\n",
            "Epoch: 3461 / 5000\n",
            "w1: [24.89209376] w2: [-22.65890193] bias: [16.40532645] loss: 30.61483056891656\n",
            "Epoch: 3462 / 5000\n",
            "w1: [24.89451598] w2: [-22.65749649] bias: [16.40757591] loss: 30.615056147292538\n",
            "Epoch: 3463 / 5000\n",
            "w1: [24.8738576] w2: [-22.66934294] bias: [16.37093519] loss: 30.614321257297462\n",
            "Epoch: 3464 / 5000\n",
            "w1: [24.90704351] w2: [-22.66411222] bias: [16.41453268] loss: 30.614348360582387\n",
            "Epoch: 3465 / 5000\n",
            "w1: [24.89784165] w2: [-22.66131335] bias: [16.4046014] loss: 30.61421961065544\n",
            "Epoch: 3466 / 5000\n",
            "w1: [24.93179421] w2: [-22.66304532] bias: [16.44476542] loss: 30.61859656262487\n",
            "Epoch: 3467 / 5000\n",
            "w1: [24.92844722] w2: [-22.66552589] bias: [16.44059991] loss: 30.61742809178912\n",
            "Epoch: 3468 / 5000\n",
            "w1: [24.92285665] w2: [-22.66944621] bias: [16.42831074] loss: 30.614941354351743\n",
            "Epoch: 3469 / 5000\n",
            "w1: [24.94668954] w2: [-22.65608119] bias: [16.48116641] loss: 30.628793293124\n",
            "Epoch: 3470 / 5000\n",
            "w1: [24.95915797] w2: [-22.64985894] bias: [16.4974257] loss: 30.635867982081894\n",
            "Epoch: 3471 / 5000\n",
            "w1: [24.95686877] w2: [-22.65862409] bias: [16.48262232] loss: 30.629425217866167\n",
            "Epoch: 3472 / 5000\n",
            "w1: [24.98620079] w2: [-22.649072] bias: [16.53121903] loss: 30.65184014831938\n",
            "Epoch: 3473 / 5000\n",
            "w1: [24.96676069] w2: [-22.65475005] bias: [16.50692007] loss: 30.63882500802997\n",
            "Epoch: 3474 / 5000\n",
            "w1: [24.96917] w2: [-22.65276822] bias: [16.50589877] loss: 30.639127820294505\n",
            "Epoch: 3475 / 5000\n",
            "w1: [24.99461184] w2: [-22.652648] bias: [16.5420436] loss: 30.65699562367302\n",
            "Epoch: 3476 / 5000\n",
            "w1: [25.00480444] w2: [-22.63166792] bias: [16.56938891] loss: 30.6774170457455\n",
            "Epoch: 3477 / 5000\n",
            "w1: [25.0087788] w2: [-22.64184118] bias: [16.55909594] loss: 30.670235813093278\n",
            "Epoch: 3478 / 5000\n",
            "w1: [24.99574292] w2: [-22.64765426] bias: [16.53131921] loss: 30.6535933312779\n",
            "Epoch: 3479 / 5000\n",
            "w1: [25.00032077] w2: [-22.64385395] bias: [16.53241165] loss: 30.655646361297187\n",
            "Epoch: 3480 / 5000\n",
            "w1: [24.98582475] w2: [-22.66372326] bias: [16.49366582] loss: 30.63435749626731\n",
            "Epoch: 3481 / 5000\n",
            "w1: [24.99258071] w2: [-22.65218287] bias: [16.51218291] loss: 30.644270246563607\n",
            "Epoch: 3482 / 5000\n",
            "w1: [24.99426927] w2: [-22.65388243] bias: [16.51224916] loss: 30.64413735428611\n",
            "Epoch: 3483 / 5000\n",
            "w1: [24.98524559] w2: [-22.65403747] bias: [16.49846494] loss: 30.637937065141433\n",
            "Epoch: 3484 / 5000\n",
            "w1: [24.98252132] w2: [-22.65612477] bias: [16.50611307] loss: 30.639948453878088\n",
            "Epoch: 3485 / 5000\n",
            "w1: [24.98381845] w2: [-22.64695986] bias: [16.51307874] loss: 30.644669695990082\n",
            "Epoch: 3486 / 5000\n",
            "w1: [24.98708128] w2: [-22.64926238] bias: [16.50923395] loss: 30.643096631280326\n",
            "Epoch: 3487 / 5000\n",
            "w1: [24.99637307] w2: [-22.66143257] bias: [16.50743388] loss: 30.640916154926103\n",
            "Epoch: 3488 / 5000\n",
            "w1: [24.95941737] w2: [-22.67844931] bias: [16.44730404] loss: 30.61728090722651\n",
            "Epoch: 3489 / 5000\n",
            "w1: [24.96032275] w2: [-22.68296275] bias: [16.43910912] loss: 30.614944709457642\n",
            "Epoch: 3490 / 5000\n",
            "w1: [24.95337715] w2: [-22.69049688] bias: [16.42185548] loss: 30.61085868069073\n",
            "Epoch: 3491 / 5000\n",
            "w1: [24.95220861] w2: [-22.69490842] bias: [16.43015276] loss: 30.61147500734462\n",
            "Epoch: 3492 / 5000\n",
            "w1: [24.943235] w2: [-22.70214656] bias: [16.41393748] loss: 30.60836621889715\n",
            "Epoch: 3493 / 5000\n",
            "w1: [24.94992889] w2: [-22.69987647] bias: [16.42567993] loss: 30.610089256438187\n",
            "Epoch: 3494 / 5000\n",
            "w1: [24.94959806] w2: [-22.70077132] bias: [16.41928269] loss: 30.609095705716214\n",
            "Epoch: 3495 / 5000\n",
            "w1: [24.96107145] w2: [-22.69707284] bias: [16.4359068] loss: 30.612195994671847\n",
            "Epoch: 3496 / 5000\n",
            "w1: [24.95175651] w2: [-22.69896686] bias: [16.419624] loss: 30.609368488554075\n",
            "Epoch: 3497 / 5000\n",
            "w1: [24.94853843] w2: [-22.69688451] bias: [16.41463304] loss: 30.60905540773068\n",
            "Epoch: 3498 / 5000\n",
            "w1: [24.95148194] w2: [-22.69644061] bias: [16.41944623] loss: 30.609697207682864\n",
            "Epoch: 3499 / 5000\n",
            "w1: [24.95055162] w2: [-22.6941842] bias: [16.42768146] loss: 30.61119517684489\n",
            "Epoch: 3500 / 5000\n",
            "w1: [24.93940029] w2: [-22.70154592] bias: [16.40616977] loss: 30.607751629962834\n",
            "Epoch: 3501 / 5000\n",
            "w1: [24.95068635] w2: [-22.69905623] bias: [16.42212346] loss: 30.60970229110391\n",
            "Epoch: 3502 / 5000\n",
            "w1: [24.93706127] w2: [-22.70887588] bias: [16.39164633] loss: 30.605885706146854\n",
            "Epoch: 3503 / 5000\n",
            "w1: [24.92807171] w2: [-22.71442996] bias: [16.3759507] loss: 30.605295679852524\n",
            "Epoch: 3504 / 5000\n",
            "w1: [24.93887064] w2: [-22.71299671] bias: [16.40665993] loss: 30.606383890335348\n",
            "Epoch: 3505 / 5000\n",
            "w1: [24.94335729] w2: [-22.72264825] bias: [16.40506454] loss: 30.604917116087194\n",
            "Epoch: 3506 / 5000\n",
            "w1: [24.95915962] w2: [-22.71474605] bias: [16.42721483] loss: 30.608193535939918\n",
            "Epoch: 3507 / 5000\n",
            "w1: [24.94682118] w2: [-22.72137253] bias: [16.41767576] loss: 30.606193116936183\n",
            "Epoch: 3508 / 5000\n",
            "w1: [24.94212194] w2: [-22.71267198] bias: [16.41691273] loss: 30.60733752934363\n",
            "Epoch: 3509 / 5000\n",
            "w1: [24.92826291] w2: [-22.7165604] bias: [16.39743711] loss: 30.6057624908612\n",
            "Epoch: 3510 / 5000\n",
            "w1: [24.92276099] w2: [-22.71806373] bias: [16.3878481] loss: 30.605518346306003\n",
            "Epoch: 3511 / 5000\n",
            "w1: [24.93034906] w2: [-22.70889287] bias: [16.4088595] loss: 30.60736750105854\n",
            "Epoch: 3512 / 5000\n",
            "w1: [24.92181703] w2: [-22.71192982] bias: [16.40045127] loss: 30.606779706794505\n",
            "Epoch: 3513 / 5000\n",
            "w1: [24.93199848] w2: [-22.70577484] bias: [16.41988899] loss: 30.60878042100195\n",
            "Epoch: 3514 / 5000\n",
            "w1: [24.91909193] w2: [-22.71262987] bias: [16.39971291] loss: 30.60679861596622\n",
            "Epoch: 3515 / 5000\n",
            "w1: [24.91965945] w2: [-22.71137908] bias: [16.40512036] loss: 30.607225242929925\n",
            "Epoch: 3516 / 5000\n",
            "w1: [24.92535298] w2: [-22.70950444] bias: [16.41282778] loss: 30.607800031572886\n",
            "Epoch: 3517 / 5000\n",
            "w1: [24.91997098] w2: [-22.70552571] bias: [16.40564016] loss: 30.607938285933272\n",
            "Epoch: 3518 / 5000\n",
            "w1: [24.91770008] w2: [-22.71680931] bias: [16.39488574] loss: 30.6061958206066\n",
            "Epoch: 3519 / 5000\n",
            "w1: [24.92371395] w2: [-22.70934353] bias: [16.40939983] loss: 30.607599164048214\n",
            "Epoch: 3520 / 5000\n",
            "w1: [24.91341048] w2: [-22.7200549] bias: [16.39395021] loss: 30.60607724354562\n",
            "Epoch: 3521 / 5000\n",
            "w1: [24.90133372] w2: [-22.72909401] bias: [16.36656821] loss: 30.606405944665237\n",
            "Epoch: 3522 / 5000\n",
            "w1: [24.89042724] w2: [-22.72919097] bias: [16.34755704] loss: 30.608947647094762\n",
            "Epoch: 3523 / 5000\n",
            "w1: [24.88480738] w2: [-22.71575313] bias: [16.34724964] loss: 30.61064377549849\n",
            "Epoch: 3524 / 5000\n",
            "w1: [24.87914904] w2: [-22.72124475] bias: [16.3353592] loss: 30.612332554726446\n",
            "Epoch: 3525 / 5000\n",
            "w1: [24.87014615] w2: [-22.7261784] bias: [16.32577704] loss: 30.6147756975002\n",
            "Epoch: 3526 / 5000\n",
            "w1: [24.86282005] w2: [-22.72788425] bias: [16.32384798] loss: 30.61621149758556\n",
            "Epoch: 3527 / 5000\n",
            "w1: [24.87507688] w2: [-22.72682769] bias: [16.3449402] loss: 30.611422793153437\n",
            "Epoch: 3528 / 5000\n",
            "w1: [24.87011999] w2: [-22.72739927] bias: [16.33641122] loss: 30.613164129363472\n",
            "Epoch: 3529 / 5000\n",
            "w1: [24.88110186] w2: [-22.72244157] bias: [16.35192805] loss: 30.610212674804025\n",
            "Epoch: 3530 / 5000\n",
            "w1: [24.86349221] w2: [-22.73107913] bias: [16.32134163] loss: 30.61637710472055\n",
            "Epoch: 3531 / 5000\n",
            "w1: [24.86878295] w2: [-22.72594875] bias: [16.33039045] loss: 30.6143044083172\n",
            "Epoch: 3532 / 5000\n",
            "w1: [24.84914612] w2: [-22.73784885] bias: [16.29779098] loss: 30.623735127113825\n",
            "Epoch: 3533 / 5000\n",
            "w1: [24.85758261] w2: [-22.73618273] bias: [16.30422542] loss: 30.620618432333526\n",
            "Epoch: 3534 / 5000\n",
            "w1: [24.8629099] w2: [-22.72845406] bias: [16.31350107] loss: 30.6180213321016\n",
            "Epoch: 3535 / 5000\n",
            "w1: [24.85800821] w2: [-22.74626957] bias: [16.29535747] loss: 30.622281833967588\n",
            "Epoch: 3536 / 5000\n",
            "w1: [24.85287053] w2: [-22.74622749] bias: [16.29011121] loss: 30.6246714065439\n",
            "Epoch: 3537 / 5000\n",
            "w1: [24.87110641] w2: [-22.734605] bias: [16.32332347] loss: 30.614590192669535\n",
            "Epoch: 3538 / 5000\n",
            "w1: [24.86216227] w2: [-22.74129728] bias: [16.30424665] loss: 30.619560730180364\n",
            "Epoch: 3539 / 5000\n",
            "w1: [24.85684575] w2: [-22.75056921] bias: [16.28932954] loss: 30.623934030829282\n",
            "Epoch: 3540 / 5000\n",
            "w1: [24.85770211] w2: [-22.75025452] bias: [16.28747081] loss: 30.624236944670724\n",
            "Epoch: 3541 / 5000\n",
            "w1: [24.85632359] w2: [-22.75897761] bias: [16.27560584] loss: 30.627688127309163\n",
            "Epoch: 3542 / 5000\n",
            "w1: [24.84965019] w2: [-22.76366546] bias: [16.26482903] loss: 30.632564404700663\n",
            "Epoch: 3543 / 5000\n",
            "w1: [24.86962863] w2: [-22.76441271] bias: [16.28443018] loss: 30.622206219663703\n",
            "Epoch: 3544 / 5000\n",
            "w1: [24.8623239] w2: [-22.76282367] bias: [16.27058958] loss: 30.62773407402713\n",
            "Epoch: 3545 / 5000\n",
            "w1: [24.85668829] w2: [-22.76362902] bias: [16.26472883] loss: 30.630867530867896\n",
            "Epoch: 3546 / 5000\n",
            "w1: [24.87916641] w2: [-22.75971688] bias: [16.29304915] loss: 30.61819368667363\n",
            "Epoch: 3547 / 5000\n",
            "w1: [24.88527012] w2: [-22.76047231] bias: [16.29706016] loss: 30.616072170639\n",
            "Epoch: 3548 / 5000\n",
            "w1: [24.87053789] w2: [-22.77128574] bias: [16.26638354] loss: 30.62701403956539\n",
            "Epoch: 3549 / 5000\n",
            "w1: [24.85238373] w2: [-22.78366379] bias: [16.23467373] loss: 30.642825976228803\n",
            "Epoch: 3550 / 5000\n",
            "w1: [24.85581132] w2: [-22.77553713] bias: [16.24261558] loss: 30.638710538221762\n",
            "Epoch: 3551 / 5000\n",
            "w1: [24.84072838] w2: [-22.78339863] bias: [16.21309507] loss: 30.65532695764127\n",
            "Epoch: 3552 / 5000\n",
            "w1: [24.84835472] w2: [-22.79121662] bias: [16.21761417] loss: 30.651277499820555\n",
            "Epoch: 3553 / 5000\n",
            "w1: [24.84456432] w2: [-22.79760946] bias: [16.21750539] loss: 30.652732657048094\n",
            "Epoch: 3554 / 5000\n",
            "w1: [24.85961669] w2: [-22.78153882] bias: [16.25699318] loss: 30.632710845395987\n",
            "Epoch: 3555 / 5000\n",
            "w1: [24.84063789] w2: [-22.79021963] bias: [16.22282507] loss: 30.651339275935182\n",
            "Epoch: 3556 / 5000\n",
            "w1: [24.85315875] w2: [-22.78477177] bias: [16.23825918] loss: 30.64124259231071\n",
            "Epoch: 3557 / 5000\n",
            "w1: [24.86287153] w2: [-22.77911204] bias: [16.25276655] loss: 30.633294844735232\n",
            "Epoch: 3558 / 5000\n",
            "w1: [24.86727638] w2: [-22.77172843] bias: [16.26227663] loss: 30.62905543528139\n",
            "Epoch: 3559 / 5000\n",
            "w1: [24.86563916] w2: [-22.77776992] bias: [16.25720751] loss: 30.631096511859255\n",
            "Epoch: 3560 / 5000\n",
            "w1: [24.85753078] w2: [-22.78005652] bias: [16.24696669] loss: 30.6367336980484\n",
            "Epoch: 3561 / 5000\n",
            "w1: [24.84968543] w2: [-22.78424384] bias: [16.23087662] loss: 30.64511821884299\n",
            "Epoch: 3562 / 5000\n",
            "w1: [24.84426087] w2: [-22.78950108] bias: [16.22341568] loss: 30.649964654277767\n",
            "Epoch: 3563 / 5000\n",
            "w1: [24.86270128] w2: [-22.78815264] bias: [16.24578091] loss: 30.635895347144633\n",
            "Epoch: 3564 / 5000\n",
            "w1: [24.86536158] w2: [-22.79131522] bias: [16.24621853] loss: 30.63507533206812\n",
            "Epoch: 3565 / 5000\n",
            "w1: [24.86355397] w2: [-22.78262736] bias: [16.24835357] loss: 30.634681163895998\n",
            "Epoch: 3566 / 5000\n",
            "w1: [24.86776705] w2: [-22.77844831] bias: [16.25554884] loss: 30.631112965882224\n",
            "Epoch: 3567 / 5000\n",
            "w1: [24.86941883] w2: [-22.7843255] bias: [16.24896052] loss: 30.632960969621852\n",
            "Epoch: 3568 / 5000\n",
            "w1: [24.87022143] w2: [-22.78056875] bias: [16.25010354] loss: 30.632329530550955\n",
            "Epoch: 3569 / 5000\n",
            "w1: [24.89838242] w2: [-22.76626469] bias: [16.29770568] loss: 30.613275699991046\n",
            "Epoch: 3570 / 5000\n",
            "w1: [24.90176489] w2: [-22.75455173] bias: [16.32164628] loss: 30.60893679897531\n",
            "Epoch: 3571 / 5000\n",
            "w1: [24.87675358] w2: [-22.7688729] bias: [16.27370685] loss: 30.6234778438944\n",
            "Epoch: 3572 / 5000\n",
            "w1: [24.87835836] w2: [-22.76334379] bias: [16.27710163] loss: 30.62226897166159\n",
            "Epoch: 3573 / 5000\n",
            "w1: [24.89598585] w2: [-22.73809636] bias: [16.31959472] loss: 30.610990069672656\n",
            "Epoch: 3574 / 5000\n",
            "w1: [24.87932155] w2: [-22.74708055] bias: [16.28995722] loss: 30.619214187057313\n",
            "Epoch: 3575 / 5000\n",
            "w1: [24.87905332] w2: [-22.7475217] bias: [16.28920385] loss: 30.619430391947628\n",
            "Epoch: 3576 / 5000\n",
            "w1: [24.8846511] w2: [-22.72873837] bias: [16.31288194] loss: 30.614352859817302\n",
            "Epoch: 3577 / 5000\n",
            "w1: [24.86419178] w2: [-22.73877294] bias: [16.27240553] loss: 30.627043353831056\n",
            "Epoch: 3578 / 5000\n",
            "w1: [24.86750884] w2: [-22.7256221] bias: [16.28623852] loss: 30.623054757249225\n",
            "Epoch: 3579 / 5000\n",
            "w1: [24.85964404] w2: [-22.72705251] bias: [16.27566455] loss: 30.627360734392806\n",
            "Epoch: 3580 / 5000\n",
            "w1: [24.86146546] w2: [-22.73745525] bias: [16.26474553] loss: 30.629867321907426\n",
            "Epoch: 3581 / 5000\n",
            "w1: [24.88661619] w2: [-22.71684116] bias: [16.31668981] loss: 30.614023763320493\n",
            "Epoch: 3582 / 5000\n",
            "w1: [24.88201656] w2: [-22.72111568] bias: [16.30242034] loss: 30.617007427912394\n",
            "Epoch: 3583 / 5000\n",
            "w1: [24.87784475] w2: [-22.71570215] bias: [16.30503563] loss: 30.617494445773694\n",
            "Epoch: 3584 / 5000\n",
            "w1: [24.86599776] w2: [-22.6970114] bias: [16.3119222] loss: 30.619204578741044\n",
            "Epoch: 3585 / 5000\n",
            "w1: [24.863156] w2: [-22.7001489] bias: [16.30143507] loss: 30.62148549352572\n",
            "Epoch: 3586 / 5000\n",
            "w1: [24.88785008] w2: [-22.70095055] bias: [16.3248203] loss: 30.61363885372676\n",
            "Epoch: 3587 / 5000\n",
            "w1: [24.87362784] w2: [-22.71132081] bias: [16.30039934] loss: 30.619309614347426\n",
            "Epoch: 3588 / 5000\n",
            "w1: [24.90093417] w2: [-22.70118801] bias: [16.35263426] loss: 30.60947111548787\n",
            "Epoch: 3589 / 5000\n",
            "w1: [24.90003308] w2: [-22.71158334] bias: [16.34273588] loss: 30.609435439568006\n",
            "Epoch: 3590 / 5000\n",
            "w1: [24.90688115] w2: [-22.70323092] bias: [16.35521927] loss: 30.60854049760435\n",
            "Epoch: 3591 / 5000\n",
            "w1: [24.89513175] w2: [-22.68750005] bias: [16.34952018] loss: 30.6114243311503\n",
            "Epoch: 3592 / 5000\n",
            "w1: [24.92435992] w2: [-22.69077995] bias: [16.38228889] loss: 30.608195140783657\n",
            "Epoch: 3593 / 5000\n",
            "w1: [24.9172319] w2: [-22.68430682] bias: [16.37876401] loss: 30.60925287246686\n",
            "Epoch: 3594 / 5000\n",
            "w1: [24.90124594] w2: [-22.70045542] bias: [16.3405314] loss: 30.610300900969687\n",
            "Epoch: 3595 / 5000\n",
            "w1: [24.91943338] w2: [-22.6941551] bias: [16.37714918] loss: 30.608020129069295\n",
            "Epoch: 3596 / 5000\n",
            "w1: [24.92805671] w2: [-22.69139916] bias: [16.38944826] loss: 30.60823163185652\n",
            "Epoch: 3597 / 5000\n",
            "w1: [24.9301757] w2: [-22.68870292] bias: [16.39827866] loss: 30.609016093992018\n",
            "Epoch: 3598 / 5000\n",
            "w1: [24.95872384] w2: [-22.68355837] bias: [16.43405671] loss: 30.61388937172009\n",
            "Epoch: 3599 / 5000\n",
            "w1: [24.95069946] w2: [-22.69025632] bias: [16.41462646] loss: 30.609928218720732\n",
            "Epoch: 3600 / 5000\n",
            "w1: [24.96596582] w2: [-22.69242265] bias: [16.42585963] loss: 30.61123154165648\n",
            "Epoch: 3601 / 5000\n",
            "w1: [24.95034749] w2: [-22.70565944] bias: [16.39543521] loss: 30.605955086458927\n",
            "Epoch: 3602 / 5000\n",
            "w1: [24.97558568] w2: [-22.6927602] bias: [16.43863747] loss: 30.613678215727692\n",
            "Epoch: 3603 / 5000\n",
            "w1: [24.97001147] w2: [-22.69102302] bias: [16.42876025] loss: 30.61197854584829\n",
            "Epoch: 3604 / 5000\n",
            "w1: [24.96292418] w2: [-22.69227782] bias: [16.41279166] loss: 30.60929056890819\n",
            "Epoch: 3605 / 5000\n",
            "w1: [24.95413234] w2: [-22.69966877] bias: [16.39038232] loss: 30.606146907294754\n",
            "Epoch: 3606 / 5000\n",
            "w1: [24.95007327] w2: [-22.70386074] bias: [16.38853563] loss: 30.60567782413128\n",
            "Epoch: 3607 / 5000\n",
            "w1: [24.93155586] w2: [-22.71290904] bias: [16.35396796] loss: 30.605323053925808\n",
            "Epoch: 3608 / 5000\n",
            "w1: [24.92892328] w2: [-22.71830478] bias: [16.34120387] loss: 30.60568335412898\n",
            "Epoch: 3609 / 5000\n",
            "w1: [24.94647425] w2: [-22.71715993] bias: [16.36717406] loss: 30.60359292756745\n",
            "Epoch: 3610 / 5000\n",
            "w1: [24.93401534] w2: [-22.72819982] bias: [16.3385232] loss: 30.604512546408174\n",
            "Epoch: 3611 / 5000\n",
            "w1: [24.92852579] w2: [-22.73341464] bias: [16.32165789] loss: 30.60627449795268\n",
            "Epoch: 3612 / 5000\n",
            "w1: [24.92486038] w2: [-22.73983535] bias: [16.30688954] loss: 30.608291611258018\n",
            "Epoch: 3613 / 5000\n",
            "w1: [24.91755861] w2: [-22.7522782] bias: [16.28477964] loss: 30.612846542974275\n",
            "Epoch: 3614 / 5000\n",
            "w1: [24.91318798] w2: [-22.75959938] bias: [16.27383224] loss: 30.61587939213866\n",
            "Epoch: 3615 / 5000\n",
            "w1: [24.93015276] w2: [-22.76292832] bias: [16.29103511] loss: 30.608996200840725\n",
            "Epoch: 3616 / 5000\n",
            "w1: [24.929136] w2: [-22.76083265] bias: [16.28943503] loss: 30.609550845959184\n",
            "Epoch: 3617 / 5000\n",
            "w1: [24.90123257] w2: [-22.76825494] bias: [16.25384721] loss: 30.623595592003447\n",
            "Epoch: 3618 / 5000\n",
            "w1: [24.92692052] w2: [-22.75566656] bias: [16.29595478] loss: 30.608956596266236\n",
            "Epoch: 3619 / 5000\n",
            "w1: [24.91797477] w2: [-22.76327592] bias: [16.28151723] loss: 30.613111117371076\n",
            "Epoch: 3620 / 5000\n",
            "w1: [24.92410039] w2: [-22.75808487] bias: [16.2912567] loss: 30.610193917072532\n",
            "Epoch: 3621 / 5000\n",
            "w1: [24.92182733] w2: [-22.75652038] bias: [16.29172295] loss: 30.61056427467152\n",
            "Epoch: 3622 / 5000\n",
            "w1: [24.93936245] w2: [-22.75672762] bias: [16.31780119] loss: 30.603807531132006\n",
            "Epoch: 3623 / 5000\n",
            "w1: [24.93038215] w2: [-22.75973477] bias: [16.30349559] loss: 30.60695833247421\n",
            "Epoch: 3624 / 5000\n",
            "w1: [24.91978049] w2: [-22.77114383] bias: [16.27717531] loss: 30.613517315758635\n",
            "Epoch: 3625 / 5000\n",
            "w1: [24.90505367] w2: [-22.78476471] bias: [16.24402158] loss: 30.62566444884451\n",
            "Epoch: 3626 / 5000\n",
            "w1: [24.91271752] w2: [-22.78011217] bias: [16.25814064] loss: 30.61967581720753\n",
            "Epoch: 3627 / 5000\n",
            "w1: [24.92366311] w2: [-22.77787244] bias: [16.28131567] loss: 30.611663366962947\n",
            "Epoch: 3628 / 5000\n",
            "w1: [24.92255544] w2: [-22.77150852] bias: [16.2875526] loss: 30.610731360703184\n",
            "Epoch: 3629 / 5000\n",
            "w1: [24.91320018] w2: [-22.77714604] bias: [16.26894214] loss: 30.616721882814822\n",
            "Epoch: 3630 / 5000\n",
            "w1: [24.90600615] w2: [-22.7810561] bias: [16.25694575] loss: 30.62152048430284\n",
            "Epoch: 3631 / 5000\n",
            "w1: [24.92770058] w2: [-22.76791005] bias: [16.28923889] loss: 30.60958456689458\n",
            "Epoch: 3632 / 5000\n",
            "w1: [24.89768017] w2: [-22.77761689] bias: [16.24432607] loss: 30.627346233358892\n",
            "Epoch: 3633 / 5000\n",
            "w1: [24.8885073] w2: [-22.78212811] bias: [16.23052242] loss: 30.634438147815303\n",
            "Epoch: 3634 / 5000\n",
            "w1: [24.89832929] w2: [-22.75943257] bias: [16.26187609] loss: 30.622058081176277\n",
            "Epoch: 3635 / 5000\n",
            "w1: [24.89798297] w2: [-22.76480716] bias: [16.25625796] loss: 30.62366447295226\n",
            "Epoch: 3636 / 5000\n",
            "w1: [24.91049187] w2: [-22.76090603] bias: [16.27438783] loss: 30.61625890734874\n",
            "Epoch: 3637 / 5000\n",
            "w1: [24.91717055] w2: [-22.7659198] bias: [16.27827005] loss: 30.613912018865385\n",
            "Epoch: 3638 / 5000\n",
            "w1: [24.91419369] w2: [-22.76797643] bias: [16.26996228] loss: 30.61642463774465\n",
            "Epoch: 3639 / 5000\n",
            "w1: [24.92179634] w2: [-22.76225736] bias: [16.28445067] loss: 30.61180438303769\n",
            "Epoch: 3640 / 5000\n",
            "w1: [24.93080074] w2: [-22.75893142] bias: [16.2997342] loss: 30.60753362102019\n",
            "Epoch: 3641 / 5000\n",
            "w1: [24.93514012] w2: [-22.76831605] bias: [16.29558981] loss: 30.607116904305183\n",
            "Epoch: 3642 / 5000\n",
            "w1: [24.94135696] w2: [-22.75259884] bias: [16.31619989] loss: 30.60396340657094\n",
            "Epoch: 3643 / 5000\n",
            "w1: [24.95564796] w2: [-22.7463922] bias: [16.33486586] loss: 30.600972921882068\n",
            "Epoch: 3644 / 5000\n",
            "w1: [24.95373416] w2: [-22.73571003] bias: [16.34197806] loss: 30.601653649123037\n",
            "Epoch: 3645 / 5000\n",
            "w1: [24.97870322] w2: [-22.73812817] bias: [16.37737241] loss: 30.59979003974056\n",
            "Epoch: 3646 / 5000\n",
            "w1: [24.99000111] w2: [-22.7384376] bias: [16.38572449] loss: 30.599862436312034\n",
            "Epoch: 3647 / 5000\n",
            "w1: [24.996955] w2: [-22.73270684] bias: [16.40937283] loss: 30.603087982830278\n",
            "Epoch: 3648 / 5000\n",
            "w1: [24.99965312] w2: [-22.73705586] bias: [16.40339868] loss: 30.60168997378551\n",
            "Epoch: 3649 / 5000\n",
            "w1: [25.00194877] w2: [-22.73845105] bias: [16.39755509] loss: 30.600764424167384\n",
            "Epoch: 3650 / 5000\n",
            "w1: [24.98848568] w2: [-22.74390958] bias: [16.38741069] loss: 30.5994028755596\n",
            "Epoch: 3651 / 5000\n",
            "w1: [25.00897276] w2: [-22.73825216] bias: [16.41201998] loss: 30.602731324710412\n",
            "Epoch: 3652 / 5000\n",
            "w1: [24.99860423] w2: [-22.74017607] bias: [16.40606077] loss: 30.601628397086692\n",
            "Epoch: 3653 / 5000\n",
            "w1: [25.00877089] w2: [-22.74253762] bias: [16.4176878] loss: 30.60302416091952\n",
            "Epoch: 3654 / 5000\n",
            "w1: [25.01702519] w2: [-22.73772467] bias: [16.43026134] loss: 30.606176081726193\n",
            "Epoch: 3655 / 5000\n",
            "w1: [25.01377408] w2: [-22.74634692] bias: [16.41939026] loss: 30.602823455576377\n",
            "Epoch: 3656 / 5000\n",
            "w1: [25.00872976] w2: [-22.74618264] bias: [16.4259243] loss: 30.603897754855783\n",
            "Epoch: 3657 / 5000\n",
            "w1: [25.03012589] w2: [-22.74341927] bias: [16.45199226] loss: 30.610752688978312\n",
            "Epoch: 3658 / 5000\n",
            "w1: [25.02549924] w2: [-22.73770299] bias: [16.44427339] loss: 30.609565715214487\n",
            "Epoch: 3659 / 5000\n",
            "w1: [25.04067184] w2: [-22.74003271] bias: [16.46252579] loss: 30.614896323685354\n",
            "Epoch: 3660 / 5000\n",
            "w1: [25.04026827] w2: [-22.74332104] bias: [16.46942406] loss: 30.616292166298173\n",
            "Epoch: 3661 / 5000\n",
            "w1: [25.02859198] w2: [-22.74948144] bias: [16.45096034] loss: 30.60939521030069\n",
            "Epoch: 3662 / 5000\n",
            "w1: [25.01268173] w2: [-22.75089607] bias: [16.42521187] loss: 30.603155654602876\n",
            "Epoch: 3663 / 5000\n",
            "w1: [25.00966296] w2: [-22.7588734] bias: [16.41318393] loss: 30.60007143013086\n",
            "Epoch: 3664 / 5000\n",
            "w1: [25.00058162] w2: [-22.77136117] bias: [16.39106876] loss: 30.596106130130547\n",
            "Epoch: 3665 / 5000\n",
            "w1: [24.9991719] w2: [-22.76841559] bias: [16.38824478] loss: 30.59626277252496\n",
            "Epoch: 3666 / 5000\n",
            "w1: [24.99988536] w2: [-22.76572811] bias: [16.39953473] loss: 30.597586930257926\n",
            "Epoch: 3667 / 5000\n",
            "w1: [24.9989528] w2: [-22.76985913] bias: [16.39091801] loss: 30.596318032020772\n",
            "Epoch: 3668 / 5000\n",
            "w1: [25.01401915] w2: [-22.7685885] bias: [16.40742352] loss: 30.597975579342947\n",
            "Epoch: 3669 / 5000\n",
            "w1: [25.0073439] w2: [-22.77582018] bias: [16.38699232] loss: 30.595048063872706\n",
            "Epoch: 3670 / 5000\n",
            "w1: [25.0260573] w2: [-22.77155102] bias: [16.4089685] loss: 30.597788258034964\n",
            "Epoch: 3671 / 5000\n",
            "w1: [25.01711871] w2: [-22.78237752] bias: [16.38215997] loss: 30.593607730191206\n",
            "Epoch: 3672 / 5000\n",
            "w1: [25.00948492] w2: [-22.7978834] bias: [16.35647016] loss: 30.5913380625967\n",
            "Epoch: 3673 / 5000\n",
            "w1: [25.007242] w2: [-22.80060055] bias: [16.34716876] loss: 30.591301175279778\n",
            "Epoch: 3674 / 5000\n",
            "w1: [24.99784979] w2: [-22.78968321] bias: [16.34219764] loss: 30.59310208709289\n",
            "Epoch: 3675 / 5000\n",
            "w1: [25.01114417] w2: [-22.78341873] bias: [16.3695511] loss: 30.592983112660598\n",
            "Epoch: 3676 / 5000\n",
            "w1: [25.01221789] w2: [-22.78558013] bias: [16.36532467] loss: 30.592538159653298\n",
            "Epoch: 3677 / 5000\n",
            "w1: [25.01686859] w2: [-22.79276853] bias: [16.36373965] loss: 30.591512637318107\n",
            "Epoch: 3678 / 5000\n",
            "w1: [25.01450839] w2: [-22.78987521] bias: [16.36023011] loss: 30.591829006610222\n",
            "Epoch: 3679 / 5000\n",
            "w1: [25.00904426] w2: [-22.79754654] bias: [16.34445443] loss: 30.59145396356203\n",
            "Epoch: 3680 / 5000\n",
            "w1: [25.02659565] w2: [-22.7919099] bias: [16.36821249] loss: 30.59130330600983\n",
            "Epoch: 3681 / 5000\n",
            "w1: [25.03984605] w2: [-22.78647529] bias: [16.37956058] loss: 30.592271273101712\n",
            "Epoch: 3682 / 5000\n",
            "w1: [25.04385903] w2: [-22.79391287] bias: [16.37674444] loss: 30.591061618634512\n",
            "Epoch: 3683 / 5000\n",
            "w1: [25.05988339] w2: [-22.796627] bias: [16.39898125] loss: 30.593144390962614\n",
            "Epoch: 3684 / 5000\n",
            "w1: [25.06215253] w2: [-22.79636511] bias: [16.41285449] loss: 30.595446418058625\n",
            "Epoch: 3685 / 5000\n",
            "w1: [25.06361176] w2: [-22.7954897] bias: [16.41193391] loss: 30.59543761611608\n",
            "Epoch: 3686 / 5000\n",
            "w1: [25.08130989] w2: [-22.79173447] bias: [16.43377978] loss: 30.60123903868247\n",
            "Epoch: 3687 / 5000\n",
            "w1: [25.06122446] w2: [-22.80408062] bias: [16.39431956] loss: 30.591533937491334\n",
            "Epoch: 3688 / 5000\n",
            "w1: [25.06788214] w2: [-22.80317645] bias: [16.39801842] loss: 30.592192563090837\n",
            "Epoch: 3689 / 5000\n",
            "w1: [25.06918874] w2: [-22.80649656] bias: [16.39922051] loss: 30.591946339475758\n",
            "Epoch: 3690 / 5000\n",
            "w1: [25.07115721] w2: [-22.80136123] bias: [16.40979639] loss: 30.59440034379389\n",
            "Epoch: 3691 / 5000\n",
            "w1: [25.06642047] w2: [-22.81291081] bias: [16.38935251] loss: 30.589774614009738\n",
            "Epoch: 3692 / 5000\n",
            "w1: [25.0948603] w2: [-22.81109904] bias: [16.44711373] loss: 30.602353864728485\n",
            "Epoch: 3693 / 5000\n",
            "w1: [25.10888328] w2: [-22.80042484] bias: [16.47249148] loss: 30.613282167591763\n",
            "Epoch: 3694 / 5000\n",
            "w1: [25.09879867] w2: [-22.80974782] bias: [16.44879399] loss: 30.603332096597793\n",
            "Epoch: 3695 / 5000\n",
            "w1: [25.09806846] w2: [-22.80862312] bias: [16.453098] loss: 30.60468287424814\n",
            "Epoch: 3696 / 5000\n",
            "w1: [25.09622298] w2: [-22.81678973] bias: [16.44263393] loss: 30.60032680578699\n",
            "Epoch: 3697 / 5000\n",
            "w1: [25.09229624] w2: [-22.8256677] bias: [16.42914871] loss: 30.595463277024532\n",
            "Epoch: 3698 / 5000\n",
            "w1: [25.08329962] w2: [-22.82871112] bias: [16.40957162] loss: 30.59085279489846\n",
            "Epoch: 3699 / 5000\n",
            "w1: [25.08494454] w2: [-22.82843097] bias: [16.40669149] loss: 30.59043244411462\n",
            "Epoch: 3700 / 5000\n",
            "w1: [25.07730691] w2: [-22.82003664] bias: [16.41102222] loss: 30.59216235367947\n",
            "Epoch: 3701 / 5000\n",
            "w1: [25.08797423] w2: [-22.81824021] bias: [16.4427224] loss: 30.599590602945113\n",
            "Epoch: 3702 / 5000\n",
            "w1: [25.09586933] w2: [-22.82589789] bias: [16.44893975] loss: 30.60047222820937\n",
            "Epoch: 3703 / 5000\n",
            "w1: [25.10653852] w2: [-22.81895613] bias: [16.46459611] loss: 30.607064791921314\n",
            "Epoch: 3704 / 5000\n",
            "w1: [25.09814964] w2: [-22.82748007] bias: [16.44461972] loss: 30.599237205899332\n",
            "Epoch: 3705 / 5000\n",
            "w1: [25.09373092] w2: [-22.83053079] bias: [16.43472528] loss: 30.596064069702464\n",
            "Epoch: 3706 / 5000\n",
            "w1: [25.1141311] w2: [-22.82397326] bias: [16.46537832] loss: 30.607147059434414\n",
            "Epoch: 3707 / 5000\n",
            "w1: [25.10597653] w2: [-22.82536258] bias: [16.45385776] loss: 30.602684119402213\n",
            "Epoch: 3708 / 5000\n",
            "w1: [25.11131086] w2: [-22.82141521] bias: [16.46246486] loss: 30.60641293490429\n",
            "Epoch: 3709 / 5000\n",
            "w1: [25.12019553] w2: [-22.8202598] bias: [16.475306] loss: 30.611778910340703\n",
            "Epoch: 3710 / 5000\n",
            "w1: [25.12238378] w2: [-22.81004941] bias: [16.48773151] loss: 30.61854424063435\n",
            "Epoch: 3711 / 5000\n",
            "w1: [25.12193281] w2: [-22.81112207] bias: [16.48504607] loss: 30.61726034653941\n",
            "Epoch: 3712 / 5000\n",
            "w1: [25.15248393] w2: [-22.80920801] bias: [16.52070811] loss: 30.637601141760406\n",
            "Epoch: 3713 / 5000\n",
            "w1: [25.16615994] w2: [-22.81230469] bias: [16.52795113] loss: 30.643045421192316\n",
            "Epoch: 3714 / 5000\n",
            "w1: [25.16214656] w2: [-22.81163761] bias: [16.5190183] loss: 30.638012947959087\n",
            "Epoch: 3715 / 5000\n",
            "w1: [25.15217396] w2: [-22.81443461] bias: [16.5008267] loss: 30.627309154562056\n",
            "Epoch: 3716 / 5000\n",
            "w1: [25.17356298] w2: [-22.8090951] bias: [16.52854107] loss: 30.645586652706992\n",
            "Epoch: 3717 / 5000\n",
            "w1: [25.17403002] w2: [-22.79810659] bias: [16.53388053] loss: 30.651138215515047\n",
            "Epoch: 3718 / 5000\n",
            "w1: [25.15918481] w2: [-22.80435098] bias: [16.50946444] loss: 30.634587350599787\n",
            "Epoch: 3719 / 5000\n",
            "w1: [25.15789259] w2: [-22.80736788] bias: [16.50252029] loss: 30.630521564228232\n",
            "Epoch: 3720 / 5000\n",
            "w1: [25.17544822] w2: [-22.79667577] bias: [16.54160441] loss: 30.655992990031404\n",
            "Epoch: 3721 / 5000\n",
            "w1: [25.17350611] w2: [-22.79999091] bias: [16.53673686] loss: 30.652096724407038\n",
            "Epoch: 3722 / 5000\n",
            "w1: [25.17433989] w2: [-22.80027966] bias: [16.53847873] loss: 30.653146135657046\n",
            "Epoch: 3723 / 5000\n",
            "w1: [25.17698351] w2: [-22.80264064] bias: [16.54916585] loss: 30.65906124111046\n",
            "Epoch: 3724 / 5000\n",
            "w1: [25.18444033] w2: [-22.79444472] bias: [16.57421766] loss: 30.677982349009355\n",
            "Epoch: 3725 / 5000\n",
            "w1: [25.17228938] w2: [-22.7948442] bias: [16.55410573] loss: 30.66278195585344\n",
            "Epoch: 3726 / 5000\n",
            "w1: [25.17192583] w2: [-22.79541288] bias: [16.54807695] loss: 30.659127138447225\n",
            "Epoch: 3727 / 5000\n",
            "w1: [25.16311959] w2: [-22.78951533] bias: [16.53554981] loss: 30.651826709799554\n",
            "Epoch: 3728 / 5000\n",
            "w1: [25.15831521] w2: [-22.78815557] bias: [16.53900668] loss: 30.6529905207316\n",
            "Epoch: 3729 / 5000\n",
            "w1: [25.17928193] w2: [-22.77812016] bias: [16.56527739] loss: 30.67552892890225\n",
            "Epoch: 3730 / 5000\n",
            "w1: [25.16571805] w2: [-22.79053939] bias: [16.54519952] loss: 30.657362546415975\n",
            "Epoch: 3731 / 5000\n",
            "w1: [25.17202403] w2: [-22.79358787] bias: [16.54611792] loss: 30.65851206996157\n",
            "Epoch: 3732 / 5000\n",
            "w1: [25.17995554] w2: [-22.79748311] bias: [16.55018939] loss: 30.66164145419498\n",
            "Epoch: 3733 / 5000\n",
            "w1: [25.16118755] w2: [-22.80618325] bias: [16.51226291] loss: 30.635845267089643\n",
            "Epoch: 3734 / 5000\n",
            "w1: [25.17283915] w2: [-22.80399941] bias: [16.5231464] loss: 30.64388653700381\n",
            "Epoch: 3735 / 5000\n",
            "w1: [25.16803531] w2: [-22.80855621] bias: [16.51001258] loss: 30.63547834093953\n",
            "Epoch: 3736 / 5000\n",
            "w1: [25.16295294] w2: [-22.82036773] bias: [16.48849583] loss: 30.622474642995584\n",
            "Epoch: 3737 / 5000\n",
            "w1: [25.16620759] w2: [-22.82130925] bias: [16.49233313] loss: 30.62440624566291\n",
            "Epoch: 3738 / 5000\n",
            "w1: [25.17020682] w2: [-22.82123678] bias: [16.49512172] loss: 30.626271446995958\n",
            "Epoch: 3739 / 5000\n",
            "w1: [25.17874926] w2: [-22.80829583] bias: [16.51250648] loss: 30.63872187701322\n",
            "Epoch: 3740 / 5000\n",
            "w1: [25.1541179] w2: [-22.81963592] bias: [16.4696014] loss: 30.6139243407525\n",
            "Epoch: 3741 / 5000\n",
            "w1: [25.13884746] w2: [-22.83411415] bias: [16.43887825] loss: 30.59960459276065\n",
            "Epoch: 3742 / 5000\n",
            "w1: [25.14314347] w2: [-22.82254809] bias: [16.45356564] loss: 30.606514602020624\n",
            "Epoch: 3743 / 5000\n",
            "w1: [25.14632551] w2: [-22.82609595] bias: [16.45654681] loss: 30.607188830184295\n",
            "Epoch: 3744 / 5000\n",
            "w1: [25.13655975] w2: [-22.8362617] bias: [16.44544073] loss: 30.600953702502757\n",
            "Epoch: 3745 / 5000\n",
            "w1: [25.11568916] w2: [-22.84419118] bias: [16.41288253] loss: 30.59028159207956\n",
            "Epoch: 3746 / 5000\n",
            "w1: [25.13539301] w2: [-22.83837265] bias: [16.44138071] loss: 30.5993221743317\n",
            "Epoch: 3747 / 5000\n",
            "w1: [25.13576272] w2: [-22.84462276] bias: [16.43408273] loss: 30.596313300991195\n",
            "Epoch: 3748 / 5000\n",
            "w1: [25.12966815] w2: [-22.85046838] bias: [16.41707795] loss: 30.590879268773723\n",
            "Epoch: 3749 / 5000\n",
            "w1: [25.12315881] w2: [-22.85110768] bias: [16.40636001] loss: 30.588281829785785\n",
            "Epoch: 3750 / 5000\n",
            "w1: [25.12317489] w2: [-22.85963774] bias: [16.39155204] loss: 30.58452514912455\n",
            "Epoch: 3751 / 5000\n",
            "w1: [25.11473812] w2: [-22.86510817] bias: [16.38111251] loss: 30.58229501335195\n",
            "Epoch: 3752 / 5000\n",
            "w1: [25.09763772] w2: [-22.88427306] bias: [16.33846567] loss: 30.577957446481953\n",
            "Epoch: 3753 / 5000\n",
            "w1: [25.10840725] w2: [-22.8795617] bias: [16.35897695] loss: 30.578691242686777\n",
            "Epoch: 3754 / 5000\n",
            "w1: [25.10681953] w2: [-22.87777396] bias: [16.35638277] loss: 30.578754508717264\n",
            "Epoch: 3755 / 5000\n",
            "w1: [25.08834739] w2: [-22.88873819] bias: [16.3208355] loss: 30.578516611099957\n",
            "Epoch: 3756 / 5000\n",
            "w1: [25.08954611] w2: [-22.89476899] bias: [16.3248506] loss: 30.577867515412883\n",
            "Epoch: 3757 / 5000\n",
            "w1: [25.09452074] w2: [-22.89588479] bias: [16.32459027] loss: 30.57739169800932\n",
            "Epoch: 3758 / 5000\n",
            "w1: [25.10968291] w2: [-22.88670535] bias: [16.35453465] loss: 30.57768298679035\n",
            "Epoch: 3759 / 5000\n",
            "w1: [25.11504567] w2: [-22.88678695] bias: [16.35795256] loss: 30.577699673705183\n",
            "Epoch: 3760 / 5000\n",
            "w1: [25.11584094] w2: [-22.89510607] bias: [16.34428119] loss: 30.576186708762183\n",
            "Epoch: 3761 / 5000\n",
            "w1: [25.11816779] w2: [-22.89128246] bias: [16.3501273] loss: 30.57669178021198\n",
            "Epoch: 3762 / 5000\n",
            "w1: [25.09923166] w2: [-22.89415323] bias: [16.32242963] loss: 30.577193078858375\n",
            "Epoch: 3763 / 5000\n",
            "w1: [25.08628645] w2: [-22.89763196] bias: [16.30350922] loss: 30.579158152534827\n",
            "Epoch: 3764 / 5000\n",
            "w1: [25.06865239] w2: [-22.90926144] bias: [16.27027761] loss: 30.58513042034255\n",
            "Epoch: 3765 / 5000\n",
            "w1: [25.05939719] w2: [-22.91612092] bias: [16.25901018] loss: 30.588635788946803\n",
            "Epoch: 3766 / 5000\n",
            "w1: [25.0673961] w2: [-22.91172797] bias: [16.28269414] loss: 30.58326984509214\n",
            "Epoch: 3767 / 5000\n",
            "w1: [25.07540861] w2: [-22.91553102] bias: [16.29788885] loss: 30.580072884054\n",
            "Epoch: 3768 / 5000\n",
            "w1: [25.09223074] w2: [-22.90298306] bias: [16.35201339] loss: 30.57693467260774\n",
            "Epoch: 3769 / 5000\n",
            "w1: [25.09248923] w2: [-22.90448463] bias: [16.35208323] loss: 30.576795419975184\n",
            "Epoch: 3770 / 5000\n",
            "w1: [25.09892705] w2: [-22.89538278] bias: [16.36636005] loss: 30.577927024238427\n",
            "Epoch: 3771 / 5000\n",
            "w1: [25.09520275] w2: [-22.90040357] bias: [16.35670484] loss: 30.577140536815286\n",
            "Epoch: 3772 / 5000\n",
            "w1: [25.08203725] w2: [-22.91373948] bias: [16.32766245] loss: 30.577143068826462\n",
            "Epoch: 3773 / 5000\n",
            "w1: [25.09619387] w2: [-22.90653155] bias: [16.35050258] loss: 30.576385721065513\n",
            "Epoch: 3774 / 5000\n",
            "w1: [25.11812988] w2: [-22.90316302] bias: [16.37243136] loss: 30.57709965197179\n",
            "Epoch: 3775 / 5000\n",
            "w1: [25.12419827] w2: [-22.90934421] bias: [16.3684172] loss: 30.575994710295873\n",
            "Epoch: 3776 / 5000\n",
            "w1: [25.11271419] w2: [-22.91319033] bias: [16.35116925] loss: 30.574992100562525\n",
            "Epoch: 3777 / 5000\n",
            "w1: [25.10160316] w2: [-22.9234556] bias: [16.3302979] loss: 30.574770824248255\n",
            "Epoch: 3778 / 5000\n",
            "w1: [25.1027908] w2: [-22.92577702] bias: [16.32924741] loss: 30.57454585125473\n",
            "Epoch: 3779 / 5000\n",
            "w1: [25.10742739] w2: [-22.91850846] bias: [16.34627452] loss: 30.574690641685915\n",
            "Epoch: 3780 / 5000\n",
            "w1: [25.1112557] w2: [-22.92140392] bias: [16.34573249] loss: 30.57423118237231\n",
            "Epoch: 3781 / 5000\n",
            "w1: [25.08919683] w2: [-22.9355212] bias: [16.30420248] loss: 30.57685639535011\n",
            "Epoch: 3782 / 5000\n",
            "w1: [25.08402654] w2: [-22.93999017] bias: [16.30148492] loss: 30.57755741014373\n",
            "Epoch: 3783 / 5000\n",
            "w1: [25.09396451] w2: [-22.93346728] bias: [16.31913712] loss: 30.575282037998758\n",
            "Epoch: 3784 / 5000\n",
            "w1: [25.10392485] w2: [-22.90749567] bias: [16.35862061] loss: 30.57618824857088\n",
            "Epoch: 3785 / 5000\n",
            "w1: [25.0731455] w2: [-22.91944767] bias: [16.31355438] loss: 30.578613509623416\n",
            "Epoch: 3786 / 5000\n",
            "w1: [25.07388479] w2: [-22.91789614] bias: [16.31349838] loss: 30.578616973618214\n",
            "Epoch: 3787 / 5000\n",
            "w1: [25.08053208] w2: [-22.91876817] bias: [16.31963397] loss: 30.577416507056785\n",
            "Epoch: 3788 / 5000\n",
            "w1: [25.07048215] w2: [-22.92861599] bias: [16.31059691] loss: 30.578740639902385\n",
            "Epoch: 3789 / 5000\n",
            "w1: [25.0852732] w2: [-22.93109251] bias: [16.32537783] loss: 30.57589062590732\n",
            "Epoch: 3790 / 5000\n",
            "w1: [25.07384241] w2: [-22.93991007] bias: [16.29977705] loss: 30.57905204180349\n",
            "Epoch: 3791 / 5000\n",
            "w1: [25.08503756] w2: [-22.92818903] bias: [16.32106495] loss: 30.576337681083732\n",
            "Epoch: 3792 / 5000\n",
            "w1: [25.08521369] w2: [-22.93543957] bias: [16.31277485] loss: 30.57653632978253\n",
            "Epoch: 3793 / 5000\n",
            "w1: [25.09323184] w2: [-22.93221312] bias: [16.32394202] loss: 30.57515708484966\n",
            "Epoch: 3794 / 5000\n",
            "w1: [25.09382967] w2: [-22.94515588] bias: [16.32250898] loss: 30.57442823757206\n",
            "Epoch: 3795 / 5000\n",
            "w1: [25.09061798] w2: [-22.94713591] bias: [16.32034864] loss: 30.574779444137377\n",
            "Epoch: 3796 / 5000\n",
            "w1: [25.10291852] w2: [-22.94214769] bias: [16.33232984] loss: 30.573358978758723\n",
            "Epoch: 3797 / 5000\n",
            "w1: [25.10950371] w2: [-22.95203965] bias: [16.33999712] loss: 30.572025161671043\n",
            "Epoch: 3798 / 5000\n",
            "w1: [25.11516837] w2: [-22.9540723] bias: [16.35111955] loss: 30.571509212289666\n",
            "Epoch: 3799 / 5000\n",
            "w1: [25.11147041] w2: [-22.96059001] bias: [16.33900312] loss: 30.571315865430847\n",
            "Epoch: 3800 / 5000\n",
            "w1: [25.09814017] w2: [-22.9690023] bias: [16.31326625] loss: 30.57346301473552\n",
            "Epoch: 3801 / 5000\n",
            "w1: [25.10286267] w2: [-22.97130335] bias: [16.31341605] loss: 30.57282682383518\n",
            "Epoch: 3802 / 5000\n",
            "w1: [25.1119371] w2: [-22.97434886] bias: [16.32195413] loss: 30.571127308300643\n",
            "Epoch: 3803 / 5000\n",
            "w1: [25.12884023] w2: [-22.96787291] bias: [16.34813784] loss: 30.569643285144814\n",
            "Epoch: 3804 / 5000\n",
            "w1: [25.13419631] w2: [-22.9682827] bias: [16.35178133] loss: 30.569400167275983\n",
            "Epoch: 3805 / 5000\n",
            "w1: [25.13201452] w2: [-22.9784949] bias: [16.34283018] loss: 30.56864545395431\n",
            "Epoch: 3806 / 5000\n",
            "w1: [25.10524302] w2: [-22.99211492] bias: [16.30620547] loss: 30.57238761716528\n",
            "Epoch: 3807 / 5000\n",
            "w1: [25.10501897] w2: [-22.99370686] bias: [16.30748781] loss: 30.572214691940015\n",
            "Epoch: 3808 / 5000\n",
            "w1: [25.08887694] w2: [-22.99933312] bias: [16.28193078] loss: 30.577985671787363\n",
            "Epoch: 3809 / 5000\n",
            "w1: [25.07114413] w2: [-22.9967197] bias: [16.25819404] loss: 30.586133308326765\n",
            "Epoch: 3810 / 5000\n",
            "w1: [25.05369974] w2: [-23.00424364] bias: [16.23049027] loss: 30.597794311498816\n",
            "Epoch: 3811 / 5000\n",
            "w1: [25.06636073] w2: [-23.01209741] bias: [16.23346715] loss: 30.59415136790617\n",
            "Epoch: 3812 / 5000\n",
            "w1: [25.08545524] w2: [-23.01165612] bias: [16.2555285] loss: 30.584097552612608\n",
            "Epoch: 3813 / 5000\n",
            "w1: [25.08079432] w2: [-23.02067522] bias: [16.23960681] loss: 30.589346570618158\n",
            "Epoch: 3814 / 5000\n",
            "w1: [25.07565674] w2: [-23.02697582] bias: [16.22616251] loss: 30.59471402544225\n",
            "Epoch: 3815 / 5000\n",
            "w1: [25.07978126] w2: [-23.02628699] bias: [16.23682461] loss: 30.590479019232344\n",
            "Epoch: 3816 / 5000\n",
            "w1: [25.07823745] w2: [-23.03243688] bias: [16.22821135] loss: 30.593617604069056\n",
            "Epoch: 3817 / 5000\n",
            "w1: [25.07646211] w2: [-23.04492062] bias: [16.21237346] loss: 30.599840585119793\n",
            "Epoch: 3818 / 5000\n",
            "w1: [25.08299014] w2: [-23.03158921] bias: [16.22979536] loss: 30.592020808792963\n",
            "Epoch: 3819 / 5000\n",
            "w1: [25.08036876] w2: [-23.03688683] bias: [16.21925965] loss: 30.596189333275625\n",
            "Epoch: 3820 / 5000\n",
            "w1: [25.08461959] w2: [-23.03928831] bias: [16.2212241] loss: 30.59460870571772\n",
            "Epoch: 3821 / 5000\n",
            "w1: [25.08815804] w2: [-23.03799746] bias: [16.22221308] loss: 30.593422349658965\n",
            "Epoch: 3822 / 5000\n",
            "w1: [25.0854331] w2: [-23.0382505] bias: [16.21893933] loss: 30.595141026746138\n",
            "Epoch: 3823 / 5000\n",
            "w1: [25.08369733] w2: [-23.03759836] bias: [16.21830294] loss: 30.595743137502826\n",
            "Epoch: 3824 / 5000\n",
            "w1: [25.09520849] w2: [-23.03109427] bias: [16.25066091] loss: 30.58355702892188\n",
            "Epoch: 3825 / 5000\n",
            "w1: [25.08548692] w2: [-23.03991149] bias: [16.22984973] loss: 30.591658857337226\n",
            "Epoch: 3826 / 5000\n",
            "w1: [25.0744127] w2: [-23.03776216] bias: [16.21715084] loss: 30.59837863874507\n",
            "Epoch: 3827 / 5000\n",
            "w1: [25.08528457] w2: [-23.03949732] bias: [16.22796745] loss: 30.592284325553457\n",
            "Epoch: 3828 / 5000\n",
            "w1: [25.09101547] w2: [-23.03762145] bias: [16.23456967] loss: 30.588949521074827\n",
            "Epoch: 3829 / 5000\n",
            "w1: [25.08571557] w2: [-23.03879966] bias: [16.22409656] loss: 30.593401514134236\n",
            "Epoch: 3830 / 5000\n",
            "w1: [25.08505297] w2: [-23.02117926] bias: [16.23611046] loss: 30.589453600808394\n",
            "Epoch: 3831 / 5000\n",
            "w1: [25.08889585] w2: [-23.01886598] bias: [16.24160862] loss: 30.58707100253761\n",
            "Epoch: 3832 / 5000\n",
            "w1: [25.08601477] w2: [-23.01015204] bias: [16.23809636] loss: 30.588512934217373\n",
            "Epoch: 3833 / 5000\n",
            "w1: [25.08807249] w2: [-22.99705322] bias: [16.24920734] loss: 30.585091427999803\n",
            "Epoch: 3834 / 5000\n",
            "w1: [25.08247568] w2: [-22.99997294] bias: [16.23584659] loss: 30.589737553840255\n",
            "Epoch: 3835 / 5000\n",
            "w1: [25.06252671] w2: [-23.01602592] bias: [16.19622883] loss: 30.60820784053504\n",
            "Epoch: 3836 / 5000\n",
            "w1: [25.07224342] w2: [-23.0298991] bias: [16.19527136] loss: 30.606656545638085\n",
            "Epoch: 3837 / 5000\n",
            "w1: [25.06606144] w2: [-23.03026418] bias: [16.18590369] loss: 30.61212545012828\n",
            "Epoch: 3838 / 5000\n",
            "w1: [25.06544154] w2: [-23.02323459] bias: [16.19326679] loss: 30.608938433025813\n",
            "Epoch: 3839 / 5000\n",
            "w1: [25.06553814] w2: [-23.01050564] bias: [16.19483187] loss: 30.607691426219308\n",
            "Epoch: 3840 / 5000\n",
            "w1: [25.07503883] w2: [-22.99828191] bias: [16.21436836] loss: 30.59788659454447\n",
            "Epoch: 3841 / 5000\n",
            "w1: [25.09151934] w2: [-22.99469652] bias: [16.23825878] loss: 30.58717699884378\n",
            "Epoch: 3842 / 5000\n",
            "w1: [25.09523922] w2: [-22.99807228] bias: [16.23766588] loss: 30.586616818475527\n",
            "Epoch: 3843 / 5000\n",
            "w1: [25.10556032] w2: [-22.99498172] bias: [16.24665647] loss: 30.582420885849732\n",
            "Epoch: 3844 / 5000\n",
            "w1: [25.09854942] w2: [-23.00344563] bias: [16.22338462] loss: 30.589932740437327\n",
            "Epoch: 3845 / 5000\n",
            "w1: [25.10071271] w2: [-23.00387962] bias: [16.24114862] loss: 30.584688256850452\n",
            "Epoch: 3846 / 5000\n",
            "w1: [25.11293008] w2: [-23.00659623] bias: [16.24811687] loss: 30.580737268076177\n",
            "Epoch: 3847 / 5000\n",
            "w1: [25.11337628] w2: [-23.0046721] bias: [16.24978211] loss: 30.580286579058946\n",
            "Epoch: 3848 / 5000\n",
            "w1: [25.14015747] w2: [-22.99467246] bias: [16.29487139] loss: 30.56939676345189\n",
            "Epoch: 3849 / 5000\n",
            "w1: [25.12994846] w2: [-22.99508601] bias: [16.27906106] loss: 30.572529871312273\n",
            "Epoch: 3850 / 5000\n",
            "w1: [25.1388164] w2: [-22.99064836] bias: [16.28993369] loss: 30.570210627807626\n",
            "Epoch: 3851 / 5000\n",
            "w1: [25.15029818] w2: [-22.98566481] bias: [16.30948175] loss: 30.56769722715049\n",
            "Epoch: 3852 / 5000\n",
            "w1: [25.15163448] w2: [-22.97189732] bias: [16.31772981] loss: 30.568062818786927\n",
            "Epoch: 3853 / 5000\n",
            "w1: [25.16338316] w2: [-22.9773792] bias: [16.32653241] loss: 30.5667802858132\n",
            "Epoch: 3854 / 5000\n",
            "w1: [25.14503111] w2: [-22.98837978] bias: [16.30333081] loss: 30.568437934469085\n",
            "Epoch: 3855 / 5000\n",
            "w1: [25.13662915] w2: [-22.98504802] bias: [16.29909178] loss: 30.56979673268168\n",
            "Epoch: 3856 / 5000\n",
            "w1: [25.13997275] w2: [-22.98335366] bias: [16.31795778] loss: 30.56831261244282\n",
            "Epoch: 3857 / 5000\n",
            "w1: [25.15214642] w2: [-22.97131223] bias: [16.35181525] loss: 30.568356143153462\n",
            "Epoch: 3858 / 5000\n",
            "w1: [25.14591919] w2: [-22.97782288] bias: [16.33630745] loss: 30.567827409577713\n",
            "Epoch: 3859 / 5000\n",
            "w1: [25.1636076] w2: [-22.98098737] bias: [16.35355028] loss: 30.5672004630289\n",
            "Epoch: 3860 / 5000\n",
            "w1: [25.17288208] w2: [-22.97934268] bias: [16.36976893] loss: 30.56834044009064\n",
            "Epoch: 3861 / 5000\n",
            "w1: [25.16957896] w2: [-22.98557686] bias: [16.36409027] loss: 30.567311225179246\n",
            "Epoch: 3862 / 5000\n",
            "w1: [25.15859995] w2: [-22.99003889] bias: [16.34446476] loss: 30.56633374725128\n",
            "Epoch: 3863 / 5000\n",
            "w1: [25.17460534] w2: [-22.98529993] bias: [16.36533048] loss: 30.567343601155418\n",
            "Epoch: 3864 / 5000\n",
            "w1: [25.17764471] w2: [-22.975214] bias: [16.37429377] loss: 30.569192501798042\n",
            "Epoch: 3865 / 5000\n",
            "w1: [25.16694228] w2: [-22.98102875] bias: [16.3584346] loss: 30.567383295942562\n",
            "Epoch: 3866 / 5000\n",
            "w1: [25.15750519] w2: [-22.98828062] bias: [16.33909056] loss: 30.566424180110932\n",
            "Epoch: 3867 / 5000\n",
            "w1: [25.18827868] w2: [-22.98324726] bias: [16.37455066] loss: 30.568384197790966\n",
            "Epoch: 3868 / 5000\n",
            "w1: [25.16803297] w2: [-23.0010832] bias: [16.33085372] loss: 30.564867455375676\n",
            "Epoch: 3869 / 5000\n",
            "w1: [25.1672018] w2: [-22.99472519] bias: [16.33175607] loss: 30.56535462828475\n",
            "Epoch: 3870 / 5000\n",
            "w1: [25.16143738] w2: [-22.98986573] bias: [16.33389258] loss: 30.566041596030495\n",
            "Epoch: 3871 / 5000\n",
            "w1: [25.16580133] w2: [-22.98785233] bias: [16.33691759] loss: 30.56598081951614\n",
            "Epoch: 3872 / 5000\n",
            "w1: [25.14915824] w2: [-22.99920368] bias: [16.30123085] loss: 30.567678565155205\n",
            "Epoch: 3873 / 5000\n",
            "w1: [25.12870146] w2: [-23.01012995] bias: [16.26226694] loss: 30.57513647873721\n",
            "Epoch: 3874 / 5000\n",
            "w1: [25.12903713] w2: [-23.01312316] bias: [16.25358132] loss: 30.576734247218834\n",
            "Epoch: 3875 / 5000\n",
            "w1: [25.11966781] w2: [-23.01378696] bias: [16.2365152] loss: 30.58225602003966\n",
            "Epoch: 3876 / 5000\n",
            "w1: [25.12679327] w2: [-23.01597659] bias: [16.24453232] loss: 30.579050644869195\n",
            "Epoch: 3877 / 5000\n",
            "w1: [25.15223436] w2: [-22.99671901] bias: [16.30325102] loss: 30.56733704798083\n",
            "Epoch: 3878 / 5000\n",
            "w1: [25.1431992] w2: [-23.00340497] bias: [16.28084817] loss: 30.570308939638316\n",
            "Epoch: 3879 / 5000\n",
            "w1: [25.13173469] w2: [-23.00999627] bias: [16.25725703] loss: 30.575594290767803\n",
            "Epoch: 3880 / 5000\n",
            "w1: [25.12259548] w2: [-23.0062804] bias: [16.251397] loss: 30.578319661177943\n",
            "Epoch: 3881 / 5000\n",
            "w1: [25.1315934] w2: [-22.99932372] bias: [16.27864312] loss: 30.57225253424695\n",
            "Epoch: 3882 / 5000\n",
            "w1: [25.15394308] w2: [-22.99605549] bias: [16.30175477] loss: 30.56730638203163\n",
            "Epoch: 3883 / 5000\n",
            "w1: [25.1633943] w2: [-22.98558739] bias: [16.32200276] loss: 30.5662569788166\n",
            "Epoch: 3884 / 5000\n",
            "w1: [25.16332446] w2: [-22.99423491] bias: [16.33070569] loss: 30.565619997693027\n",
            "Epoch: 3885 / 5000\n",
            "w1: [25.16169752] w2: [-23.00155894] bias: [16.33016396] loss: 30.565238316607275\n",
            "Epoch: 3886 / 5000\n",
            "w1: [25.17841528] w2: [-23.00701956] bias: [16.35406403] loss: 30.564548632989826\n",
            "Epoch: 3887 / 5000\n",
            "w1: [25.1816714] w2: [-23.01022849] bias: [16.36186365] loss: 30.564665824498203\n",
            "Epoch: 3888 / 5000\n",
            "w1: [25.18598735] w2: [-23.01220579] bias: [16.36340595] loss: 30.564512128222518\n",
            "Epoch: 3889 / 5000\n",
            "w1: [25.17051693] w2: [-23.01254467] bias: [16.34625384] loss: 30.564115044626362\n",
            "Epoch: 3890 / 5000\n",
            "w1: [25.15889413] w2: [-23.01697706] bias: [16.32990006] loss: 30.564466013100528\n",
            "Epoch: 3891 / 5000\n",
            "w1: [25.1567452] w2: [-23.01630495] bias: [16.3204403] loss: 30.564972164673293\n",
            "Epoch: 3892 / 5000\n",
            "w1: [25.1547334] w2: [-23.01926356] bias: [16.32068854] loss: 30.564970352148524\n",
            "Epoch: 3893 / 5000\n",
            "w1: [25.17313296] w2: [-23.01563297] bias: [16.35317912] loss: 30.56399768138489\n",
            "Epoch: 3894 / 5000\n",
            "w1: [25.18697199] w2: [-23.01336144] bias: [16.37193775] loss: 30.56511891358822\n",
            "Epoch: 3895 / 5000\n",
            "w1: [25.19578196] w2: [-23.0155694] bias: [16.37805924] loss: 30.565497901303083\n",
            "Epoch: 3896 / 5000\n",
            "w1: [25.19280587] w2: [-23.00362668] bias: [16.3925434] loss: 30.568624692517112\n",
            "Epoch: 3897 / 5000\n",
            "w1: [25.18454459] w2: [-23.01009339] bias: [16.37579221] loss: 30.565828705521923\n",
            "Epoch: 3898 / 5000\n",
            "w1: [25.17641599] w2: [-23.01778844] bias: [16.35597813] loss: 30.563830666509336\n",
            "Epoch: 3899 / 5000\n",
            "w1: [25.1924442] w2: [-23.01706087] bias: [16.36807705] loss: 30.56435607827945\n",
            "Epoch: 3900 / 5000\n",
            "w1: [25.18297084] w2: [-23.02967364] bias: [16.34221929] loss: 30.56218223255808\n",
            "Epoch: 3901 / 5000\n",
            "w1: [25.20489396] w2: [-23.01890424] bias: [16.38746192] loss: 30.56641783773638\n",
            "Epoch: 3902 / 5000\n",
            "w1: [25.20241032] w2: [-23.01353817] bias: [16.39066518] loss: 30.567421930753042\n",
            "Epoch: 3903 / 5000\n",
            "w1: [25.20974617] w2: [-23.01332161] bias: [16.39592876] loss: 30.568439727086698\n",
            "Epoch: 3904 / 5000\n",
            "w1: [25.20586409] w2: [-23.02038227] bias: [16.39913547] loss: 30.568050125563897\n",
            "Epoch: 3905 / 5000\n",
            "w1: [25.21556767] w2: [-23.00761517] bias: [16.41725061] loss: 30.57347650365412\n",
            "Epoch: 3906 / 5000\n",
            "w1: [25.19596533] w2: [-23.01823583] bias: [16.38015126] loss: 30.565471953684295\n",
            "Epoch: 3907 / 5000\n",
            "w1: [25.2004017] w2: [-23.01312934] bias: [16.3859335] loss: 30.566764915592\n",
            "Epoch: 3908 / 5000\n",
            "w1: [25.20177005] w2: [-23.01035413] bias: [16.38314007] loss: 30.56669937586614\n",
            "Epoch: 3909 / 5000\n",
            "w1: [25.18800049] w2: [-23.01629635] bias: [16.36000702] loss: 30.563860701283346\n",
            "Epoch: 3910 / 5000\n",
            "w1: [25.16780452] w2: [-23.02276192] bias: [16.32565106] loss: 30.56357752856601\n",
            "Epoch: 3911 / 5000\n",
            "w1: [25.15809183] w2: [-23.03477527] bias: [16.30516494] loss: 30.564926553275026\n",
            "Epoch: 3912 / 5000\n",
            "w1: [25.15018344] w2: [-23.02818171] bias: [16.30207493] loss: 30.56629443259175\n",
            "Epoch: 3913 / 5000\n",
            "w1: [25.14703053] w2: [-23.02768364] bias: [16.29639556] loss: 30.56723674150058\n",
            "Epoch: 3914 / 5000\n",
            "w1: [25.14104941] w2: [-23.02926311] bias: [16.28668313] loss: 30.569100181598216\n",
            "Epoch: 3915 / 5000\n",
            "w1: [25.13144929] w2: [-23.02119789] bias: [16.27618541] loss: 30.572147563085174\n",
            "Epoch: 3916 / 5000\n",
            "w1: [25.12828058] w2: [-23.01791498] bias: [16.27376618] loss: 30.57306685338807\n",
            "Epoch: 3917 / 5000\n",
            "w1: [25.13045828] w2: [-23.01564516] bias: [16.27151332] loss: 30.57315920657983\n",
            "Epoch: 3918 / 5000\n",
            "w1: [25.13182543] w2: [-23.00084613] bias: [16.2818959] loss: 30.571727889567757\n",
            "Epoch: 3919 / 5000\n",
            "w1: [25.1380322] w2: [-23.00080826] bias: [16.29032531] loss: 30.56989443758176\n",
            "Epoch: 3920 / 5000\n",
            "w1: [25.12419084] w2: [-23.01176587] bias: [16.26251915] loss: 30.5757875128305\n",
            "Epoch: 3921 / 5000\n",
            "w1: [25.12646345] w2: [-23.01705514] bias: [16.2510968] loss: 30.57766811494987\n",
            "Epoch: 3922 / 5000\n",
            "w1: [25.12704017] w2: [-23.0037668] bias: [16.26969219] loss: 30.57418592266934\n",
            "Epoch: 3923 / 5000\n",
            "w1: [25.12243035] w2: [-23.01341891] bias: [16.2582661] loss: 30.57688933520163\n",
            "Epoch: 3924 / 5000\n",
            "w1: [25.14432297] w2: [-22.99723084] bias: [16.29999748] loss: 30.568368341959943\n",
            "Epoch: 3925 / 5000\n",
            "w1: [25.15729166] w2: [-22.9743804] bias: [16.33368374] loss: 30.567390097026053\n",
            "Epoch: 3926 / 5000\n",
            "w1: [25.13056793] w2: [-22.98937807] bias: [16.29056148] loss: 30.571172767698126\n",
            "Epoch: 3927 / 5000\n",
            "w1: [25.11938781] w2: [-22.98958071] bias: [16.27559] loss: 30.574653249207785\n",
            "Epoch: 3928 / 5000\n",
            "w1: [25.12399098] w2: [-22.98852559] bias: [16.279163] loss: 30.573504186704195\n",
            "Epoch: 3929 / 5000\n",
            "w1: [25.13853949] w2: [-22.9837124] bias: [16.29569013] loss: 30.569950166061247\n",
            "Epoch: 3930 / 5000\n",
            "w1: [25.14964938] w2: [-22.96988629] bias: [16.33160251] loss: 30.568155166971174\n",
            "Epoch: 3931 / 5000\n",
            "w1: [25.14730726] w2: [-22.96717713] bias: [16.32709454] loss: 30.56851434383082\n",
            "Epoch: 3932 / 5000\n",
            "w1: [25.15322105] w2: [-22.96076694] bias: [16.33881359] loss: 30.568727550097076\n",
            "Epoch: 3933 / 5000\n",
            "w1: [25.16402664] w2: [-22.95830597] bias: [16.34922089] loss: 30.56891981433734\n",
            "Epoch: 3934 / 5000\n",
            "w1: [25.16682948] w2: [-22.9586431] bias: [16.35660119] loss: 30.56930386590494\n",
            "Epoch: 3935 / 5000\n",
            "w1: [25.16189016] w2: [-22.94691123] bias: [16.35466444] loss: 30.570378422540184\n",
            "Epoch: 3936 / 5000\n",
            "w1: [25.17075542] w2: [-22.9465193] bias: [16.36372254] loss: 30.571056988527058\n",
            "Epoch: 3937 / 5000\n",
            "w1: [25.15879227] w2: [-22.94532261] bias: [16.35376269] loss: 30.57054153772389\n",
            "Epoch: 3938 / 5000\n",
            "w1: [25.16387283] w2: [-22.94117611] bias: [16.35470986] loss: 30.570883208104664\n",
            "Epoch: 3939 / 5000\n",
            "w1: [25.16650452] w2: [-22.94692009] bias: [16.34946013] loss: 30.56989260812566\n",
            "Epoch: 3940 / 5000\n",
            "w1: [25.15387731] w2: [-22.95696503] bias: [16.32333935] loss: 30.568815264095644\n",
            "Epoch: 3941 / 5000\n",
            "w1: [25.15743664] w2: [-22.96741069] bias: [16.32180202] loss: 30.56786915117211\n",
            "Epoch: 3942 / 5000\n",
            "w1: [25.14679336] w2: [-22.97062818] bias: [16.31238341] loss: 30.568706404597304\n",
            "Epoch: 3943 / 5000\n",
            "w1: [25.13655829] w2: [-22.97964961] bias: [16.29867071] loss: 30.57007969845029\n",
            "Epoch: 3944 / 5000\n",
            "w1: [25.13846803] w2: [-22.97850093] bias: [16.30490511] loss: 30.569456252240553\n",
            "Epoch: 3945 / 5000\n",
            "w1: [25.13321238] w2: [-22.98620821] bias: [16.29430486] loss: 30.570579011398234\n",
            "Epoch: 3946 / 5000\n",
            "w1: [25.13662729] w2: [-22.9880536] bias: [16.29387492] loss: 30.570158101153964\n",
            "Epoch: 3947 / 5000\n",
            "w1: [25.14013739] w2: [-22.99258531] bias: [16.2979297] loss: 30.569196663286245\n",
            "Epoch: 3948 / 5000\n",
            "w1: [25.16597571] w2: [-22.98986662] bias: [16.3354513] loss: 30.565801437696095\n",
            "Epoch: 3949 / 5000\n",
            "w1: [25.1752982] w2: [-22.98597213] bias: [16.3573715] loss: 30.566654833998125\n",
            "Epoch: 3950 / 5000\n",
            "w1: [25.16783865] w2: [-22.98946972] bias: [16.34308984] loss: 30.56590734414207\n",
            "Epoch: 3951 / 5000\n",
            "w1: [25.18697832] w2: [-22.98212627] bias: [16.38563992] loss: 30.569931287274517\n",
            "Epoch: 3952 / 5000\n",
            "w1: [25.17733468] w2: [-22.98584415] bias: [16.36659566] loss: 30.567361098316734\n",
            "Epoch: 3953 / 5000\n",
            "w1: [25.17727389] w2: [-22.99387234] bias: [16.35280841] loss: 30.565621123115697\n",
            "Epoch: 3954 / 5000\n",
            "w1: [25.17213072] w2: [-22.99543933] bias: [16.33915942] loss: 30.565143789990074\n",
            "Epoch: 3955 / 5000\n",
            "w1: [25.17640953] w2: [-22.98814972] bias: [16.35058223] loss: 30.566010216397245\n",
            "Epoch: 3956 / 5000\n",
            "w1: [25.16420044] w2: [-22.99632239] bias: [16.32520279] loss: 30.565465483823967\n",
            "Epoch: 3957 / 5000\n",
            "w1: [25.19170421] w2: [-22.98911598] bias: [16.36573894] loss: 30.566811198957254\n",
            "Epoch: 3958 / 5000\n",
            "w1: [25.18791834] w2: [-23.00080893] bias: [16.34973528] loss: 30.564535696595865\n",
            "Epoch: 3959 / 5000\n",
            "w1: [25.20440206] w2: [-22.99565316] bias: [16.36900282] loss: 30.56647652479682\n",
            "Epoch: 3960 / 5000\n",
            "w1: [25.18521956] w2: [-23.00972697] bias: [16.33489939] loss: 30.563358409270386\n",
            "Epoch: 3961 / 5000\n",
            "w1: [25.18053282] w2: [-23.00490839] bias: [16.32676238] loss: 30.563858360174887\n",
            "Epoch: 3962 / 5000\n",
            "w1: [25.18188227] w2: [-23.00419896] bias: [16.32675142] loss: 30.56382778236691\n",
            "Epoch: 3963 / 5000\n",
            "w1: [25.17483225] w2: [-23.00310113] bias: [16.31581969] loss: 30.564473846644923\n",
            "Epoch: 3964 / 5000\n",
            "w1: [25.16717817] w2: [-23.01141519] bias: [16.29248027] loss: 30.566004094738155\n",
            "Epoch: 3965 / 5000\n",
            "w1: [25.17715437] w2: [-23.01552925] bias: [16.29853337] loss: 30.56438681999264\n",
            "Epoch: 3966 / 5000\n",
            "w1: [25.1861078] w2: [-23.0150968] bias: [16.30845314] loss: 30.56315168511063\n",
            "Epoch: 3967 / 5000\n",
            "w1: [25.17588178] w2: [-23.01417933] bias: [16.29288689] loss: 30.56496732695918\n",
            "Epoch: 3968 / 5000\n",
            "w1: [25.17618061] w2: [-23.00778628] bias: [16.29547525] loss: 30.565041994617133\n",
            "Epoch: 3969 / 5000\n",
            "w1: [25.18532247] w2: [-23.00505671] bias: [16.30469525] loss: 30.563907073572242\n",
            "Epoch: 3970 / 5000\n",
            "w1: [25.17485476] w2: [-23.00093969] bias: [16.29243544] loss: 30.565696393447844\n",
            "Epoch: 3971 / 5000\n",
            "w1: [25.18723524] w2: [-22.98420013] bias: [16.32036268] loss: 30.564876226065106\n",
            "Epoch: 3972 / 5000\n",
            "w1: [25.16280606] w2: [-23.00097148] bias: [16.27608564] loss: 30.568524546496032\n",
            "Epoch: 3973 / 5000\n",
            "w1: [25.17629273] w2: [-23.00711253] bias: [16.28551805] loss: 30.565822409612693\n",
            "Epoch: 3974 / 5000\n",
            "w1: [25.17526033] w2: [-23.01375802] bias: [16.27425472] loss: 30.566821411815393\n",
            "Epoch: 3975 / 5000\n",
            "w1: [25.16426869] w2: [-23.02343415] bias: [16.25088253] loss: 30.57150835908958\n",
            "Epoch: 3976 / 5000\n",
            "w1: [25.16366656] w2: [-23.02853308] bias: [16.2527113] loss: 30.5712120481474\n",
            "Epoch: 3977 / 5000\n",
            "w1: [25.16444844] w2: [-23.01760105] bias: [16.26663145] loss: 30.569063546837576\n",
            "Epoch: 3978 / 5000\n",
            "w1: [25.17546405] w2: [-23.01705144] bias: [16.2884593] loss: 30.56525183468371\n",
            "Epoch: 3979 / 5000\n",
            "w1: [25.15363291] w2: [-23.03195359] bias: [16.24745522] loss: 30.57377071546602\n",
            "Epoch: 3980 / 5000\n",
            "w1: [25.17297724] w2: [-23.01966437] bias: [16.28161417] loss: 30.566085728348348\n",
            "Epoch: 3981 / 5000\n",
            "w1: [25.17117354] w2: [-23.00767187] bias: [16.28973626] loss: 30.565975399366256\n",
            "Epoch: 3982 / 5000\n",
            "w1: [25.17589558] w2: [-23.0073543] bias: [16.31154644] loss: 30.564272847774724\n",
            "Epoch: 3983 / 5000\n",
            "w1: [25.16155174] w2: [-23.01791401] bias: [16.28231409] loss: 30.567406458470913\n",
            "Epoch: 3984 / 5000\n",
            "w1: [25.16966191] w2: [-23.02760868] bias: [16.28554807] loss: 30.565779943840447\n",
            "Epoch: 3985 / 5000\n",
            "w1: [25.18119021] w2: [-23.03082278] bias: [16.29474634] loss: 30.56358735541241\n",
            "Epoch: 3986 / 5000\n",
            "w1: [25.18095924] w2: [-23.02139575] bias: [16.29885882] loss: 30.563738309221346\n",
            "Epoch: 3987 / 5000\n",
            "w1: [25.18157243] w2: [-23.02430087] bias: [16.29814026] loss: 30.56359354014631\n",
            "Epoch: 3988 / 5000\n",
            "w1: [25.17387884] w2: [-23.02887223] bias: [16.28300826] loss: 30.56552289159685\n",
            "Epoch: 3989 / 5000\n",
            "w1: [25.17546878] w2: [-23.02271441] bias: [16.29276919] loss: 30.56465709008193\n",
            "Epoch: 3990 / 5000\n",
            "w1: [25.16611332] w2: [-23.02552615] bias: [16.2733472] loss: 30.567724380539136\n",
            "Epoch: 3991 / 5000\n",
            "w1: [25.14165985] w2: [-23.03803385] bias: [16.23028137] loss: 30.579803770134042\n",
            "Epoch: 3992 / 5000\n",
            "w1: [25.13852779] w2: [-23.03559271] bias: [16.22556452] loss: 30.581597312488615\n",
            "Epoch: 3993 / 5000\n",
            "w1: [25.13212446] w2: [-23.04561612] bias: [16.20908692] loss: 30.587847066866743\n",
            "Epoch: 3994 / 5000\n",
            "w1: [25.1405691] w2: [-23.05260448] bias: [16.2116371] loss: 30.585412837028933\n",
            "Epoch: 3995 / 5000\n",
            "w1: [25.13259575] w2: [-23.05964443] bias: [16.19435338] loss: 30.59303030966919\n",
            "Epoch: 3996 / 5000\n",
            "w1: [25.13615626] w2: [-23.05178265] bias: [16.20347478] loss: 30.58888663427246\n",
            "Epoch: 3997 / 5000\n",
            "w1: [25.13932152] w2: [-23.06407748] bias: [16.19592221] loss: 30.5910647123921\n",
            "Epoch: 3998 / 5000\n",
            "w1: [25.13463184] w2: [-23.06807165] bias: [16.18659887] loss: 30.595647355160683\n",
            "Epoch: 3999 / 5000\n",
            "w1: [25.1368434] w2: [-23.06668882] bias: [16.19034247] loss: 30.593696034733536\n",
            "Epoch: 4000 / 5000\n",
            "w1: [25.12527015] w2: [-23.06518172] bias: [16.17693197] loss: 30.601562316101933\n",
            "Epoch: 4001 / 5000\n",
            "w1: [25.12360384] w2: [-23.07865602] bias: [16.16212951] loss: 30.608921937198133\n",
            "Epoch: 4002 / 5000\n",
            "w1: [25.11418834] w2: [-23.07645903] bias: [16.1509958] loss: 30.616493548213235\n",
            "Epoch: 4003 / 5000\n",
            "w1: [25.1032619] w2: [-23.06900501] bias: [16.13570832] loss: 30.626638780344223\n",
            "Epoch: 4004 / 5000\n",
            "w1: [25.10780277] w2: [-23.06047211] bias: [16.14781028] loss: 30.6186959435372\n",
            "Epoch: 4005 / 5000\n",
            "w1: [25.1100301] w2: [-23.04807292] bias: [16.16435932] loss: 30.609853280061134\n",
            "Epoch: 4006 / 5000\n",
            "w1: [25.12450197] w2: [-23.04584833] bias: [16.18486505] loss: 30.597810176150634\n",
            "Epoch: 4007 / 5000\n",
            "w1: [25.13265336] w2: [-23.04163355] bias: [16.20666721] loss: 30.58836824823451\n",
            "Epoch: 4008 / 5000\n",
            "w1: [25.13233462] w2: [-23.03430915] bias: [16.2094897] loss: 30.58738580283848\n",
            "Epoch: 4009 / 5000\n",
            "w1: [25.13667599] w2: [-23.03640947] bias: [16.21631925] loss: 30.584512111549813\n",
            "Epoch: 4010 / 5000\n",
            "w1: [25.13620411] w2: [-23.033972] bias: [16.22418515] loss: 30.582402097271554\n",
            "Epoch: 4011 / 5000\n",
            "w1: [25.13818065] w2: [-23.04138878] bias: [16.21776065] loss: 30.583888254870587\n",
            "Epoch: 4012 / 5000\n",
            "w1: [25.1284785] w2: [-23.03472998] bias: [16.21200516] loss: 30.587479157812208\n",
            "Epoch: 4013 / 5000\n",
            "w1: [25.13963547] w2: [-23.03663802] bias: [16.2333111] loss: 30.57942136486831\n",
            "Epoch: 4014 / 5000\n",
            "w1: [25.13021422] w2: [-23.03993279] bias: [16.2224729] loss: 30.584185838898136\n",
            "Epoch: 4015 / 5000\n",
            "w1: [25.13526199] w2: [-23.04530845] bias: [16.22026853] loss: 30.583862865320665\n",
            "Epoch: 4016 / 5000\n",
            "w1: [25.12713636] w2: [-23.0520989] bias: [16.20196873] loss: 30.59146151523552\n",
            "Epoch: 4017 / 5000\n",
            "w1: [25.11970914] w2: [-23.05389514] bias: [16.18878824] loss: 30.5979407740298\n",
            "Epoch: 4018 / 5000\n",
            "w1: [25.11697514] w2: [-23.05370661] bias: [16.18223099] loss: 30.601090320038008\n",
            "Epoch: 4019 / 5000\n",
            "w1: [25.10398091] w2: [-23.06402793] bias: [16.15225308] loss: 30.618058203374837\n",
            "Epoch: 4020 / 5000\n",
            "w1: [25.10469394] w2: [-23.06279078] bias: [16.15647949] loss: 30.615820536355308\n",
            "Epoch: 4021 / 5000\n",
            "w1: [25.11310919] w2: [-23.07280478] bias: [16.16149967] loss: 30.611813194261934\n",
            "Epoch: 4022 / 5000\n",
            "w1: [25.11958964] w2: [-23.05898373] bias: [16.17734164] loss: 30.602573129362696\n",
            "Epoch: 4023 / 5000\n",
            "w1: [25.13803947] w2: [-23.05662232] bias: [16.20222073] loss: 30.589016154347178\n",
            "Epoch: 4024 / 5000\n",
            "w1: [25.15273736] w2: [-23.05035313] bias: [16.22629468] loss: 30.57882553209455\n",
            "Epoch: 4025 / 5000\n",
            "w1: [25.17494214] w2: [-23.04455632] bias: [16.25896744] loss: 30.568255477660657\n",
            "Epoch: 4026 / 5000\n",
            "w1: [25.17318919] w2: [-23.05085769] bias: [16.24972095] loss: 30.570070561799678\n",
            "Epoch: 4027 / 5000\n",
            "w1: [25.18444354] w2: [-23.0436709] bias: [16.27921923] loss: 30.564243418355442\n",
            "Epoch: 4028 / 5000\n",
            "w1: [25.16112533] w2: [-23.04482042] bias: [16.24324006] loss: 30.573343108652306\n",
            "Epoch: 4029 / 5000\n",
            "w1: [25.17628776] w2: [-23.04543846] bias: [16.26267246] loss: 30.567460685839954\n",
            "Epoch: 4030 / 5000\n",
            "w1: [25.18045454] w2: [-23.03699301] bias: [16.27919061] loss: 30.564917418953556\n",
            "Epoch: 4031 / 5000\n",
            "w1: [25.1854356] w2: [-23.04074738] bias: [16.27826805] loss: 30.56432241014901\n",
            "Epoch: 4032 / 5000\n",
            "w1: [25.18578619] w2: [-23.04495377] bias: [16.2753445] loss: 30.56449578090405\n",
            "Epoch: 4033 / 5000\n",
            "w1: [25.18184188] w2: [-23.04930066] bias: [16.26503601] loss: 30.566270494341484\n",
            "Epoch: 4034 / 5000\n",
            "w1: [25.19457646] w2: [-23.03475995] bias: [16.29141026] loss: 30.562363339307336\n",
            "Epoch: 4035 / 5000\n",
            "w1: [25.19869949] w2: [-23.0223986] bias: [16.30718051] loss: 30.561831120968368\n",
            "Epoch: 4036 / 5000\n",
            "w1: [25.18002916] w2: [-23.03124659] bias: [16.28233541] loss: 30.564812602058993\n",
            "Epoch: 4037 / 5000\n",
            "w1: [25.16868552] w2: [-23.02988042] bias: [16.26509998] loss: 30.56843950319931\n",
            "Epoch: 4038 / 5000\n",
            "w1: [25.17459219] w2: [-23.02920867] bias: [16.2741503] loss: 30.56645010655989\n",
            "Epoch: 4039 / 5000\n",
            "w1: [25.16895929] w2: [-23.03118363] bias: [16.26666351] loss: 30.568144290929062\n",
            "Epoch: 4040 / 5000\n",
            "w1: [25.1718989] w2: [-23.03232414] bias: [16.26729229] loss: 30.567632793176756\n",
            "Epoch: 4041 / 5000\n",
            "w1: [25.15997307] w2: [-23.03868952] bias: [16.23843036] loss: 30.574567723702955\n",
            "Epoch: 4042 / 5000\n",
            "w1: [25.17120981] w2: [-23.04435784] bias: [16.25636726] loss: 30.56924105780349\n",
            "Epoch: 4043 / 5000\n",
            "w1: [25.1845681] w2: [-23.0325913] bias: [16.28112424] loss: 30.56438067356359\n",
            "Epoch: 4044 / 5000\n",
            "w1: [25.17274925] w2: [-23.04303864] bias: [16.25487465] loss: 30.569285499926465\n",
            "Epoch: 4045 / 5000\n",
            "w1: [25.15844716] w2: [-23.05351403] bias: [16.22803138] loss: 30.57733735834107\n",
            "Epoch: 4046 / 5000\n",
            "w1: [25.16506129] w2: [-23.04610833] bias: [16.23852109] loss: 30.573675520756666\n",
            "Epoch: 4047 / 5000\n",
            "w1: [25.15576053] w2: [-23.03387029] bias: [16.23619435] loss: 30.5757884992116\n",
            "Epoch: 4048 / 5000\n",
            "w1: [25.16178149] w2: [-23.03605942] bias: [16.24095187] loss: 30.573727851732258\n",
            "Epoch: 4049 / 5000\n",
            "w1: [25.15845439] w2: [-23.04116126] bias: [16.22920072] loss: 30.576944090724407\n",
            "Epoch: 4050 / 5000\n",
            "w1: [25.14922452] w2: [-23.03434806] bias: [16.23556726] loss: 30.577096692004712\n",
            "Epoch: 4051 / 5000\n",
            "w1: [25.14839647] w2: [-23.03324332] bias: [16.23214158] loss: 30.578045142645863\n",
            "Epoch: 4052 / 5000\n",
            "w1: [25.144142] w2: [-23.02379323] bias: [16.23000458] loss: 30.57928997149963\n",
            "Epoch: 4053 / 5000\n",
            "w1: [25.16405353] w2: [-23.01498494] bias: [16.26460758] loss: 30.56946951527881\n",
            "Epoch: 4054 / 5000\n",
            "w1: [25.15752201] w2: [-23.02435416] bias: [16.24790047] loss: 30.573104207477265\n",
            "Epoch: 4055 / 5000\n",
            "w1: [25.15255366] w2: [-23.00714197] bias: [16.25631735] loss: 30.572571523624784\n",
            "Epoch: 4056 / 5000\n",
            "w1: [25.13755101] w2: [-23.017148] bias: [16.22657853] loss: 30.58133185768409\n",
            "Epoch: 4057 / 5000\n",
            "w1: [25.1314231] w2: [-23.0207142] bias: [16.21794552] loss: 30.584866347659467\n",
            "Epoch: 4058 / 5000\n",
            "w1: [25.15002994] w2: [-23.01470157] bias: [16.24716766] loss: 30.574536093716816\n",
            "Epoch: 4059 / 5000\n",
            "w1: [25.1576266] w2: [-23.01856194] bias: [16.24962407] loss: 30.572820927998507\n",
            "Epoch: 4060 / 5000\n",
            "w1: [25.15838525] w2: [-23.02764598] bias: [16.23846668] loss: 30.574843920420342\n",
            "Epoch: 4061 / 5000\n",
            "w1: [25.16984622] w2: [-23.01386078] bias: [16.27032807] loss: 30.56795697949549\n",
            "Epoch: 4062 / 5000\n",
            "w1: [25.18865123] w2: [-23.00959499] bias: [16.29277573] loss: 30.563969424862748\n",
            "Epoch: 4063 / 5000\n",
            "w1: [25.20942271] w2: [-23.00286051] bias: [16.32916593] loss: 30.562642817789328\n",
            "Epoch: 4064 / 5000\n",
            "w1: [25.21151778] w2: [-23.00701685] bias: [16.32307273] loss: 30.562045158046537\n",
            "Epoch: 4065 / 5000\n",
            "w1: [25.21801202] w2: [-22.99002644] bias: [16.34898835] loss: 30.564861740397596\n",
            "Epoch: 4066 / 5000\n",
            "w1: [25.25261627] w2: [-22.98267605] bias: [16.40083521] loss: 30.57534849938699\n",
            "Epoch: 4067 / 5000\n",
            "w1: [25.23844212] w2: [-22.97871612] bias: [16.38808712] loss: 30.57227328709459\n",
            "Epoch: 4068 / 5000\n",
            "w1: [25.23717573] w2: [-22.98249169] bias: [16.38124134] loss: 30.570432309907254\n",
            "Epoch: 4069 / 5000\n",
            "w1: [25.24000369] w2: [-22.98405613] bias: [16.38353352] loss: 30.570778456957967\n",
            "Epoch: 4070 / 5000\n",
            "w1: [25.24057545] w2: [-22.98830342] bias: [16.37433422] loss: 30.568629603013417\n",
            "Epoch: 4071 / 5000\n",
            "w1: [25.24008842] w2: [-22.98961813] bias: [16.39132305] loss: 30.571612603394588\n",
            "Epoch: 4072 / 5000\n",
            "w1: [25.2393678] w2: [-22.99250224] bias: [16.38458527] loss: 30.56991063090541\n",
            "Epoch: 4073 / 5000\n",
            "w1: [25.22407791] w2: [-22.9993475] bias: [16.35856762] loss: 30.56492344849832\n",
            "Epoch: 4074 / 5000\n",
            "w1: [25.2192323] w2: [-22.99951652] bias: [16.35577458] loss: 30.56461019145427\n",
            "Epoch: 4075 / 5000\n",
            "w1: [25.21259289] w2: [-23.00440047] bias: [16.350325] loss: 30.5637079587745\n",
            "Epoch: 4076 / 5000\n",
            "w1: [25.20659522] w2: [-23.0070092] bias: [16.3389497] loss: 30.56285439948268\n",
            "Epoch: 4077 / 5000\n",
            "w1: [25.18985331] w2: [-23.01084388] bias: [16.31161175] loss: 30.563028377543965\n",
            "Epoch: 4078 / 5000\n",
            "w1: [25.20286405] w2: [-23.00578022] bias: [16.33957033] loss: 30.563106588709836\n",
            "Epoch: 4079 / 5000\n",
            "w1: [25.20813549] w2: [-23.00359108] bias: [16.34342191] loss: 30.56335952838401\n",
            "Epoch: 4080 / 5000\n",
            "w1: [25.20858373] w2: [-23.00857945] bias: [16.34057061] loss: 30.562753020358908\n",
            "Epoch: 4081 / 5000\n",
            "w1: [25.21182168] w2: [-23.00292953] bias: [16.34792199] loss: 30.56366027956728\n",
            "Epoch: 4082 / 5000\n",
            "w1: [25.21544565] w2: [-22.99487846] bias: [16.35968505] loss: 30.5654976903427\n",
            "Epoch: 4083 / 5000\n",
            "w1: [25.2064985] w2: [-22.99155957] bias: [16.35366657] loss: 30.56527418855921\n",
            "Epoch: 4084 / 5000\n",
            "w1: [25.2473198] w2: [-22.98985018] bias: [16.41029265] loss: 30.57628296445246\n",
            "Epoch: 4085 / 5000\n",
            "w1: [25.27066919] w2: [-22.99494292] bias: [16.430913] loss: 30.58333665324372\n",
            "Epoch: 4086 / 5000\n",
            "w1: [25.24323152] w2: [-23.01636787] bias: [16.37532306] loss: 30.565648623171796\n",
            "Epoch: 4087 / 5000\n",
            "w1: [25.24572798] w2: [-23.01643638] bias: [16.3760799] loss: 30.565827081793294\n",
            "Epoch: 4088 / 5000\n",
            "w1: [25.24662154] w2: [-23.02080743] bias: [16.37862729] loss: 30.56577422781282\n",
            "Epoch: 4089 / 5000\n",
            "w1: [25.251541] w2: [-23.02575545] bias: [16.37926473] loss: 30.565466935730488\n",
            "Epoch: 4090 / 5000\n",
            "w1: [25.25627487] w2: [-23.02615378] bias: [16.38431491] loss: 30.56647639807934\n",
            "Epoch: 4091 / 5000\n",
            "w1: [25.27862603] w2: [-23.02107764] bias: [16.41286321] loss: 30.574937124701975\n",
            "Epoch: 4092 / 5000\n",
            "w1: [25.29114432] w2: [-23.02092191] bias: [16.43427277] loss: 30.58250346693734\n",
            "Epoch: 4093 / 5000\n",
            "w1: [25.30439449] w2: [-23.01452518] bias: [16.45768077] loss: 30.59362161366746\n",
            "Epoch: 4094 / 5000\n",
            "w1: [25.30247181] w2: [-23.02633872] bias: [16.44501712] loss: 30.586620426127087\n",
            "Epoch: 4095 / 5000\n",
            "w1: [25.30467962] w2: [-23.03559274] bias: [16.43873654] loss: 30.58320383212212\n",
            "Epoch: 4096 / 5000\n",
            "w1: [25.2966721] w2: [-23.03969867] bias: [16.43180428] loss: 30.579381646338128\n",
            "Epoch: 4097 / 5000\n",
            "w1: [25.28985295] w2: [-23.0325444] bias: [16.43090111] loss: 30.57947667684741\n",
            "Epoch: 4098 / 5000\n",
            "w1: [25.28917809] w2: [-23.03284525] bias: [16.42630854] loss: 30.57797113138667\n",
            "Epoch: 4099 / 5000\n",
            "w1: [25.29743272] w2: [-23.03335062] bias: [16.43280232] loss: 30.58077041447244\n",
            "Epoch: 4100 / 5000\n",
            "w1: [25.30322321] w2: [-23.0368058] bias: [16.44042474] loss: 30.5833994542345\n",
            "Epoch: 4101 / 5000\n",
            "w1: [25.28898616] w2: [-23.04171562] bias: [16.41351591] loss: 30.57304919518171\n",
            "Epoch: 4102 / 5000\n",
            "w1: [25.30266259] w2: [-23.04565989] bias: [16.42328133] loss: 30.576501771033765\n",
            "Epoch: 4103 / 5000\n",
            "w1: [25.2802881] w2: [-23.05592317] bias: [16.38513051] loss: 30.56413624148734\n",
            "Epoch: 4104 / 5000\n",
            "w1: [25.28609388] w2: [-23.04638023] bias: [16.40189206] loss: 30.569261361827476\n",
            "Epoch: 4105 / 5000\n",
            "w1: [25.28772925] w2: [-23.01628489] bias: [16.42389851] loss: 30.579625021674428\n",
            "Epoch: 4106 / 5000\n",
            "w1: [25.28096026] w2: [-23.02904624] bias: [16.40176073] loss: 30.571183434660746\n",
            "Epoch: 4107 / 5000\n",
            "w1: [25.27732901] w2: [-23.02568992] bias: [16.39758607] loss: 30.57039384000873\n",
            "Epoch: 4108 / 5000\n",
            "w1: [25.25050191] w2: [-23.02582499] bias: [16.36692904] loss: 30.563513442617364\n",
            "Epoch: 4109 / 5000\n",
            "w1: [25.23491174] w2: [-23.02779425] bias: [16.34525908] loss: 30.560860209422653\n",
            "Epoch: 4110 / 5000\n",
            "w1: [25.22721083] w2: [-23.03563521] bias: [16.32610068] loss: 30.55936277273993\n",
            "Epoch: 4111 / 5000\n",
            "w1: [25.22237884] w2: [-23.04540145] bias: [16.31247003] loss: 30.558799780965078\n",
            "Epoch: 4112 / 5000\n",
            "w1: [25.21281707] w2: [-23.05921005] bias: [16.28667459] loss: 30.559962866577912\n",
            "Epoch: 4113 / 5000\n",
            "w1: [25.22161732] w2: [-23.05910781] bias: [16.29304562] loss: 30.55874147134558\n",
            "Epoch: 4114 / 5000\n",
            "w1: [25.21643339] w2: [-23.06636929] bias: [16.28039173] loss: 30.559866426546368\n",
            "Epoch: 4115 / 5000\n",
            "w1: [25.22717674] w2: [-23.06410686] bias: [16.29359878] loss: 30.558017765913384\n",
            "Epoch: 4116 / 5000\n",
            "w1: [25.234172] w2: [-23.06864825] bias: [16.29161485] loss: 30.557334830942686\n",
            "Epoch: 4117 / 5000\n",
            "w1: [25.23133549] w2: [-23.06320196] bias: [16.29881478] loss: 30.55750475169501\n",
            "Epoch: 4118 / 5000\n",
            "w1: [25.23363873] w2: [-23.06882839] bias: [16.29818871] loss: 30.55707618054109\n",
            "Epoch: 4119 / 5000\n",
            "w1: [25.22858255] w2: [-23.07828935] bias: [16.28496346] loss: 30.557855834675202\n",
            "Epoch: 4120 / 5000\n",
            "w1: [25.23348105] w2: [-23.06842091] bias: [16.2963334] loss: 30.557182279613727\n",
            "Epoch: 4121 / 5000\n",
            "w1: [25.24478891] w2: [-23.07549591] bias: [16.30173961] loss: 30.555829628303407\n",
            "Epoch: 4122 / 5000\n",
            "w1: [25.23758003] w2: [-23.07562258] bias: [16.30313508] loss: 30.55628377476687\n",
            "Epoch: 4123 / 5000\n",
            "w1: [25.24062823] w2: [-23.07115385] bias: [16.31192016] loss: 30.556187265143024\n",
            "Epoch: 4124 / 5000\n",
            "w1: [25.24946503] w2: [-23.06044925] bias: [16.32583925] loss: 30.556708172925994\n",
            "Epoch: 4125 / 5000\n",
            "w1: [25.25531284] w2: [-23.04500456] bias: [16.34272891] loss: 30.55887981866017\n",
            "Epoch: 4126 / 5000\n",
            "w1: [25.26598822] w2: [-23.04690398] bias: [16.35473693] loss: 30.559952220257006\n",
            "Epoch: 4127 / 5000\n",
            "w1: [25.27196931] w2: [-23.05954265] bias: [16.34814471] loss: 30.558024736439872\n",
            "Epoch: 4128 / 5000\n",
            "w1: [25.25572041] w2: [-23.06914903] bias: [16.32295493] loss: 30.555757870039876\n",
            "Epoch: 4129 / 5000\n",
            "w1: [25.26792695] w2: [-23.04634662] bias: [16.3554339] loss: 30.56011099231315\n",
            "Epoch: 4130 / 5000\n",
            "w1: [25.26051634] w2: [-23.0480023] bias: [16.35017329] loss: 30.559304665354617\n",
            "Epoch: 4131 / 5000\n",
            "w1: [25.26964267] w2: [-23.04643087] bias: [16.36395262] loss: 30.56127823748547\n",
            "Epoch: 4132 / 5000\n",
            "w1: [25.26882748] w2: [-23.05141869] bias: [16.3636136] loss: 30.560697973381867\n",
            "Epoch: 4133 / 5000\n",
            "w1: [25.29840907] w2: [-23.04461125] bias: [16.40708515] loss: 30.571729977940787\n",
            "Epoch: 4134 / 5000\n",
            "w1: [25.28726574] w2: [-23.05259951] bias: [16.38601332] loss: 30.565046774240752\n",
            "Epoch: 4135 / 5000\n",
            "w1: [25.29611152] w2: [-23.04390053] bias: [16.39893344] loss: 30.56958961591881\n",
            "Epoch: 4136 / 5000\n",
            "w1: [25.32200983] w2: [-23.03452426] bias: [16.44982333] loss: 30.589642598735562\n",
            "Epoch: 4137 / 5000\n",
            "w1: [25.32204409] w2: [-23.03961291] bias: [16.44545904] loss: 30.587147811185567\n",
            "Epoch: 4138 / 5000\n",
            "w1: [25.32976183] w2: [-23.03784778] bias: [16.45089255] loss: 30.590599326395814\n",
            "Epoch: 4139 / 5000\n",
            "w1: [25.33027999] w2: [-23.03459357] bias: [16.4550293] loss: 30.59287586663565\n",
            "Epoch: 4140 / 5000\n",
            "w1: [25.3151299] w2: [-23.04424013] bias: [16.42560614] loss: 30.57875864938094\n",
            "Epoch: 4141 / 5000\n",
            "w1: [25.33731298] w2: [-23.03926179] bias: [16.45228087] loss: 30.592030458901473\n",
            "Epoch: 4142 / 5000\n",
            "w1: [25.32148983] w2: [-23.05978648] bias: [16.41196088] loss: 30.57297756859226\n",
            "Epoch: 4143 / 5000\n",
            "w1: [25.32294894] w2: [-23.05926657] bias: [16.40843292] loss: 30.572189737019432\n",
            "Epoch: 4144 / 5000\n",
            "w1: [25.32508752] w2: [-23.06955006] bias: [16.40784632] loss: 30.570766587689498\n",
            "Epoch: 4145 / 5000\n",
            "w1: [25.33823986] w2: [-23.07738445] bias: [16.41735198] loss: 30.573698734879944\n",
            "Epoch: 4146 / 5000\n",
            "w1: [25.32867654] w2: [-23.07828025] bias: [16.40421954] loss: 30.56889007362689\n",
            "Epoch: 4147 / 5000\n",
            "w1: [25.31392381] w2: [-23.08342002] bias: [16.37813253] loss: 30.561173815702773\n",
            "Epoch: 4148 / 5000\n",
            "w1: [25.30894794] w2: [-23.08718556] bias: [16.36514584] loss: 30.558214011478082\n",
            "Epoch: 4149 / 5000\n",
            "w1: [25.30070036] w2: [-23.08972505] bias: [16.34856442] loss: 30.555439844035604\n",
            "Epoch: 4150 / 5000\n",
            "w1: [25.2945208] w2: [-23.07987505] bias: [16.35026912] loss: 30.5565054937117\n",
            "Epoch: 4151 / 5000\n",
            "w1: [25.28871743] w2: [-23.07955449] bias: [16.34627029] loss: 30.556030942667327\n",
            "Epoch: 4152 / 5000\n",
            "w1: [25.28549913] w2: [-23.08496779] bias: [16.3339813] loss: 30.55443513878326\n",
            "Epoch: 4153 / 5000\n",
            "w1: [25.27196772] w2: [-23.09033424] bias: [16.31002096] loss: 30.553380371631665\n",
            "Epoch: 4154 / 5000\n",
            "w1: [25.26690145] w2: [-23.09753737] bias: [16.30013231] loss: 30.55327319623667\n",
            "Epoch: 4155 / 5000\n",
            "w1: [25.28893944] w2: [-23.09577668] bias: [16.3216378] loss: 30.552753453047046\n",
            "Epoch: 4156 / 5000\n",
            "w1: [25.28767849] w2: [-23.09146483] bias: [16.31794134] loss: 30.552920935980882\n",
            "Epoch: 4157 / 5000\n",
            "w1: [25.28815719] w2: [-23.08342597] bias: [16.32090591] loss: 30.553634916972474\n",
            "Epoch: 4158 / 5000\n",
            "w1: [25.27780912] w2: [-23.08391678] bias: [16.30249088] loss: 30.553410504804223\n",
            "Epoch: 4159 / 5000\n",
            "w1: [25.26482062] w2: [-23.08756633] bias: [16.28029388] loss: 30.554583173735374\n",
            "Epoch: 4160 / 5000\n",
            "w1: [25.26201302] w2: [-23.08357609] bias: [16.2804674] loss: 30.55497209192296\n",
            "Epoch: 4161 / 5000\n",
            "w1: [25.26326902] w2: [-23.09034691] bias: [16.27732444] loss: 30.55477138390851\n",
            "Epoch: 4162 / 5000\n",
            "w1: [25.27621825] w2: [-23.0792309] bias: [16.31833121] loss: 30.554158771367135\n",
            "Epoch: 4163 / 5000\n",
            "w1: [25.26885748] w2: [-23.08281186] bias: [16.30799892] loss: 30.553967769142982\n",
            "Epoch: 4164 / 5000\n",
            "w1: [25.28066696] w2: [-23.08508362] bias: [16.31676109] loss: 30.553540810272576\n",
            "Epoch: 4165 / 5000\n",
            "w1: [25.29675068] w2: [-23.09050103] bias: [16.32900258] loss: 30.55346136835717\n",
            "Epoch: 4166 / 5000\n",
            "w1: [25.28952493] w2: [-23.09134839] bias: [16.31877224] loss: 30.55291328363016\n",
            "Epoch: 4167 / 5000\n",
            "w1: [25.28117168] w2: [-23.09762056] bias: [16.30065189] loss: 30.552433655211413\n",
            "Epoch: 4168 / 5000\n",
            "w1: [25.2873222] w2: [-23.09316987] bias: [16.3111737] loss: 30.552570012731486\n",
            "Epoch: 4169 / 5000\n",
            "w1: [25.28920967] w2: [-23.09417674] bias: [16.317476] loss: 30.552664683108794\n",
            "Epoch: 4170 / 5000\n",
            "w1: [25.27951697] w2: [-23.1016571] bias: [16.2920705] loss: 30.552418651184272\n",
            "Epoch: 4171 / 5000\n",
            "w1: [25.26409913] w2: [-23.11056239] bias: [16.26391599] loss: 30.555121633478407\n",
            "Epoch: 4172 / 5000\n",
            "w1: [25.2550442] w2: [-23.11421839] bias: [16.24940273] loss: 30.557851870173806\n",
            "Epoch: 4173 / 5000\n",
            "w1: [25.26234172] w2: [-23.12219271] bias: [16.24995925] loss: 30.55674557821182\n",
            "Epoch: 4174 / 5000\n",
            "w1: [25.26289945] w2: [-23.1287659] bias: [16.23876038] loss: 30.55828492544467\n",
            "Epoch: 4175 / 5000\n",
            "w1: [25.25898837] w2: [-23.13549863] bias: [16.22999346] loss: 30.560377350770096\n",
            "Epoch: 4176 / 5000\n",
            "w1: [25.25689069] w2: [-23.14727679] bias: [16.21404971] loss: 30.564154151044242\n",
            "Epoch: 4177 / 5000\n",
            "w1: [25.27378575] w2: [-23.13765743] bias: [16.2476395] loss: 30.5554389872898\n",
            "Epoch: 4178 / 5000\n",
            "w1: [25.28629413] w2: [-23.1321243] bias: [16.26662933] loss: 30.552047539681794\n",
            "Epoch: 4179 / 5000\n",
            "w1: [25.2842763] w2: [-23.13563558] bias: [16.25686382] loss: 30.553109152969995\n",
            "Epoch: 4180 / 5000\n",
            "w1: [25.27280263] w2: [-23.14525774] bias: [16.23431021] loss: 30.55758545924282\n",
            "Epoch: 4181 / 5000\n",
            "w1: [25.26497435] w2: [-23.15200264] bias: [16.21906652] loss: 30.561748186830716\n",
            "Epoch: 4182 / 5000\n",
            "w1: [25.25305508] w2: [-23.15772849] bias: [16.20361183] loss: 30.567620615562962\n",
            "Epoch: 4183 / 5000\n",
            "w1: [25.2374182] w2: [-23.16823838] bias: [16.17222687] loss: 30.58084659616422\n",
            "Epoch: 4184 / 5000\n",
            "w1: [25.23808285] w2: [-23.16402412] bias: [16.1733645] loss: 30.580087791774826\n",
            "Epoch: 4185 / 5000\n",
            "w1: [25.25092518] w2: [-23.14289187] bias: [16.20370665] loss: 30.567636857285205\n",
            "Epoch: 4186 / 5000\n",
            "w1: [25.26137811] w2: [-23.1370511] bias: [16.22776196] loss: 30.56044270823447\n",
            "Epoch: 4187 / 5000\n",
            "w1: [25.26805958] w2: [-23.1290419] bias: [16.24326343] loss: 30.556890927838364\n",
            "Epoch: 4188 / 5000\n",
            "w1: [25.27717814] w2: [-23.1220841] bias: [16.27216003] loss: 30.55276217511708\n",
            "Epoch: 4189 / 5000\n",
            "w1: [25.27542193] w2: [-23.12392052] bias: [16.26564056] loss: 30.553432550560025\n",
            "Epoch: 4190 / 5000\n",
            "w1: [25.27326918] w2: [-23.13360947] bias: [16.25021411] loss: 30.55520687147701\n",
            "Epoch: 4191 / 5000\n",
            "w1: [25.27694987] w2: [-23.12488505] bias: [16.2569898] loss: 30.554122676023876\n",
            "Epoch: 4192 / 5000\n",
            "w1: [25.2867279] w2: [-23.12438029] bias: [16.26717938] loss: 30.552190167118173\n",
            "Epoch: 4193 / 5000\n",
            "w1: [25.3016635] w2: [-23.11865513] bias: [16.28863745] loss: 30.550257843750966\n",
            "Epoch: 4194 / 5000\n",
            "w1: [25.30478961] w2: [-23.12125149] bias: [16.30091647] loss: 30.549913015738536\n",
            "Epoch: 4195 / 5000\n",
            "w1: [25.32050446] w2: [-23.09737881] bias: [16.34508901] loss: 30.55454246744203\n",
            "Epoch: 4196 / 5000\n",
            "w1: [25.31193613] w2: [-23.10073218] bias: [16.32420237] loss: 30.55209492175074\n",
            "Epoch: 4197 / 5000\n",
            "w1: [25.31039066] w2: [-23.11365007] bias: [16.30454575] loss: 30.55020138452085\n",
            "Epoch: 4198 / 5000\n",
            "w1: [25.29622707] w2: [-23.11693146] bias: [16.28586783] loss: 30.55074322196351\n",
            "Epoch: 4199 / 5000\n",
            "w1: [25.30664038] w2: [-23.10525086] bias: [16.30086168] loss: 30.550779983470647\n",
            "Epoch: 4200 / 5000\n",
            "w1: [25.31672291] w2: [-23.11682291] bias: [16.30171609] loss: 30.549690397986108\n",
            "Epoch: 4201 / 5000\n",
            "w1: [25.30722525] w2: [-23.12380452] bias: [16.2770792] loss: 30.54996393360343\n",
            "Epoch: 4202 / 5000\n",
            "w1: [25.29013456] w2: [-23.13318752] bias: [16.2435839] loss: 30.55405384560334\n",
            "Epoch: 4203 / 5000\n",
            "w1: [25.292918] w2: [-23.13393592] bias: [16.24486031] loss: 30.55355759156958\n",
            "Epoch: 4204 / 5000\n",
            "w1: [25.28750227] w2: [-23.13171682] bias: [16.23624896] loss: 30.555389436832257\n",
            "Epoch: 4205 / 5000\n",
            "w1: [25.28303126] w2: [-23.13677731] bias: [16.22206753] loss: 30.558269781134598\n",
            "Epoch: 4206 / 5000\n",
            "w1: [25.28997809] w2: [-23.11882423] bias: [16.24386753] loss: 30.554282918200265\n",
            "Epoch: 4207 / 5000\n",
            "w1: [25.29456977] w2: [-23.12358772] bias: [16.2421544] loss: 30.55387422503478\n",
            "Epoch: 4208 / 5000\n",
            "w1: [25.29423256] w2: [-23.118423] bias: [16.24196081] loss: 30.554031752382194\n",
            "Epoch: 4209 / 5000\n",
            "w1: [25.28074709] w2: [-23.13280233] bias: [16.21427714] loss: 30.560062841895217\n",
            "Epoch: 4210 / 5000\n",
            "w1: [25.293457] w2: [-23.13320933] bias: [16.22790053] loss: 30.555851923538636\n",
            "Epoch: 4211 / 5000\n",
            "w1: [25.2945573] w2: [-23.14251907] bias: [16.22116051] loss: 30.55677414891591\n",
            "Epoch: 4212 / 5000\n",
            "w1: [25.29680401] w2: [-23.13848567] bias: [16.22532764] loss: 30.555779864534465\n",
            "Epoch: 4213 / 5000\n",
            "w1: [25.30829982] w2: [-23.13736285] bias: [16.23827484] loss: 30.5525370501635\n",
            "Epoch: 4214 / 5000\n",
            "w1: [25.31389054] w2: [-23.13138261] bias: [16.25077747] loss: 30.550772689770618\n",
            "Epoch: 4215 / 5000\n",
            "w1: [25.32745046] w2: [-23.12631223] bias: [16.27286242] loss: 30.54862388752796\n",
            "Epoch: 4216 / 5000\n",
            "w1: [25.3412318] w2: [-23.1111652] bias: [16.30314298] loss: 30.54942247716325\n",
            "Epoch: 4217 / 5000\n",
            "w1: [25.32634789] w2: [-23.10888965] bias: [16.29464735] loss: 30.549635318553516\n",
            "Epoch: 4218 / 5000\n",
            "w1: [25.32228415] w2: [-23.11176871] bias: [16.28259119] loss: 30.549503220918577\n",
            "Epoch: 4219 / 5000\n",
            "w1: [25.32367321] w2: [-23.10341426] bias: [16.28855479] loss: 30.549945880126618\n",
            "Epoch: 4220 / 5000\n",
            "w1: [25.31106852] w2: [-23.10250415] bias: [16.274171] loss: 30.55075305275078\n",
            "Epoch: 4221 / 5000\n",
            "w1: [25.31437085] w2: [-23.09930462] bias: [16.28609308] loss: 30.55059555096585\n",
            "Epoch: 4222 / 5000\n",
            "w1: [25.29698913] w2: [-23.10062897] bias: [16.26078095] loss: 30.552519710462935\n",
            "Epoch: 4223 / 5000\n",
            "w1: [25.29968432] w2: [-23.0996989] bias: [16.27232385] loss: 30.55173063094058\n",
            "Epoch: 4224 / 5000\n",
            "w1: [25.29227054] w2: [-23.0855171] bias: [16.27845922] loss: 30.55270732987894\n",
            "Epoch: 4225 / 5000\n",
            "w1: [25.27982426] w2: [-23.08663075] bias: [16.25955971] loss: 30.554653915492896\n",
            "Epoch: 4226 / 5000\n",
            "w1: [25.26395832] w2: [-23.09467131] bias: [16.22896834] loss: 30.55997264121725\n",
            "Epoch: 4227 / 5000\n",
            "w1: [25.26690583] w2: [-23.09701903] bias: [16.23041133] loss: 30.559319508742988\n",
            "Epoch: 4228 / 5000\n",
            "w1: [25.27009847] w2: [-23.1002611] bias: [16.24380132] loss: 30.556964694462266\n",
            "Epoch: 4229 / 5000\n",
            "w1: [25.27484658] w2: [-23.10085305] bias: [16.249278] loss: 30.555743234763355\n",
            "Epoch: 4230 / 5000\n",
            "w1: [25.26554704] w2: [-23.10835047] bias: [16.23116668] loss: 30.559287169835923\n",
            "Epoch: 4231 / 5000\n",
            "w1: [25.29188362] w2: [-23.1014678] bias: [16.26725258] loss: 30.552519299385498\n",
            "Epoch: 4232 / 5000\n",
            "w1: [25.27918819] w2: [-23.11526227] bias: [16.24375414] loss: 30.55561895071311\n",
            "Epoch: 4233 / 5000\n",
            "w1: [25.27359046] w2: [-23.12847943] bias: [16.23017675] loss: 30.558220410181093\n",
            "Epoch: 4234 / 5000\n",
            "w1: [25.28861118] w2: [-23.12563621] bias: [16.2532939] loss: 30.553240569404416\n",
            "Epoch: 4235 / 5000\n",
            "w1: [25.28506278] w2: [-23.12221934] bias: [16.2526875] loss: 30.55376334230481\n",
            "Epoch: 4236 / 5000\n",
            "w1: [25.28916552] w2: [-23.12464163] bias: [16.25070741] loss: 30.553479124804536\n",
            "Epoch: 4237 / 5000\n",
            "w1: [25.30055116] w2: [-23.12533958] bias: [16.26556117] loss: 30.551033374336107\n",
            "Epoch: 4238 / 5000\n",
            "w1: [25.29812789] w2: [-23.12925825] bias: [16.25719725] loss: 30.551796839119756\n",
            "Epoch: 4239 / 5000\n",
            "w1: [25.28274293] w2: [-23.13330504] bias: [16.22975564] loss: 30.557000531824134\n",
            "Epoch: 4240 / 5000\n",
            "w1: [25.28889618] w2: [-23.13528088] bias: [16.2341419] loss: 30.555485131775626\n",
            "Epoch: 4241 / 5000\n",
            "w1: [25.28655394] w2: [-23.13660793] bias: [16.2269536] loss: 30.556923340935654\n",
            "Epoch: 4242 / 5000\n",
            "w1: [25.28795017] w2: [-23.1345671] bias: [16.24378772] loss: 30.554266988778508\n",
            "Epoch: 4243 / 5000\n",
            "w1: [25.28027098] w2: [-23.12939212] bias: [16.23181403] loss: 30.557027425071478\n",
            "Epoch: 4244 / 5000\n",
            "w1: [25.28189286] w2: [-23.12476673] bias: [16.23785784] loss: 30.555946757277084\n",
            "Epoch: 4245 / 5000\n",
            "w1: [25.26849177] w2: [-23.12825236] bias: [16.21474758] loss: 30.561862716074756\n",
            "Epoch: 4246 / 5000\n",
            "w1: [25.27526698] w2: [-23.13120125] bias: [16.21820956] loss: 30.560134061954166\n",
            "Epoch: 4247 / 5000\n",
            "w1: [25.26251457] w2: [-23.13606587] bias: [16.19535294] loss: 30.5674580214206\n",
            "Epoch: 4248 / 5000\n",
            "w1: [25.25587685] w2: [-23.15308123] bias: [16.17052546] loss: 30.576508921154907\n",
            "Epoch: 4249 / 5000\n",
            "w1: [25.2448393] w2: [-23.15452871] bias: [16.16231844] loss: 30.581844559651202\n",
            "Epoch: 4250 / 5000\n",
            "w1: [25.24553568] w2: [-23.16072766] bias: [16.15874417] loss: 30.58328197050727\n",
            "Epoch: 4251 / 5000\n",
            "w1: [25.28408147] w2: [-23.15596445] bias: [16.20992579] loss: 30.560631528264615\n",
            "Epoch: 4252 / 5000\n",
            "w1: [25.30211673] w2: [-23.1588133] bias: [16.22896357] loss: 30.554406480084047\n",
            "Epoch: 4253 / 5000\n",
            "w1: [25.3063355] w2: [-23.16109089] bias: [16.22760676] loss: 30.554052544258212\n",
            "Epoch: 4254 / 5000\n",
            "w1: [25.28956519] w2: [-23.16872224] bias: [16.20083413] loss: 30.561960621101253\n",
            "Epoch: 4255 / 5000\n",
            "w1: [25.30823167] w2: [-23.17229709] bias: [16.22476345] loss: 30.55425285097349\n",
            "Epoch: 4256 / 5000\n",
            "w1: [25.30657035] w2: [-23.18171408] bias: [16.21583258] loss: 30.55617125959792\n",
            "Epoch: 4257 / 5000\n",
            "w1: [25.29551995] w2: [-23.19164214] bias: [16.19387139] loss: 30.56316304707689\n",
            "Epoch: 4258 / 5000\n",
            "w1: [25.30275521] w2: [-23.18876402] bias: [16.20290946] loss: 30.559625327252775\n",
            "Epoch: 4259 / 5000\n",
            "w1: [25.32436719] w2: [-23.18405657] bias: [16.24340238] loss: 30.54944272796722\n",
            "Epoch: 4260 / 5000\n",
            "w1: [25.33280144] w2: [-23.17710977] bias: [16.25460864] loss: 30.547512337806253\n",
            "Epoch: 4261 / 5000\n",
            "w1: [25.33330748] w2: [-23.17374673] bias: [16.25302916] loss: 30.547678391656785\n",
            "Epoch: 4262 / 5000\n",
            "w1: [25.34162391] w2: [-23.1692646] bias: [16.26613924] loss: 30.546195642961447\n",
            "Epoch: 4263 / 5000\n",
            "w1: [25.33909271] w2: [-23.16900411] bias: [16.25555409] loss: 30.547065155009612\n",
            "Epoch: 4264 / 5000\n",
            "w1: [25.32867749] w2: [-23.18085926] bias: [16.22721737] loss: 30.551145675406413\n",
            "Epoch: 4265 / 5000\n",
            "w1: [25.34190613] w2: [-23.18634459] bias: [16.23319693] loss: 30.548698391761302\n",
            "Epoch: 4266 / 5000\n",
            "w1: [25.35191458] w2: [-23.18196814] bias: [16.24440392] loss: 30.54650416568149\n",
            "Epoch: 4267 / 5000\n",
            "w1: [25.34463151] w2: [-23.18976735] bias: [16.22765325] loss: 30.549080752506725\n",
            "Epoch: 4268 / 5000\n",
            "w1: [25.34526919] w2: [-23.18110533] bias: [16.22998598] loss: 30.548771745861426\n",
            "Epoch: 4269 / 5000\n",
            "w1: [25.36294112] w2: [-23.18007174] bias: [16.24878697] loss: 30.54521273781262\n",
            "Epoch: 4270 / 5000\n",
            "w1: [25.36215383] w2: [-23.17643736] bias: [16.25439992] loss: 30.54502787982819\n",
            "Epoch: 4271 / 5000\n",
            "w1: [25.35386213] w2: [-23.17716968] bias: [16.24488979] loss: 30.546382306139925\n",
            "Epoch: 4272 / 5000\n",
            "w1: [25.34614585] w2: [-23.18457409] bias: [16.2294591] loss: 30.548704937284597\n",
            "Epoch: 4273 / 5000\n",
            "w1: [25.34056865] w2: [-23.19071197] bias: [16.22451609] loss: 30.550017441898163\n",
            "Epoch: 4274 / 5000\n",
            "w1: [25.34908128] w2: [-23.1801891] bias: [16.24835667] loss: 30.5464618265079\n",
            "Epoch: 4275 / 5000\n",
            "w1: [25.33824022] w2: [-23.18859786] bias: [16.23209837] loss: 30.549246391486413\n",
            "Epoch: 4276 / 5000\n",
            "w1: [25.34096262] w2: [-23.1840238] bias: [16.25249459] loss: 30.546776685781627\n",
            "Epoch: 4277 / 5000\n",
            "w1: [25.34641396] w2: [-23.17824255] bias: [16.2607947] loss: 30.545835901520796\n",
            "Epoch: 4278 / 5000\n",
            "w1: [25.33835915] w2: [-23.1738111] bias: [16.25315294] loss: 30.547195764918815\n",
            "Epoch: 4279 / 5000\n",
            "w1: [25.33217956] w2: [-23.17512305] bias: [16.23928156] loss: 30.549178437583905\n",
            "Epoch: 4280 / 5000\n",
            "w1: [25.37530633] w2: [-23.17240225] bias: [16.29864899] loss: 30.544374516197376\n",
            "Epoch: 4281 / 5000\n",
            "w1: [25.36224328] w2: [-23.17284096] bias: [16.27368192] loss: 30.54445867018623\n",
            "Epoch: 4282 / 5000\n",
            "w1: [25.35445033] w2: [-23.16784877] bias: [16.26946317] loss: 30.54522778263465\n",
            "Epoch: 4283 / 5000\n",
            "w1: [25.37280852] w2: [-23.16020939] bias: [16.2999956] loss: 30.545274547426228\n",
            "Epoch: 4284 / 5000\n",
            "w1: [25.34769383] w2: [-23.17581962] bias: [16.25280227] loss: 30.54633865207445\n",
            "Epoch: 4285 / 5000\n",
            "w1: [25.3546616] w2: [-23.1773879] bias: [16.25261591] loss: 30.545714850211233\n",
            "Epoch: 4286 / 5000\n",
            "w1: [25.34974762] w2: [-23.16965099] bias: [16.25020722] loss: 30.546514084245587\n",
            "Epoch: 4287 / 5000\n",
            "w1: [25.31985697] w2: [-23.17912889] bias: [16.20425756] loss: 30.556409614702883\n",
            "Epoch: 4288 / 5000\n",
            "w1: [25.32975846] w2: [-23.17834312] bias: [16.21255762] loss: 30.553374022892378\n",
            "Epoch: 4289 / 5000\n",
            "w1: [25.3333742] w2: [-23.15948084] bias: [16.23081648] loss: 30.550270774499232\n",
            "Epoch: 4290 / 5000\n",
            "w1: [25.32710611] w2: [-23.1657327] bias: [16.21908733] loss: 30.552638545592696\n",
            "Epoch: 4291 / 5000\n",
            "w1: [25.32331882] w2: [-23.17150972] bias: [16.21502434] loss: 30.5538229315331\n",
            "Epoch: 4292 / 5000\n",
            "w1: [25.32055614] w2: [-23.17699087] bias: [16.2046099] loss: 30.55620615369222\n",
            "Epoch: 4293 / 5000\n",
            "w1: [25.31705746] w2: [-23.18286259] bias: [16.19563969] loss: 30.55876012220496\n",
            "Epoch: 4294 / 5000\n",
            "w1: [25.31148888] w2: [-23.17580503] bias: [16.20105125] loss: 30.55836130426126\n",
            "Epoch: 4295 / 5000\n",
            "w1: [25.30824495] w2: [-23.18250594] bias: [16.19037415] loss: 30.56150291687036\n",
            "Epoch: 4296 / 5000\n",
            "w1: [25.30642518] w2: [-23.18184646] bias: [16.17977881] loss: 30.5645286317695\n",
            "Epoch: 4297 / 5000\n",
            "w1: [25.32443633] w2: [-23.17387226] bias: [16.20802704] loss: 30.55493381623298\n",
            "Epoch: 4298 / 5000\n",
            "w1: [25.32277893] w2: [-23.17439334] bias: [16.20594574] loss: 30.555579993220853\n",
            "Epoch: 4299 / 5000\n",
            "w1: [25.3174939] w2: [-23.17602969] bias: [16.19235679] loss: 30.559298972702596\n",
            "Epoch: 4300 / 5000\n",
            "w1: [25.30851239] w2: [-23.18252199] bias: [16.1838012] loss: 30.563104616528378\n",
            "Epoch: 4301 / 5000\n",
            "w1: [25.30600191] w2: [-23.18421443] bias: [16.17771819] loss: 30.56524253342561\n",
            "Epoch: 4302 / 5000\n",
            "w1: [25.29888895] w2: [-23.19621538] bias: [16.1593478] loss: 30.572691257991053\n",
            "Epoch: 4303 / 5000\n",
            "w1: [25.31129187] w2: [-23.19270703] bias: [16.18417074] loss: 30.562795078220624\n",
            "Epoch: 4304 / 5000\n",
            "w1: [25.30679013] w2: [-23.19115623] bias: [16.17790663] loss: 30.56527488828593\n",
            "Epoch: 4305 / 5000\n",
            "w1: [25.30046831] w2: [-23.18953888] bias: [16.17845664] loss: 30.566295733230547\n",
            "Epoch: 4306 / 5000\n",
            "w1: [25.29862983] w2: [-23.19606996] bias: [16.16579379] loss: 30.570688760228673\n",
            "Epoch: 4307 / 5000\n",
            "w1: [25.2935357] w2: [-23.19594126] bias: [16.16047412] loss: 30.573486414197962\n",
            "Epoch: 4308 / 5000\n",
            "w1: [25.28723536] w2: [-23.19283539] bias: [16.15261221] loss: 30.577403539539784\n",
            "Epoch: 4309 / 5000\n",
            "w1: [25.30255105] w2: [-23.17599447] bias: [16.18700161] loss: 30.563198653360182\n",
            "Epoch: 4310 / 5000\n",
            "w1: [25.32084092] w2: [-23.17544736] bias: [16.20504158] loss: 30.55606021454426\n",
            "Epoch: 4311 / 5000\n",
            "w1: [25.33233273] w2: [-23.17821818] bias: [16.21590458] loss: 30.552448510473496\n",
            "Epoch: 4312 / 5000\n",
            "w1: [25.32657048] w2: [-23.18662671] bias: [16.19712474] loss: 30.55694431080712\n",
            "Epoch: 4313 / 5000\n",
            "w1: [25.33938532] w2: [-23.17819373] bias: [16.23151772] loss: 30.549280383590695\n",
            "Epoch: 4314 / 5000\n",
            "w1: [25.33209278] w2: [-23.18286551] bias: [16.21356255] loss: 30.552890785562166\n",
            "Epoch: 4315 / 5000\n",
            "w1: [25.34505767] w2: [-23.18472053] bias: [16.23248011] loss: 30.54844762212423\n",
            "Epoch: 4316 / 5000\n",
            "w1: [25.33615367] w2: [-23.18921498] bias: [16.21109251] loss: 30.552787118346085\n",
            "Epoch: 4317 / 5000\n",
            "w1: [25.37445018] w2: [-23.18746674] bias: [16.25810831] loss: 30.54358657495463\n",
            "Epoch: 4318 / 5000\n",
            "w1: [25.38143468] w2: [-23.18973957] bias: [16.26965846] loss: 30.542741868142326\n",
            "Epoch: 4319 / 5000\n",
            "w1: [25.39156132] w2: [-23.18498371] bias: [16.28773525] loss: 30.542760299557226\n",
            "Epoch: 4320 / 5000\n",
            "w1: [25.40961068] w2: [-23.18989757] bias: [16.29993408] loss: 30.542829060706303\n",
            "Epoch: 4321 / 5000\n",
            "w1: [25.41383629] w2: [-23.194169] bias: [16.30003124] loss: 30.54252278717329\n",
            "Epoch: 4322 / 5000\n",
            "w1: [25.40579787] w2: [-23.19330817] bias: [16.28513264] loss: 30.541813067083034\n",
            "Epoch: 4323 / 5000\n",
            "w1: [25.40366229] w2: [-23.19386608] bias: [16.28393202] loss: 30.541791444824987\n",
            "Epoch: 4324 / 5000\n",
            "w1: [25.4056234] w2: [-23.19218215] bias: [16.28549399] loss: 30.541896839325197\n",
            "Epoch: 4325 / 5000\n",
            "w1: [25.41034131] w2: [-23.19690841] bias: [16.28228859] loss: 30.541384379384542\n",
            "Epoch: 4326 / 5000\n",
            "w1: [25.40505528] w2: [-23.19979604] bias: [16.26969928] loss: 30.54115517959714\n",
            "Epoch: 4327 / 5000\n",
            "w1: [25.39748562] w2: [-23.19687063] bias: [16.26475259] loss: 30.541657948058507\n",
            "Epoch: 4328 / 5000\n",
            "w1: [25.41229833] w2: [-23.18939389] bias: [16.29735297] loss: 30.54265250929362\n",
            "Epoch: 4329 / 5000\n",
            "w1: [25.42648677] w2: [-23.19894409] bias: [16.30152102] loss: 30.542304532458985\n",
            "Epoch: 4330 / 5000\n",
            "w1: [25.41756184] w2: [-23.20599633] bias: [16.28223527] loss: 30.54069432113501\n",
            "Epoch: 4331 / 5000\n",
            "w1: [25.41959001] w2: [-23.19923067] bias: [16.28995951] loss: 30.5414416527375\n",
            "Epoch: 4332 / 5000\n",
            "w1: [25.4218122] w2: [-23.20348541] bias: [16.28882281] loss: 30.54107981192638\n",
            "Epoch: 4333 / 5000\n",
            "w1: [25.42242957] w2: [-23.2052352] bias: [16.29097461] loss: 30.541092909706045\n",
            "Epoch: 4334 / 5000\n",
            "w1: [25.4233972] w2: [-23.19716573] bias: [16.29338178] loss: 30.54176508914246\n",
            "Epoch: 4335 / 5000\n",
            "w1: [25.42247166] w2: [-23.19979902] bias: [16.28552216] loss: 30.54110819267043\n",
            "Epoch: 4336 / 5000\n",
            "w1: [25.42455152] w2: [-23.19186366] bias: [16.29061649] loss: 30.541908042649606\n",
            "Epoch: 4337 / 5000\n",
            "w1: [25.42676134] w2: [-23.1917239] bias: [16.30115381] loss: 30.542794041097682\n",
            "Epoch: 4338 / 5000\n",
            "w1: [25.45064272] w2: [-23.18877617] bias: [16.32641375] loss: 30.547027227604957\n",
            "Epoch: 4339 / 5000\n",
            "w1: [25.43415857] w2: [-23.19628377] bias: [16.29446996] loss: 30.541879558989216\n",
            "Epoch: 4340 / 5000\n",
            "w1: [25.4422991] w2: [-23.19282415] bias: [16.30437332] loss: 30.543219775283827\n",
            "Epoch: 4341 / 5000\n",
            "w1: [25.44563747] w2: [-23.19226581] bias: [16.3039228] loss: 30.543269753234338\n",
            "Epoch: 4342 / 5000\n",
            "w1: [25.42756891] w2: [-23.2001298] bias: [16.27247516] loss: 30.540403437290806\n",
            "Epoch: 4343 / 5000\n",
            "w1: [25.45544116] w2: [-23.20138571] bias: [16.30429317] loss: 30.542780024689527\n",
            "Epoch: 4344 / 5000\n",
            "w1: [25.47070641] w2: [-23.19680331] bias: [16.3348595] loss: 30.548919538589722\n",
            "Epoch: 4345 / 5000\n",
            "w1: [25.47322518] w2: [-23.19016407] bias: [16.33848916] loss: 30.550570701641032\n",
            "Epoch: 4346 / 5000\n",
            "w1: [25.46299409] w2: [-23.19595602] bias: [16.31423024] loss: 30.54487372291973\n",
            "Epoch: 4347 / 5000\n",
            "w1: [25.44822269] w2: [-23.20906258] bias: [16.28458811] loss: 30.54019357961867\n",
            "Epoch: 4348 / 5000\n",
            "w1: [25.44454877] w2: [-23.19847285] bias: [16.28457877] loss: 30.54090506846747\n",
            "Epoch: 4349 / 5000\n",
            "w1: [25.43128881] w2: [-23.20968902] bias: [16.26495442] loss: 30.539610194705485\n",
            "Epoch: 4350 / 5000\n",
            "w1: [25.41963305] w2: [-23.22298591] bias: [16.238762] loss: 30.540268349180423\n",
            "Epoch: 4351 / 5000\n",
            "w1: [25.43004005] w2: [-23.2228145] bias: [16.26081917] loss: 30.539037366860438\n",
            "Epoch: 4352 / 5000\n",
            "w1: [25.42841019] w2: [-23.22518474] bias: [16.2588574] loss: 30.539024475770876\n",
            "Epoch: 4353 / 5000\n",
            "w1: [25.45553645] w2: [-23.22432961] bias: [16.2986649] loss: 30.54039957809428\n",
            "Epoch: 4354 / 5000\n",
            "w1: [25.46288841] w2: [-23.21428409] bias: [16.31497021] loss: 30.543367594208124\n",
            "Epoch: 4355 / 5000\n",
            "w1: [25.46368331] w2: [-23.21756944] bias: [16.31373952] loss: 30.542935121667824\n",
            "Epoch: 4356 / 5000\n",
            "w1: [25.44440249] w2: [-23.23550177] bias: [16.27285097] loss: 30.53812486325738\n",
            "Epoch: 4357 / 5000\n",
            "w1: [25.44199491] w2: [-23.24604112] bias: [16.25466618] loss: 30.53762317425314\n",
            "Epoch: 4358 / 5000\n",
            "w1: [25.45377743] w2: [-23.24403065] bias: [16.27777114] loss: 30.537657930204265\n",
            "Epoch: 4359 / 5000\n",
            "w1: [25.45161754] w2: [-23.25625232] bias: [16.26367896] loss: 30.536774863754747\n",
            "Epoch: 4360 / 5000\n",
            "w1: [25.45064519] w2: [-23.25702145] bias: [16.25976813] loss: 30.536773606580027\n",
            "Epoch: 4361 / 5000\n",
            "w1: [25.46170228] w2: [-23.26349587] bias: [16.26857889] loss: 30.536199418597047\n",
            "Epoch: 4362 / 5000\n",
            "w1: [25.4653377] w2: [-23.26666143] bias: [16.261529] loss: 30.535825742918167\n",
            "Epoch: 4363 / 5000\n",
            "w1: [25.47150061] w2: [-23.26336595] bias: [16.26740454] loss: 30.535909497328113\n",
            "Epoch: 4364 / 5000\n",
            "w1: [25.4602627] w2: [-23.26880316] bias: [16.24524634] loss: 30.53612163629859\n",
            "Epoch: 4365 / 5000\n",
            "w1: [25.46626474] w2: [-23.24812325] bias: [16.27002905] loss: 30.536868663726356\n",
            "Epoch: 4366 / 5000\n",
            "w1: [25.46913986] w2: [-23.25454347] bias: [16.26819814] loss: 30.536415576807958\n",
            "Epoch: 4367 / 5000\n",
            "w1: [25.47942696] w2: [-23.25054917] bias: [16.29046115] loss: 30.53800364180332\n",
            "Epoch: 4368 / 5000\n",
            "w1: [25.47870197] w2: [-23.2560593] bias: [16.296924] loss: 30.53825579844547\n",
            "Epoch: 4369 / 5000\n",
            "w1: [25.47956286] w2: [-23.24966762] bias: [16.30424381] loss: 30.539548606566928\n",
            "Epoch: 4370 / 5000\n",
            "w1: [25.48959091] w2: [-23.25443393] bias: [16.31108503] loss: 30.54036384467297\n",
            "Epoch: 4371 / 5000\n",
            "w1: [25.4819344] w2: [-23.25192644] bias: [16.3039338] loss: 30.539394978798928\n",
            "Epoch: 4372 / 5000\n",
            "w1: [25.50945314] w2: [-23.2335333] bias: [16.36229693] loss: 30.5546567315009\n",
            "Epoch: 4373 / 5000\n",
            "w1: [25.51664214] w2: [-23.23889992] bias: [16.35922086] loss: 30.55389958670132\n",
            "Epoch: 4374 / 5000\n",
            "w1: [25.51660857] w2: [-23.23857756] bias: [16.35458711] loss: 30.552673847288432\n",
            "Epoch: 4375 / 5000\n",
            "w1: [25.51404203] w2: [-23.2426337] bias: [16.34468257] loss: 30.54944268581779\n",
            "Epoch: 4376 / 5000\n",
            "w1: [25.51906457] w2: [-23.23858776] bias: [16.3525626] loss: 30.552375964076226\n",
            "Epoch: 4377 / 5000\n",
            "w1: [25.50170792] w2: [-23.24621976] bias: [16.32526945] loss: 30.54399411382013\n",
            "Epoch: 4378 / 5000\n",
            "w1: [25.4924867] w2: [-23.24768164] bias: [16.31774053] loss: 30.542063002171215\n",
            "Epoch: 4379 / 5000\n",
            "w1: [25.47519049] w2: [-23.2595722] bias: [16.28443969] loss: 30.536932487534962\n",
            "Epoch: 4380 / 5000\n",
            "w1: [25.46121252] w2: [-23.26535046] bias: [16.26326478] loss: 30.5360446801833\n",
            "Epoch: 4381 / 5000\n",
            "w1: [25.45209823] w2: [-23.27055111] bias: [16.24699105] loss: 30.536488120417495\n",
            "Epoch: 4382 / 5000\n",
            "w1: [25.44446853] w2: [-23.27423268] bias: [16.24091938] loss: 30.537172914659184\n",
            "Epoch: 4383 / 5000\n",
            "w1: [25.43124532] w2: [-23.27684335] bias: [16.22234353] loss: 30.539801765208324\n",
            "Epoch: 4384 / 5000\n",
            "w1: [25.43516941] w2: [-23.26732924] bias: [16.23729903] loss: 30.5382270040839\n",
            "Epoch: 4385 / 5000\n",
            "w1: [25.42253175] w2: [-23.26846106] bias: [16.21492266] loss: 30.541610046723427\n",
            "Epoch: 4386 / 5000\n",
            "w1: [25.41520056] w2: [-23.26745773] bias: [16.20366174] loss: 30.544072555172043\n",
            "Epoch: 4387 / 5000\n",
            "w1: [25.42332649] w2: [-23.27073474] bias: [16.21524245] loss: 30.54148206736008\n",
            "Epoch: 4388 / 5000\n",
            "w1: [25.42279151] w2: [-23.27733526] bias: [16.20751767] loss: 30.54262945203663\n",
            "Epoch: 4389 / 5000\n",
            "w1: [25.42814945] w2: [-23.27078352] bias: [16.21717469] loss: 30.540728497203446\n",
            "Epoch: 4390 / 5000\n",
            "w1: [25.428308] w2: [-23.25076377] bias: [16.23501986] loss: 30.539228918711412\n",
            "Epoch: 4391 / 5000\n",
            "w1: [25.44853053] w2: [-23.25219666] bias: [16.26145044] loss: 30.537050461573116\n",
            "Epoch: 4392 / 5000\n",
            "w1: [25.43512721] w2: [-23.24060563] bias: [16.25891795] loss: 30.53810714503806\n",
            "Epoch: 4393 / 5000\n",
            "w1: [25.44650075] w2: [-23.24858415] bias: [16.25833487] loss: 30.53728158030873\n",
            "Epoch: 4394 / 5000\n",
            "w1: [25.45194417] w2: [-23.24631813] bias: [16.26613347] loss: 30.53722239290863\n",
            "Epoch: 4395 / 5000\n",
            "w1: [25.47340594] w2: [-23.22079093] bias: [16.31269639] loss: 30.542837372612397\n",
            "Epoch: 4396 / 5000\n",
            "w1: [25.45894609] w2: [-23.23757047] bias: [16.28003015] loss: 30.53805560192745\n",
            "Epoch: 4397 / 5000\n",
            "w1: [25.44954861] w2: [-23.24017685] bias: [16.26541062] loss: 30.537566032271908\n",
            "Epoch: 4398 / 5000\n",
            "w1: [25.46991752] w2: [-23.2313028] bias: [16.29220644] loss: 30.539401159349726\n",
            "Epoch: 4399 / 5000\n",
            "w1: [25.470671] w2: [-23.22875717] bias: [16.30122257] loss: 30.540577421272143\n",
            "Epoch: 4400 / 5000\n",
            "w1: [25.49373336] w2: [-23.22015392] bias: [16.33317325] loss: 30.5476630342155\n",
            "Epoch: 4401 / 5000\n",
            "w1: [25.4982653] w2: [-23.21543302] bias: [16.33552291] loss: 30.54900368958117\n",
            "Epoch: 4402 / 5000\n",
            "w1: [25.50440474] w2: [-23.21290218] bias: [16.34520463] loss: 30.552098362370668\n",
            "Epoch: 4403 / 5000\n",
            "w1: [25.5030298] w2: [-23.21863304] bias: [16.33963133] loss: 30.54997207747566\n",
            "Epoch: 4404 / 5000\n",
            "w1: [25.52936622] w2: [-23.19039345] bias: [16.396551] loss: 30.57495016809701\n",
            "Epoch: 4405 / 5000\n",
            "w1: [25.51839028] w2: [-23.18828781] bias: [16.38349951] loss: 30.56867547099845\n",
            "Epoch: 4406 / 5000\n",
            "w1: [25.51662953] w2: [-23.18704396] bias: [16.37680183] loss: 30.566264112380267\n",
            "Epoch: 4407 / 5000\n",
            "w1: [25.51615774] w2: [-23.19288836] bias: [16.36772269] loss: 30.562358572506643\n",
            "Epoch: 4408 / 5000\n",
            "w1: [25.49934977] w2: [-23.20381249] bias: [16.33695522] loss: 30.5506968720312\n",
            "Epoch: 4409 / 5000\n",
            "w1: [25.53228067] w2: [-23.1826898] bias: [16.39578623] loss: 30.576371995217375\n",
            "Epoch: 4410 / 5000\n",
            "w1: [25.54327008] w2: [-23.17938428] bias: [16.42832032] loss: 30.593305950722854\n",
            "Epoch: 4411 / 5000\n",
            "w1: [25.54948523] w2: [-23.18237545] bias: [16.43041671] loss: 30.59507103345192\n",
            "Epoch: 4412 / 5000\n",
            "w1: [25.57208397] w2: [-23.16246329] bias: [16.47832772] loss: 30.63132688980745\n",
            "Epoch: 4413 / 5000\n",
            "w1: [25.56692809] w2: [-23.16322283] bias: [16.47026678] loss: 30.624829898267382\n",
            "Epoch: 4414 / 5000\n",
            "w1: [25.5663776] w2: [-23.17448505] bias: [16.46278814] loss: 30.61784458928752\n",
            "Epoch: 4415 / 5000\n",
            "w1: [25.54846356] w2: [-23.18480135] bias: [16.42899106] loss: 30.593708686524156\n",
            "Epoch: 4416 / 5000\n",
            "w1: [25.56435809] w2: [-23.18632569] bias: [16.4520557] loss: 30.60885433870243\n",
            "Epoch: 4417 / 5000\n",
            "w1: [25.56081209] w2: [-23.19273443] bias: [16.43806118] loss: 30.599386046701856\n",
            "Epoch: 4418 / 5000\n",
            "w1: [25.56102718] w2: [-23.18967467] bias: [16.44073115] loss: 30.601397277967937\n",
            "Epoch: 4419 / 5000\n",
            "w1: [25.56127421] w2: [-23.19134569] bias: [16.43601119] loss: 30.59871860474036\n",
            "Epoch: 4420 / 5000\n",
            "w1: [25.57818024] w2: [-23.1862] bias: [16.45588661] loss: 30.614458353106198\n",
            "Epoch: 4421 / 5000\n",
            "w1: [25.58070913] w2: [-23.1909307] bias: [16.45278168] loss: 30.61236275932736\n",
            "Epoch: 4422 / 5000\n",
            "w1: [25.58155279] w2: [-23.1823123] bias: [16.45147914] loss: 30.61364784758457\n",
            "Epoch: 4423 / 5000\n",
            "w1: [25.58300636] w2: [-23.17601633] bias: [16.46092991] loss: 30.620808703145027\n",
            "Epoch: 4424 / 5000\n",
            "w1: [25.56664742] w2: [-23.18589172] bias: [16.44143367] loss: 30.60381064322454\n",
            "Epoch: 4425 / 5000\n",
            "w1: [25.55814011] w2: [-23.18554798] bias: [16.43125172] loss: 30.596751578735372\n",
            "Epoch: 4426 / 5000\n",
            "w1: [25.55271054] w2: [-23.19339542] bias: [16.41064836] loss: 30.584514284554725\n",
            "Epoch: 4427 / 5000\n",
            "w1: [25.54329986] w2: [-23.19447936] bias: [16.3978666] loss: 30.577163902526312\n",
            "Epoch: 4428 / 5000\n",
            "w1: [25.54277243] w2: [-23.19388299] bias: [16.39424362] loss: 30.575704063994763\n",
            "Epoch: 4429 / 5000\n",
            "w1: [25.55481513] w2: [-23.19916448] bias: [16.41415422] loss: 30.585480691262983\n",
            "Epoch: 4430 / 5000\n",
            "w1: [25.55476884] w2: [-23.20465235] bias: [16.40652701] loss: 30.581160980607468\n",
            "Epoch: 4431 / 5000\n",
            "w1: [25.55728875] w2: [-23.20292763] bias: [16.41406848] loss: 30.58526467900656\n",
            "Epoch: 4432 / 5000\n",
            "w1: [25.55177407] w2: [-23.20215514] bias: [16.40862875] loss: 30.581938681099295\n",
            "Epoch: 4433 / 5000\n",
            "w1: [25.57164058] w2: [-23.19382631] bias: [16.43723592] loss: 30.6012172331758\n",
            "Epoch: 4434 / 5000\n",
            "w1: [25.56062548] w2: [-23.20909789] bias: [16.42051839] loss: 30.587783068972172\n",
            "Epoch: 4435 / 5000\n",
            "w1: [25.56755524] w2: [-23.21149515] bias: [16.44482948] loss: 30.600758072625606\n",
            "Epoch: 4436 / 5000\n",
            "w1: [25.55747206] w2: [-23.21986649] bias: [16.43376683] loss: 30.591433095205847\n",
            "Epoch: 4437 / 5000\n",
            "w1: [25.5587326] w2: [-23.22456019] bias: [16.42720566] loss: 30.58774748803028\n",
            "Epoch: 4438 / 5000\n",
            "w1: [25.55749795] w2: [-23.22907836] bias: [16.4252906] loss: 30.5858169719646\n",
            "Epoch: 4439 / 5000\n",
            "w1: [25.54635987] w2: [-23.24468639] bias: [16.39108509] loss: 30.567217252801953\n",
            "Epoch: 4440 / 5000\n",
            "w1: [25.556753] w2: [-23.2455102] bias: [16.41814697] loss: 30.57968643182802\n",
            "Epoch: 4441 / 5000\n",
            "w1: [25.55215319] w2: [-23.24748689] bias: [16.40797923] loss: 30.574272936058133\n",
            "Epoch: 4442 / 5000\n",
            "w1: [25.54020951] w2: [-23.25985161] bias: [16.38235377] loss: 30.561105274725747\n",
            "Epoch: 4443 / 5000\n",
            "w1: [25.51589626] w2: [-23.26720774] bias: [16.33825554] loss: 30.54550832618286\n",
            "Epoch: 4444 / 5000\n",
            "w1: [25.52667044] w2: [-23.26107125] bias: [16.36083266] loss: 30.552728035641476\n",
            "Epoch: 4445 / 5000\n",
            "w1: [25.53249917] w2: [-23.26857492] bias: [16.36413556] loss: 30.5533827099184\n",
            "Epoch: 4446 / 5000\n",
            "w1: [25.5289694] w2: [-23.27270602] bias: [16.35464064] loss: 30.549944131131042\n",
            "Epoch: 4447 / 5000\n",
            "w1: [25.54002212] w2: [-23.27831924] bias: [16.36072164] loss: 30.552071085180476\n",
            "Epoch: 4448 / 5000\n",
            "w1: [25.54806452] w2: [-23.28398256] bias: [16.36068137] loss: 30.552268607205285\n",
            "Epoch: 4449 / 5000\n",
            "w1: [25.54909849] w2: [-23.26309323] bias: [16.37289797] loss: 30.558742632896152\n",
            "Epoch: 4450 / 5000\n",
            "w1: [25.56535974] w2: [-23.25363682] bias: [16.41081012] loss: 30.576806108573162\n",
            "Epoch: 4451 / 5000\n",
            "w1: [25.55304894] w2: [-23.2584971] bias: [16.38976152] loss: 30.565733144877157\n",
            "Epoch: 4452 / 5000\n",
            "w1: [25.55786804] w2: [-23.26817219] bias: [16.38141401] loss: 30.562105723215524\n",
            "Epoch: 4453 / 5000\n",
            "w1: [25.55706975] w2: [-23.26854934] bias: [16.37314096] loss: 30.559150343321043\n",
            "Epoch: 4454 / 5000\n",
            "w1: [25.56321619] w2: [-23.26675978] bias: [16.3770515] loss: 30.561557451635878\n",
            "Epoch: 4455 / 5000\n",
            "w1: [25.57193511] w2: [-23.26177477] bias: [16.38987795] loss: 30.568256189073214\n",
            "Epoch: 4456 / 5000\n",
            "w1: [25.5639216] w2: [-23.26688598] bias: [16.38041361] loss: 30.562811027022345\n",
            "Epoch: 4457 / 5000\n",
            "w1: [25.56555398] w2: [-23.27831125] bias: [16.37501619] loss: 30.559619014273515\n",
            "Epoch: 4458 / 5000\n",
            "w1: [25.56433247] w2: [-23.281839] bias: [16.36422392] loss: 30.555510772842243\n",
            "Epoch: 4459 / 5000\n",
            "w1: [25.56185939] w2: [-23.26869913] bias: [16.36530647] loss: 30.55722475799891\n",
            "Epoch: 4460 / 5000\n",
            "w1: [25.55231473] w2: [-23.2714734] bias: [16.3462922] loss: 30.550206934207804\n",
            "Epoch: 4461 / 5000\n",
            "w1: [25.54568444] w2: [-23.28141687] bias: [16.329002] loss: 30.544308197896218\n",
            "Epoch: 4462 / 5000\n",
            "w1: [25.54411998] w2: [-23.2852554] bias: [16.32059902] loss: 30.542053196093597\n",
            "Epoch: 4463 / 5000\n",
            "w1: [25.5477771] w2: [-23.28850228] bias: [16.31687344] loss: 30.54125602148742\n",
            "Epoch: 4464 / 5000\n",
            "w1: [25.54714071] w2: [-23.27827754] bias: [16.32179902] loss: 30.54317531669722\n",
            "Epoch: 4465 / 5000\n",
            "w1: [25.55298208] w2: [-23.27055462] bias: [16.33245346] loss: 30.546840951571937\n",
            "Epoch: 4466 / 5000\n",
            "w1: [25.55703584] w2: [-23.27255292] bias: [16.33542389] loss: 30.547725017671567\n",
            "Epoch: 4467 / 5000\n",
            "w1: [25.56461001] w2: [-23.27418083] bias: [16.34429383] loss: 30.550633575200106\n",
            "Epoch: 4468 / 5000\n",
            "w1: [25.54856205] w2: [-23.27898389] bias: [16.32327404] loss: 30.543522493642243\n",
            "Epoch: 4469 / 5000\n",
            "w1: [25.54714126] w2: [-23.28154882] bias: [16.32366329] loss: 30.543249880368656\n",
            "Epoch: 4470 / 5000\n",
            "w1: [25.53157067] w2: [-23.28782414] bias: [16.29927691] loss: 30.537527604893594\n",
            "Epoch: 4471 / 5000\n",
            "w1: [25.54071413] w2: [-23.27063497] bias: [16.32864399] loss: 30.544932036304097\n",
            "Epoch: 4472 / 5000\n",
            "w1: [25.52122006] w2: [-23.27997642] bias: [16.2966577] loss: 30.537416271580916\n",
            "Epoch: 4473 / 5000\n",
            "w1: [25.50794677] w2: [-23.28090834] bias: [16.28008352] loss: 30.53533580952608\n",
            "Epoch: 4474 / 5000\n",
            "w1: [25.49883802] w2: [-23.29094738] bias: [16.25505516] loss: 30.533662591942235\n",
            "Epoch: 4475 / 5000\n",
            "w1: [25.48530156] w2: [-23.2967022] bias: [16.23105556] loss: 30.534467112593358\n",
            "Epoch: 4476 / 5000\n",
            "w1: [25.48944545] w2: [-23.29217334] bias: [16.24155737] loss: 30.533995485612753\n",
            "Epoch: 4477 / 5000\n",
            "w1: [25.47905603] w2: [-23.29259808] bias: [16.23521192] loss: 30.534760801551016\n",
            "Epoch: 4478 / 5000\n",
            "w1: [25.47295798] w2: [-23.29810841] bias: [16.22881881] loss: 30.535419370726736\n",
            "Epoch: 4479 / 5000\n",
            "w1: [25.46559498] w2: [-23.30681536] bias: [16.20720846] loss: 30.53803553424181\n",
            "Epoch: 4480 / 5000\n",
            "w1: [25.47290821] w2: [-23.30673079] bias: [16.21364995] loss: 30.536604316220203\n",
            "Epoch: 4481 / 5000\n",
            "w1: [25.46221498] w2: [-23.31786426] bias: [16.20607904] loss: 30.538588987441155\n",
            "Epoch: 4482 / 5000\n",
            "w1: [25.47991609] w2: [-23.30459256] bias: [16.2421434] loss: 30.53416469801661\n",
            "Epoch: 4483 / 5000\n",
            "w1: [25.47417968] w2: [-23.30558097] bias: [16.23050369] loss: 30.53510847687923\n",
            "Epoch: 4484 / 5000\n",
            "w1: [25.46793235] w2: [-23.30774089] bias: [16.21638333] loss: 30.53678367992508\n",
            "Epoch: 4485 / 5000\n",
            "w1: [25.46227753] w2: [-23.31327369] bias: [16.20534426] loss: 30.53865088370653\n",
            "Epoch: 4486 / 5000\n",
            "w1: [25.46732171] w2: [-23.30680303] bias: [16.21423411] loss: 30.537066249518237\n",
            "Epoch: 4487 / 5000\n",
            "w1: [25.48288959] w2: [-23.30942754] bias: [16.23225249] loss: 30.534327224819236\n",
            "Epoch: 4488 / 5000\n",
            "w1: [25.49782858] w2: [-23.31018635] bias: [16.24276336] loss: 30.533055396270854\n",
            "Epoch: 4489 / 5000\n",
            "w1: [25.51069702] w2: [-23.30583067] bias: [16.2651275] loss: 30.533057378084163\n",
            "Epoch: 4490 / 5000\n",
            "w1: [25.51343942] w2: [-23.29571179] bias: [16.27247512] loss: 30.533925940419355\n",
            "Epoch: 4491 / 5000\n",
            "w1: [25.52135886] w2: [-23.28567434] bias: [16.28889963] loss: 30.5360658826208\n",
            "Epoch: 4492 / 5000\n",
            "w1: [25.50822714] w2: [-23.29752808] bias: [16.26265874] loss: 30.53337795284669\n",
            "Epoch: 4493 / 5000\n",
            "w1: [25.50303712] w2: [-23.29773542] bias: [16.26015223] loss: 30.53339106032407\n",
            "Epoch: 4494 / 5000\n",
            "w1: [25.50335182] w2: [-23.29988825] bias: [16.2593461] loss: 30.533270543899683\n",
            "Epoch: 4495 / 5000\n",
            "w1: [25.52702698] w2: [-23.30141289] bias: [16.28579699] loss: 30.534795293021077\n",
            "Epoch: 4496 / 5000\n",
            "w1: [25.51483249] w2: [-23.30582523] bias: [16.27059335] loss: 30.53327809238577\n",
            "Epoch: 4497 / 5000\n",
            "w1: [25.51928698] w2: [-23.30722526] bias: [16.27691254] loss: 30.533601293947587\n",
            "Epoch: 4498 / 5000\n",
            "w1: [25.51710861] w2: [-23.30716488] bias: [16.27123438] loss: 30.533231353399856\n",
            "Epoch: 4499 / 5000\n",
            "w1: [25.5131764] w2: [-23.31332834] bias: [16.26176967] loss: 30.532555564222825\n",
            "Epoch: 4500 / 5000\n",
            "w1: [25.50935358] w2: [-23.31031356] bias: [16.26344621] loss: 30.532818662692303\n",
            "Epoch: 4501 / 5000\n",
            "w1: [25.50415808] w2: [-23.30193545] bias: [16.26889286] loss: 30.53350404015359\n",
            "Epoch: 4502 / 5000\n",
            "w1: [25.5012975] w2: [-23.30128484] bias: [16.26767507] loss: 30.53352943619912\n",
            "Epoch: 4503 / 5000\n",
            "w1: [25.50850679] w2: [-23.30331253] bias: [16.27504412] loss: 30.533715342761163\n",
            "Epoch: 4504 / 5000\n",
            "w1: [25.49562014] w2: [-23.31255387] bias: [16.24806742] loss: 30.53300929461377\n",
            "Epoch: 4505 / 5000\n",
            "w1: [25.49549372] w2: [-23.30710219] bias: [16.25504532] loss: 30.533165933779234\n",
            "Epoch: 4506 / 5000\n",
            "w1: [25.51119986] w2: [-23.30036924] bias: [16.28701059] loss: 30.534783592777302\n",
            "Epoch: 4507 / 5000\n",
            "w1: [25.52634907] w2: [-23.30592345] bias: [16.29178458] loss: 30.53513209267407\n",
            "Epoch: 4508 / 5000\n",
            "w1: [25.51287814] w2: [-23.31315633] bias: [16.26506479] loss: 30.53268888134243\n",
            "Epoch: 4509 / 5000\n",
            "w1: [25.49355656] w2: [-23.30681453] bias: [16.25076705] loss: 30.533250807297158\n",
            "Epoch: 4510 / 5000\n",
            "w1: [25.48335091] w2: [-23.31664343] bias: [16.22410578] loss: 30.534724716545128\n",
            "Epoch: 4511 / 5000\n",
            "w1: [25.46599932] w2: [-23.31906207] bias: [16.19450008] loss: 30.539834211996606\n",
            "Epoch: 4512 / 5000\n",
            "w1: [25.45155694] w2: [-23.31949195] bias: [16.17720177] loss: 30.544857914982355\n",
            "Epoch: 4513 / 5000\n",
            "w1: [25.44352109] w2: [-23.32174281] bias: [16.16362771] loss: 30.549203525504794\n",
            "Epoch: 4514 / 5000\n",
            "w1: [25.44740553] w2: [-23.30493697] bias: [16.1782843] loss: 30.54486423631416\n",
            "Epoch: 4515 / 5000\n",
            "w1: [25.42546124] w2: [-23.31972471] bias: [16.14102871] loss: 30.55855346871568\n",
            "Epoch: 4516 / 5000\n",
            "w1: [25.42988081] w2: [-23.32509866] bias: [16.14037821] loss: 30.558178008367513\n",
            "Epoch: 4517 / 5000\n",
            "w1: [25.42566374] w2: [-23.33028773] bias: [16.12749112] loss: 30.56350354879474\n",
            "Epoch: 4518 / 5000\n",
            "w1: [25.44330354] w2: [-23.32770226] bias: [16.15696198] loss: 30.551149411519656\n",
            "Epoch: 4519 / 5000\n",
            "w1: [25.45281624] w2: [-23.33086325] bias: [16.15973107] loss: 30.548964256945975\n",
            "Epoch: 4520 / 5000\n",
            "w1: [25.44416128] w2: [-23.33463212] bias: [16.14528195] loss: 30.55449821889846\n",
            "Epoch: 4521 / 5000\n",
            "w1: [25.45321609] w2: [-23.32887152] bias: [16.15653884] loss: 30.54960222528491\n",
            "Epoch: 4522 / 5000\n",
            "w1: [25.457952] w2: [-23.32777973] bias: [16.16422907] loss: 30.54694825767302\n",
            "Epoch: 4523 / 5000\n",
            "w1: [25.48144592] w2: [-23.32803404] bias: [16.1965682] loss: 30.537850612150155\n",
            "Epoch: 4524 / 5000\n",
            "w1: [25.47928108] w2: [-23.32070661] bias: [16.2061842] loss: 30.536799692847303\n",
            "Epoch: 4525 / 5000\n",
            "w1: [25.47557616] w2: [-23.32267983] bias: [16.20918116] loss: 30.536823879387605\n",
            "Epoch: 4526 / 5000\n",
            "w1: [25.45898893] w2: [-23.33350599] bias: [16.17623792] loss: 30.54436779472739\n",
            "Epoch: 4527 / 5000\n",
            "w1: [25.46833851] w2: [-23.32307006] bias: [16.19894506] loss: 30.538942917649628\n",
            "Epoch: 4528 / 5000\n",
            "w1: [25.47831779] w2: [-23.32488261] bias: [16.20793194] loss: 30.53670201754597\n",
            "Epoch: 4529 / 5000\n",
            "w1: [25.48322551] w2: [-23.32375849] bias: [16.21592669] loss: 30.535385086478115\n",
            "Epoch: 4530 / 5000\n",
            "w1: [25.47355239] w2: [-23.32442449] bias: [16.20540368] loss: 30.5374998502326\n",
            "Epoch: 4531 / 5000\n",
            "w1: [25.46351203] w2: [-23.32319019] bias: [16.19149326] loss: 30.5406795376466\n",
            "Epoch: 4532 / 5000\n",
            "w1: [25.46096976] w2: [-23.32441734] bias: [16.17906815] loss: 30.543268759690314\n",
            "Epoch: 4533 / 5000\n",
            "w1: [25.44316079] w2: [-23.33765028] bias: [16.14584973] loss: 30.554685383249566\n",
            "Epoch: 4534 / 5000\n",
            "w1: [25.44630487] w2: [-23.34042573] bias: [16.14601956] loss: 30.55419298439614\n",
            "Epoch: 4535 / 5000\n",
            "w1: [25.4369341] w2: [-23.35093514] bias: [16.1266602] loss: 30.562771211084726\n",
            "Epoch: 4536 / 5000\n",
            "w1: [25.46500169] w2: [-23.35201667] bias: [16.15740206] loss: 30.548393924085744\n",
            "Epoch: 4537 / 5000\n",
            "w1: [25.45835917] w2: [-23.35829278] bias: [16.14205763] loss: 30.55403976263293\n",
            "Epoch: 4538 / 5000\n",
            "w1: [25.45189888] w2: [-23.35802499] bias: [16.14679571] loss: 30.553878273814867\n",
            "Epoch: 4539 / 5000\n",
            "w1: [25.4459132] w2: [-23.36796889] bias: [16.12811412] loss: 30.561551983320825\n",
            "Epoch: 4540 / 5000\n",
            "w1: [25.44826123] w2: [-23.37005451] bias: [16.13336307] loss: 30.55946216835632\n",
            "Epoch: 4541 / 5000\n",
            "w1: [25.43996883] w2: [-23.37813212] bias: [16.12099633] loss: 30.566130567853094\n",
            "Epoch: 4542 / 5000\n",
            "w1: [25.4548282] w2: [-23.38194303] bias: [16.13285723] loss: 30.559077900067052\n",
            "Epoch: 4543 / 5000\n",
            "w1: [25.44907673] w2: [-23.38759893] bias: [16.11949248] loss: 30.56536392574644\n",
            "Epoch: 4544 / 5000\n",
            "w1: [25.43523486] w2: [-23.38386804] bias: [16.10886008] loss: 30.5723511259652\n",
            "Epoch: 4545 / 5000\n",
            "w1: [25.42910899] w2: [-23.39531775] bias: [16.08892505] loss: 30.58349681048763\n",
            "Epoch: 4546 / 5000\n",
            "w1: [25.43491002] w2: [-23.3975298] bias: [16.1050292] loss: 30.575252883710238\n",
            "Epoch: 4547 / 5000\n",
            "w1: [25.42461127] w2: [-23.40691285] bias: [16.09886795] loss: 30.581512909257313\n",
            "Epoch: 4548 / 5000\n",
            "w1: [25.43147742] w2: [-23.4023254] bias: [16.11344377] loss: 30.57313801153315\n",
            "Epoch: 4549 / 5000\n",
            "w1: [25.44490863] w2: [-23.39800179] bias: [16.13120743] loss: 30.562942916190735\n",
            "Epoch: 4550 / 5000\n",
            "w1: [25.44532727] w2: [-23.38115263] bias: [16.14646666] loss: 30.55663506353722\n",
            "Epoch: 4551 / 5000\n",
            "w1: [25.43952873] w2: [-23.38599236] bias: [16.12958135] loss: 30.563774919992944\n",
            "Epoch: 4552 / 5000\n",
            "w1: [25.44513739] w2: [-23.37963914] bias: [16.15270868] loss: 30.554691106889067\n",
            "Epoch: 4553 / 5000\n",
            "w1: [25.4326328] w2: [-23.38584602] bias: [16.13118672] loss: 30.56473249883686\n",
            "Epoch: 4554 / 5000\n",
            "w1: [25.45397082] w2: [-23.38777021] bias: [16.15459836] loss: 30.552940156950637\n",
            "Epoch: 4555 / 5000\n",
            "w1: [25.44608418] w2: [-23.39368235] bias: [16.13893561] loss: 30.559736877021876\n",
            "Epoch: 4556 / 5000\n",
            "w1: [25.45221571] w2: [-23.3898702] bias: [16.15098026] loss: 30.554459638333647\n",
            "Epoch: 4557 / 5000\n",
            "w1: [25.45650999] w2: [-23.39495752] bias: [16.14635262] loss: 30.55533972209622\n",
            "Epoch: 4558 / 5000\n",
            "w1: [25.45080588] w2: [-23.39997008] bias: [16.13333624] loss: 30.5610736834731\n",
            "Epoch: 4559 / 5000\n",
            "w1: [25.43594344] w2: [-23.41285691] bias: [16.10638847] loss: 30.575918998480365\n",
            "Epoch: 4560 / 5000\n",
            "w1: [25.43015599] w2: [-23.41663587] bias: [16.0940457] loss: 30.5832046176414\n",
            "Epoch: 4561 / 5000\n",
            "w1: [25.43008479] w2: [-23.42465067] bias: [16.09151672] loss: 30.58526515391082\n",
            "Epoch: 4562 / 5000\n",
            "w1: [25.4406202] w2: [-23.41715758] bias: [16.10805385] loss: 30.574462437521504\n",
            "Epoch: 4563 / 5000\n",
            "w1: [25.43165665] w2: [-23.42332996] bias: [16.09293271] loss: 30.58403397114729\n",
            "Epoch: 4564 / 5000\n",
            "w1: [25.42999569] w2: [-23.40785242] bias: [16.10837328] loss: 30.576117155094696\n",
            "Epoch: 4565 / 5000\n",
            "w1: [25.43090257] w2: [-23.40114377] bias: [16.11671768] loss: 30.571864576283566\n",
            "Epoch: 4566 / 5000\n",
            "w1: [25.4376914] w2: [-23.3969936] bias: [16.13363415] loss: 30.563607100789675\n",
            "Epoch: 4567 / 5000\n",
            "w1: [25.45687059] w2: [-23.39112074] bias: [16.16079641] loss: 30.550853546610785\n",
            "Epoch: 4568 / 5000\n",
            "w1: [25.45740113] w2: [-23.40029575] bias: [16.15329655] loss: 30.553418677073747\n",
            "Epoch: 4569 / 5000\n",
            "w1: [25.46934261] w2: [-23.3974349] bias: [16.17468856] loss: 30.545485229675833\n",
            "Epoch: 4570 / 5000\n",
            "w1: [25.46462314] w2: [-23.38060962] bias: [16.18359244] loss: 30.543531189685186\n",
            "Epoch: 4571 / 5000\n",
            "w1: [25.47040257] w2: [-23.36773502] bias: [16.19767753] loss: 30.539633250000534\n",
            "Epoch: 4572 / 5000\n",
            "w1: [25.462167] w2: [-23.38169476] bias: [16.17894659] loss: 30.544971397510697\n",
            "Epoch: 4573 / 5000\n",
            "w1: [25.46044425] w2: [-23.36938107] bias: [16.18653072] loss: 30.543146060599554\n",
            "Epoch: 4574 / 5000\n",
            "w1: [25.43813791] w2: [-23.38145356] bias: [16.14842814] loss: 30.55748572194516\n",
            "Epoch: 4575 / 5000\n",
            "w1: [25.43491627] w2: [-23.38989025] bias: [16.1375595] loss: 30.562310780595013\n",
            "Epoch: 4576 / 5000\n",
            "w1: [25.43335636] w2: [-23.38796426] bias: [16.14990116] loss: 30.55842046134288\n",
            "Epoch: 4577 / 5000\n",
            "w1: [25.45417955] w2: [-23.37119561] bias: [16.19301394] loss: 30.542787890055376\n",
            "Epoch: 4578 / 5000\n",
            "w1: [25.45962781] w2: [-23.36792184] bias: [16.20005925] loss: 30.540614148246767\n",
            "Epoch: 4579 / 5000\n",
            "w1: [25.4583288] w2: [-23.37394915] bias: [16.19177997] loss: 30.542528529558105\n",
            "Epoch: 4580 / 5000\n",
            "w1: [25.48352307] w2: [-23.35731573] bias: [16.23382942] loss: 30.5336280744773\n",
            "Epoch: 4581 / 5000\n",
            "w1: [25.48433398] w2: [-23.36399209] bias: [16.22604648] loss: 30.53423806401989\n",
            "Epoch: 4582 / 5000\n",
            "w1: [25.483903] w2: [-23.36069902] bias: [16.23370147] loss: 30.53359010063324\n",
            "Epoch: 4583 / 5000\n",
            "w1: [25.47834361] w2: [-23.3404755] bias: [16.24810198] loss: 30.533284526498946\n",
            "Epoch: 4584 / 5000\n",
            "w1: [25.47212783] w2: [-23.33370719] bias: [16.24393312] loss: 30.534018188355\n",
            "Epoch: 4585 / 5000\n",
            "w1: [25.47667839] w2: [-23.32908447] bias: [16.26049465] loss: 30.533235523491417\n",
            "Epoch: 4586 / 5000\n",
            "w1: [25.46440105] w2: [-23.3393191] bias: [16.22816736] loss: 30.53583509007305\n",
            "Epoch: 4587 / 5000\n",
            "w1: [25.45769283] w2: [-23.34974201] bias: [16.21962241] loss: 30.53752189131073\n",
            "Epoch: 4588 / 5000\n",
            "w1: [25.45300541] w2: [-23.35308177] bias: [16.20416555] loss: 30.540430771883628\n",
            "Epoch: 4589 / 5000\n",
            "w1: [25.45988403] w2: [-23.34554546] bias: [16.21525905] loss: 30.53782870632017\n",
            "Epoch: 4590 / 5000\n",
            "w1: [25.4758382] w2: [-23.34196791] bias: [16.23788986] loss: 30.534036401982863\n",
            "Epoch: 4591 / 5000\n",
            "w1: [25.47838175] w2: [-23.32941609] bias: [16.24829788] loss: 30.53348129906178\n",
            "Epoch: 4592 / 5000\n",
            "w1: [25.47644419] w2: [-23.32755638] bias: [16.243171] loss: 30.533868541662432\n",
            "Epoch: 4593 / 5000\n",
            "w1: [25.45911174] w2: [-23.33609259] bias: [16.21289644] loss: 30.538149479652066\n",
            "Epoch: 4594 / 5000\n",
            "w1: [25.46198668] w2: [-23.33978135] bias: [16.2093954] loss: 30.538347614208263\n",
            "Epoch: 4595 / 5000\n",
            "w1: [25.45990304] w2: [-23.35429442] bias: [16.19472447] loss: 30.541212519582437\n",
            "Epoch: 4596 / 5000\n",
            "w1: [25.48722239] w2: [-23.33985649] bias: [16.24284714] loss: 30.532986458805837\n",
            "Epoch: 4597 / 5000\n",
            "w1: [25.49032286] w2: [-23.3333173] bias: [16.25987336] loss: 30.532516850945967\n",
            "Epoch: 4598 / 5000\n",
            "w1: [25.48687746] w2: [-23.33145795] bias: [16.25555593] loss: 30.532773348442465\n",
            "Epoch: 4599 / 5000\n",
            "w1: [25.49468809] w2: [-23.33108903] bias: [16.25463221] loss: 30.5324413022346\n",
            "Epoch: 4600 / 5000\n",
            "w1: [25.49752797] w2: [-23.32680618] bias: [16.26488547] loss: 30.532495948877962\n",
            "Epoch: 4601 / 5000\n",
            "w1: [25.50742554] w2: [-23.32783318] bias: [16.28006922] loss: 30.53279345556451\n",
            "Epoch: 4602 / 5000\n",
            "w1: [25.52016722] w2: [-23.32920702] bias: [16.28534559] loss: 30.533042688014156\n",
            "Epoch: 4603 / 5000\n",
            "w1: [25.5168884] w2: [-23.3351828] bias: [16.27729478] loss: 30.53221034526388\n",
            "Epoch: 4604 / 5000\n",
            "w1: [25.53594889] w2: [-23.32857545] bias: [16.30142677] loss: 30.534998091551927\n",
            "Epoch: 4605 / 5000\n",
            "w1: [25.55558111] w2: [-23.32979452] bias: [16.32130008] loss: 30.53892137280752\n",
            "Epoch: 4606 / 5000\n",
            "w1: [25.54501635] w2: [-23.33542471] bias: [16.29912347] loss: 30.534510511835435\n",
            "Epoch: 4607 / 5000\n",
            "w1: [25.53098] w2: [-23.34699355] bias: [16.27003583] loss: 30.531164339224677\n",
            "Epoch: 4608 / 5000\n",
            "w1: [25.51593445] w2: [-23.36354628] bias: [16.23699002] loss: 30.53112888318895\n",
            "Epoch: 4609 / 5000\n",
            "w1: [25.50862699] w2: [-23.36584589] bias: [16.22482015] loss: 30.532334130126294\n",
            "Epoch: 4610 / 5000\n",
            "w1: [25.50547414] w2: [-23.37469909] bias: [16.21079736] loss: 30.5339475137459\n",
            "Epoch: 4611 / 5000\n",
            "w1: [25.51903785] w2: [-23.36556366] bias: [16.23003905] loss: 30.531254718942588\n",
            "Epoch: 4612 / 5000\n",
            "w1: [25.51515985] w2: [-23.37201663] bias: [16.21892138] loss: 30.532279124537464\n",
            "Epoch: 4613 / 5000\n",
            "w1: [25.50333197] w2: [-23.38211878] bias: [16.19584568] loss: 30.536236155018663\n",
            "Epoch: 4614 / 5000\n",
            "w1: [25.50999522] w2: [-23.38023192] bias: [16.21242194] loss: 30.533374688951664\n",
            "Epoch: 4615 / 5000\n",
            "w1: [25.52595009] w2: [-23.38876239] bias: [16.22348731] loss: 30.531032094438277\n",
            "Epoch: 4616 / 5000\n",
            "w1: [25.54367855] w2: [-23.38230684] bias: [16.24965715] loss: 30.52916370504008\n",
            "Epoch: 4617 / 5000\n",
            "w1: [25.55925247] w2: [-23.3811792] bias: [16.26435924] loss: 30.529181180556428\n",
            "Epoch: 4618 / 5000\n",
            "w1: [25.57343375] w2: [-23.37497154] bias: [16.28291418] loss: 30.53090588246626\n",
            "Epoch: 4619 / 5000\n",
            "w1: [25.56860238] w2: [-23.37174257] bias: [16.27534694] loss: 30.530311904813004\n",
            "Epoch: 4620 / 5000\n",
            "w1: [25.58525299] w2: [-23.37006136] bias: [16.28991219] loss: 30.532333984628682\n",
            "Epoch: 4621 / 5000\n",
            "w1: [25.58157338] w2: [-23.37013036] bias: [16.29225702] loss: 30.532508184222564\n",
            "Epoch: 4622 / 5000\n",
            "w1: [25.57312294] w2: [-23.37573522] bias: [16.27557057] loss: 30.53017279711074\n",
            "Epoch: 4623 / 5000\n",
            "w1: [25.608651] w2: [-23.37733793] bias: [16.32054697] loss: 30.538346732057466\n",
            "Epoch: 4624 / 5000\n",
            "w1: [25.6140182] w2: [-23.37884665] bias: [16.31943736] loss: 30.538401240424918\n",
            "Epoch: 4625 / 5000\n",
            "w1: [25.62017404] w2: [-23.37032371] bias: [16.3296863] loss: 30.54210390029873\n",
            "Epoch: 4626 / 5000\n",
            "w1: [25.61615082] w2: [-23.37898715] bias: [16.32208812] loss: 30.53914129730875\n",
            "Epoch: 4627 / 5000\n",
            "w1: [25.6108536] w2: [-23.38927159] bias: [16.30398651] loss: 30.53432552274777\n",
            "Epoch: 4628 / 5000\n",
            "w1: [25.60855321] w2: [-23.38953942] bias: [16.29561011] loss: 30.532806330507736\n",
            "Epoch: 4629 / 5000\n",
            "w1: [25.6004296] w2: [-23.39280479] bias: [16.27785569] loss: 30.529965854512685\n",
            "Epoch: 4630 / 5000\n",
            "w1: [25.60544784] w2: [-23.39242425] bias: [16.28122741] loss: 30.53051461357972\n",
            "Epoch: 4631 / 5000\n",
            "w1: [25.61009586] w2: [-23.391146] bias: [16.28450843] loss: 30.531169457316707\n",
            "Epoch: 4632 / 5000\n",
            "w1: [25.61199173] w2: [-23.40299786] bias: [16.27634002] loss: 30.529526362201484\n",
            "Epoch: 4633 / 5000\n",
            "w1: [25.60554543] w2: [-23.41203776] bias: [16.25880058] loss: 30.52745309088162\n",
            "Epoch: 4634 / 5000\n",
            "w1: [25.60582115] w2: [-23.41140468] bias: [16.25728422] loss: 30.527383653730535\n",
            "Epoch: 4635 / 5000\n",
            "w1: [25.60455911] w2: [-23.40974815] bias: [16.26637117] loss: 30.528091720741976\n",
            "Epoch: 4636 / 5000\n",
            "w1: [25.61074806] w2: [-23.41269737] bias: [16.28020569] loss: 30.529386340763732\n",
            "Epoch: 4637 / 5000\n",
            "w1: [25.61828195] w2: [-23.42017205] bias: [16.28054043] loss: 30.52922664938473\n",
            "Epoch: 4638 / 5000\n",
            "w1: [25.63706151] w2: [-23.39359631] bias: [16.32340246] loss: 30.53994650678538\n",
            "Epoch: 4639 / 5000\n",
            "w1: [25.6524605] w2: [-23.3921653] bias: [16.34475087] loss: 30.547478254240318\n",
            "Epoch: 4640 / 5000\n",
            "w1: [25.63107944] w2: [-23.40594129] bias: [16.30565466] loss: 30.534626687352766\n",
            "Epoch: 4641 / 5000\n",
            "w1: [25.61762551] w2: [-23.41298359] bias: [16.28825301] loss: 30.530595761490183\n",
            "Epoch: 4642 / 5000\n",
            "w1: [25.60526653] w2: [-23.42018184] bias: [16.26454385] loss: 30.527499623981317\n",
            "Epoch: 4643 / 5000\n",
            "w1: [25.5914347] w2: [-23.43239324] bias: [16.23372549] loss: 30.526472268613734\n",
            "Epoch: 4644 / 5000\n",
            "w1: [25.57853689] w2: [-23.43861043] bias: [16.22100284] loss: 30.52747736750641\n",
            "Epoch: 4645 / 5000\n",
            "w1: [25.567936] w2: [-23.44406464] bias: [16.20537469] loss: 30.529486117308625\n",
            "Epoch: 4646 / 5000\n",
            "w1: [25.56038483] w2: [-23.4459318] bias: [16.19256763] loss: 30.53173779932118\n",
            "Epoch: 4647 / 5000\n",
            "w1: [25.56081989] w2: [-23.44592817] bias: [16.19234022] loss: 30.5317239375123\n",
            "Epoch: 4648 / 5000\n",
            "w1: [25.55351264] w2: [-23.45625255] bias: [16.16998652] loss: 30.536579420070137\n",
            "Epoch: 4649 / 5000\n",
            "w1: [25.55676368] w2: [-23.45725646] bias: [16.16866463] loss: 30.5364425736181\n",
            "Epoch: 4650 / 5000\n",
            "w1: [25.54013318] w2: [-23.47005121] bias: [16.12775192] loss: 30.549954286453175\n",
            "Epoch: 4651 / 5000\n",
            "w1: [25.54363032] w2: [-23.45516078] bias: [16.13821009] loss: 30.545369786643988\n",
            "Epoch: 4652 / 5000\n",
            "w1: [25.55600085] w2: [-23.45029711] bias: [16.15285085] loss: 30.539546104107725\n",
            "Epoch: 4653 / 5000\n",
            "w1: [25.57738157] w2: [-23.44463388] bias: [16.18658636] loss: 30.530793728910123\n",
            "Epoch: 4654 / 5000\n",
            "w1: [25.57654317] w2: [-23.44039392] bias: [16.18894711] loss: 30.530502489752173\n",
            "Epoch: 4655 / 5000\n",
            "w1: [25.56285356] w2: [-23.44003987] bias: [16.17235258] loss: 30.53440375031073\n",
            "Epoch: 4656 / 5000\n",
            "w1: [25.55567049] w2: [-23.44293067] bias: [16.15532578] loss: 30.53872309857395\n",
            "Epoch: 4657 / 5000\n",
            "w1: [25.56109215] w2: [-23.44547993] bias: [16.15853611] loss: 30.53740019378858\n",
            "Epoch: 4658 / 5000\n",
            "w1: [25.57000321] w2: [-23.44164772] bias: [16.19678089] loss: 30.530202743362565\n",
            "Epoch: 4659 / 5000\n",
            "w1: [25.5609114] w2: [-23.42713004] bias: [16.20638036] loss: 30.529828589971707\n",
            "Epoch: 4660 / 5000\n",
            "w1: [25.57637505] w2: [-23.42756682] bias: [16.21834794] loss: 30.527802658154215\n",
            "Epoch: 4661 / 5000\n",
            "w1: [25.56194656] w2: [-23.44185295] bias: [16.18885419] loss: 30.532001678991016\n",
            "Epoch: 4662 / 5000\n",
            "w1: [25.59445331] w2: [-23.43936541] bias: [16.22556834] loss: 30.526424888569245\n",
            "Epoch: 4663 / 5000\n",
            "w1: [25.59089318] w2: [-23.43820435] bias: [16.21722616] loss: 30.5269530097335\n",
            "Epoch: 4664 / 5000\n",
            "w1: [25.59960002] w2: [-23.41353331] bias: [16.2549506] loss: 30.52718607082486\n",
            "Epoch: 4665 / 5000\n",
            "w1: [25.6018476] w2: [-23.41178188] bias: [16.25672372] loss: 30.52733748252878\n",
            "Epoch: 4666 / 5000\n",
            "w1: [25.59675173] w2: [-23.39734506] bias: [16.2611307] loss: 30.52820483433254\n",
            "Epoch: 4667 / 5000\n",
            "w1: [25.60237332] w2: [-23.39845057] bias: [16.26078421] loss: 30.528159514007452\n",
            "Epoch: 4668 / 5000\n",
            "w1: [25.59497479] w2: [-23.40161209] bias: [16.25237579] loss: 30.527531525702713\n",
            "Epoch: 4669 / 5000\n",
            "w1: [25.59724205] w2: [-23.40028396] bias: [16.25295106] loss: 30.527594771967657\n",
            "Epoch: 4670 / 5000\n",
            "w1: [25.59606452] w2: [-23.4008939] bias: [16.24818818] loss: 30.527365838959675\n",
            "Epoch: 4671 / 5000\n",
            "w1: [25.59973101] w2: [-23.40588663] bias: [16.24670178] loss: 30.52709445446632\n",
            "Epoch: 4672 / 5000\n",
            "w1: [25.60767395] w2: [-23.39678974] bias: [16.25980275] loss: 30.528201332460288\n",
            "Epoch: 4673 / 5000\n",
            "w1: [25.60068987] w2: [-23.40017677] bias: [16.2428591] loss: 30.52713425151605\n",
            "Epoch: 4674 / 5000\n",
            "w1: [25.58440753] w2: [-23.39600718] bias: [16.22376442] loss: 30.52754106907056\n",
            "Epoch: 4675 / 5000\n",
            "w1: [25.60960883] w2: [-23.39805009] bias: [16.25249636] loss: 30.52763736273644\n",
            "Epoch: 4676 / 5000\n",
            "w1: [25.62148641] w2: [-23.39681997] bias: [16.26773578] loss: 30.529170829504128\n",
            "Epoch: 4677 / 5000\n",
            "w1: [25.64109053] w2: [-23.39495469] bias: [16.29297137] loss: 30.533794209902542\n",
            "Epoch: 4678 / 5000\n",
            "w1: [25.64977643] w2: [-23.38865546] bias: [16.31502567] loss: 30.539606792725397\n",
            "Epoch: 4679 / 5000\n",
            "w1: [25.64636632] w2: [-23.38243457] bias: [16.31508199] loss: 30.53988618779007\n",
            "Epoch: 4680 / 5000\n",
            "w1: [25.63748158] w2: [-23.39160317] bias: [16.29181288] loss: 30.533617162625397\n",
            "Epoch: 4681 / 5000\n",
            "w1: [25.63392804] w2: [-23.390669] bias: [16.28421345] loss: 30.532217999896844\n",
            "Epoch: 4682 / 5000\n",
            "w1: [25.62480793] w2: [-23.38858246] bias: [16.27109726] loss: 30.530128647291896\n",
            "Epoch: 4683 / 5000\n",
            "w1: [25.62810533] w2: [-23.39228735] bias: [16.26942315] loss: 30.529811086572852\n",
            "Epoch: 4684 / 5000\n",
            "w1: [25.6281153] w2: [-23.37104529] bias: [16.29283373] loss: 30.534801960483495\n",
            "Epoch: 4685 / 5000\n",
            "w1: [25.61836473] w2: [-23.37589386] bias: [16.27442223] loss: 30.531111040483474\n",
            "Epoch: 4686 / 5000\n",
            "w1: [25.60062328] w2: [-23.38287878] bias: [16.24068532] loss: 30.527654298868\n",
            "Epoch: 4687 / 5000\n",
            "w1: [25.59930187] w2: [-23.38218586] bias: [16.24718943] loss: 30.52799401206345\n",
            "Epoch: 4688 / 5000\n",
            "w1: [25.60078271] w2: [-23.38728137] bias: [16.2418675] loss: 30.527541309430074\n",
            "Epoch: 4689 / 5000\n",
            "w1: [25.6083533] w2: [-23.37998164] bias: [16.25365347] loss: 30.52851742588707\n",
            "Epoch: 4690 / 5000\n",
            "w1: [25.61384383] w2: [-23.39005281] bias: [16.25157825] loss: 30.527938194377093\n",
            "Epoch: 4691 / 5000\n",
            "w1: [25.61508842] w2: [-23.39370523] bias: [16.24476199] loss: 30.527346447267078\n",
            "Epoch: 4692 / 5000\n",
            "w1: [25.60298245] w2: [-23.40627115] bias: [16.21427675] loss: 30.52677120301319\n",
            "Epoch: 4693 / 5000\n",
            "w1: [25.6133003] w2: [-23.41264824] bias: [16.2230674] loss: 30.52616590829287\n",
            "Epoch: 4694 / 5000\n",
            "w1: [25.64412461] w2: [-23.38582868] bias: [16.28831128] loss: 30.533844828484707\n",
            "Epoch: 4695 / 5000\n",
            "w1: [25.65125577] w2: [-23.39258688] bias: [16.28186401] loss: 30.53264655748997\n",
            "Epoch: 4696 / 5000\n",
            "w1: [25.65710105] w2: [-23.39276452] bias: [16.31029821] loss: 30.53879242127301\n",
            "Epoch: 4697 / 5000\n",
            "w1: [25.64529663] w2: [-23.39592742] bias: [16.2891737] loss: 30.533307269994815\n",
            "Epoch: 4698 / 5000\n",
            "w1: [25.64697665] w2: [-23.39664758] bias: [16.28542864] loss: 30.532706600448947\n",
            "Epoch: 4699 / 5000\n",
            "w1: [25.639458] w2: [-23.40040302] bias: [16.27015755] loss: 30.529810752477292\n",
            "Epoch: 4700 / 5000\n",
            "w1: [25.65434452] w2: [-23.39770443] bias: [16.28770623] loss: 30.53348266686333\n",
            "Epoch: 4701 / 5000\n",
            "w1: [25.65358862] w2: [-23.40202774] bias: [16.27848705] loss: 30.531550362452748\n",
            "Epoch: 4702 / 5000\n",
            "w1: [25.64372462] w2: [-23.40941803] bias: [16.25759941] loss: 30.527973823860556\n",
            "Epoch: 4703 / 5000\n",
            "w1: [25.67597111] w2: [-23.40553096] bias: [16.2991238] loss: 30.53679429035106\n",
            "Epoch: 4704 / 5000\n",
            "w1: [25.66161152] w2: [-23.41428826] bias: [16.27158914] loss: 30.530081870543007\n",
            "Epoch: 4705 / 5000\n",
            "w1: [25.64580203] w2: [-23.42766165] bias: [16.24099422] loss: 30.525819680427755\n",
            "Epoch: 4706 / 5000\n",
            "w1: [25.63895095] w2: [-23.43224265] bias: [16.22881963] loss: 30.525177484170804\n",
            "Epoch: 4707 / 5000\n",
            "w1: [25.63090137] w2: [-23.43417018] bias: [16.21734317] loss: 30.525203836461284\n",
            "Epoch: 4708 / 5000\n",
            "w1: [25.64619242] w2: [-23.4188306] bias: [16.2594372] loss: 30.52773971428848\n",
            "Epoch: 4709 / 5000\n",
            "w1: [25.63529209] w2: [-23.41659337] bias: [16.24516529] loss: 30.52647839583748\n",
            "Epoch: 4710 / 5000\n",
            "w1: [25.63103139] w2: [-23.41724208] bias: [16.23821557] loss: 30.526069485615075\n",
            "Epoch: 4711 / 5000\n",
            "w1: [25.62151686] w2: [-23.42391935] bias: [16.22593441] loss: 30.525695618323702\n",
            "Epoch: 4712 / 5000\n",
            "w1: [25.65759765] w2: [-23.40796873] bias: [16.28828102] loss: 30.53302431425775\n",
            "Epoch: 4713 / 5000\n",
            "w1: [25.65534006] w2: [-23.41412274] bias: [16.27699974] loss: 30.530595264536913\n",
            "Epoch: 4714 / 5000\n",
            "w1: [25.66650931] w2: [-23.41315817] bias: [16.29346436] loss: 30.534216843677093\n",
            "Epoch: 4715 / 5000\n",
            "w1: [25.65056092] w2: [-23.43090459] bias: [16.25770971] loss: 30.52706756379081\n",
            "Epoch: 4716 / 5000\n",
            "w1: [25.64946329] w2: [-23.43333164] bias: [16.24979855] loss: 30.526238649538808\n",
            "Epoch: 4717 / 5000\n",
            "w1: [25.65006447] w2: [-23.44090213] bias: [16.23860327] loss: 30.525212578022604\n",
            "Epoch: 4718 / 5000\n",
            "w1: [25.67036749] w2: [-23.42690595] bias: [16.27451374] loss: 30.53014537533849\n",
            "Epoch: 4719 / 5000\n",
            "w1: [25.65414165] w2: [-23.43352834] bias: [16.25127205] loss: 30.526420244913556\n",
            "Epoch: 4720 / 5000\n",
            "w1: [25.65520223] w2: [-23.43012623] bias: [16.25541985] loss: 30.5269836546557\n",
            "Epoch: 4721 / 5000\n",
            "w1: [25.66268076] w2: [-23.42356996] bias: [16.26658173] loss: 30.52885878596028\n",
            "Epoch: 4722 / 5000\n",
            "w1: [25.66373559] w2: [-23.42729741] bias: [16.26223437] loss: 30.528130673456328\n",
            "Epoch: 4723 / 5000\n",
            "w1: [25.65788864] w2: [-23.43710364] bias: [16.24585704] loss: 30.525873444120595\n",
            "Epoch: 4724 / 5000\n",
            "w1: [25.64707121] w2: [-23.43773576] bias: [16.22732825] loss: 30.5248685260323\n",
            "Epoch: 4725 / 5000\n",
            "w1: [25.64248864] w2: [-23.43404268] bias: [16.2213595] loss: 30.52491142622844\n",
            "Epoch: 4726 / 5000\n",
            "w1: [25.63494435] w2: [-23.44493774] bias: [16.20480372] loss: 30.52514657734676\n",
            "Epoch: 4727 / 5000\n",
            "w1: [25.63789003] w2: [-23.43381688] bias: [16.21590814] loss: 30.524996801601933\n",
            "Epoch: 4728 / 5000\n",
            "w1: [25.64736005] w2: [-23.42686666] bias: [16.23368692] loss: 30.525445245625896\n",
            "Epoch: 4729 / 5000\n",
            "w1: [25.63318842] w2: [-23.44463112] bias: [16.20026935] loss: 30.525408254615726\n",
            "Epoch: 4730 / 5000\n",
            "w1: [25.63876976] w2: [-23.45031993] bias: [16.19680418] loss: 30.525248101316443\n",
            "Epoch: 4731 / 5000\n",
            "w1: [25.64088871] w2: [-23.45431238] bias: [16.19183502] loss: 30.5253870597206\n",
            "Epoch: 4732 / 5000\n",
            "w1: [25.65800971] w2: [-23.44896559] bias: [16.21533139] loss: 30.52416834376337\n",
            "Epoch: 4733 / 5000\n",
            "w1: [25.66104358] w2: [-23.43892818] bias: [16.23304771] loss: 30.524975572530874\n",
            "Epoch: 4734 / 5000\n",
            "w1: [25.65546671] w2: [-23.44849595] bias: [16.21820336] loss: 30.524267639410517\n",
            "Epoch: 4735 / 5000\n",
            "w1: [25.66436576] w2: [-23.44532511] bias: [16.23892984] loss: 30.52511210032627\n",
            "Epoch: 4736 / 5000\n",
            "w1: [25.65616704] w2: [-23.44162601] bias: [16.23366113] loss: 30.524924351769357\n",
            "Epoch: 4737 / 5000\n",
            "w1: [25.6423463] w2: [-23.44127172] bias: [16.21346469] loss: 30.52473583458759\n",
            "Epoch: 4738 / 5000\n",
            "w1: [25.64742546] w2: [-23.43617265] bias: [16.23246138] loss: 30.525089442313025\n",
            "Epoch: 4739 / 5000\n",
            "w1: [25.64693694] w2: [-23.44080092] bias: [16.22519997] loss: 30.52473520007048\n",
            "Epoch: 4740 / 5000\n",
            "w1: [25.63500088] w2: [-23.44088777] bias: [16.21099752] loss: 30.52502989184875\n",
            "Epoch: 4741 / 5000\n",
            "w1: [25.6127309] w2: [-23.44120521] bias: [16.18178564] loss: 30.528096061515853\n",
            "Epoch: 4742 / 5000\n",
            "w1: [25.61478133] w2: [-23.42145972] bias: [16.20272748] loss: 30.52641715644073\n",
            "Epoch: 4743 / 5000\n",
            "w1: [25.58599837] w2: [-23.44291744] bias: [16.15308667] loss: 30.535051782817526\n",
            "Epoch: 4744 / 5000\n",
            "w1: [25.58568369] w2: [-23.44387618] bias: [16.15165559] loss: 30.53539681414798\n",
            "Epoch: 4745 / 5000\n",
            "w1: [25.57482753] w2: [-23.45785797] bias: [16.13621701] loss: 30.540910126318654\n",
            "Epoch: 4746 / 5000\n",
            "w1: [25.57174112] w2: [-23.45568648] bias: [16.12972843] loss: 30.542894100453758\n",
            "Epoch: 4747 / 5000\n",
            "w1: [25.60837173] w2: [-23.444611] bias: [16.19881558] loss: 30.526979916092003\n",
            "Epoch: 4748 / 5000\n",
            "w1: [25.61782416] w2: [-23.44135795] bias: [16.21658471] loss: 30.525604846648637\n",
            "Epoch: 4749 / 5000\n",
            "w1: [25.6180623] w2: [-23.43956806] bias: [16.21469173] loss: 30.525664132475264\n",
            "Epoch: 4750 / 5000\n",
            "w1: [25.61344975] w2: [-23.43571424] bias: [16.215114] loss: 30.525900809579404\n",
            "Epoch: 4751 / 5000\n",
            "w1: [25.63267743] w2: [-23.43426886] bias: [16.2548734] loss: 30.52641387024968\n",
            "Epoch: 4752 / 5000\n",
            "w1: [25.63248298] w2: [-23.43184571] bias: [16.25563255] loss: 30.52656703044222\n",
            "Epoch: 4753 / 5000\n",
            "w1: [25.64603075] w2: [-23.43121295] bias: [16.27100569] loss: 30.52837010884879\n",
            "Epoch: 4754 / 5000\n",
            "w1: [25.64327371] w2: [-23.43631483] bias: [16.26415823] loss: 30.527278707612947\n",
            "Epoch: 4755 / 5000\n",
            "w1: [25.66233953] w2: [-23.43029945] bias: [16.30225752] loss: 30.534298336192254\n",
            "Epoch: 4756 / 5000\n",
            "w1: [25.66870249] w2: [-23.43224413] bias: [16.3147711] loss: 30.537355397431707\n",
            "Epoch: 4757 / 5000\n",
            "w1: [25.67701755] w2: [-23.42944991] bias: [16.32706896] loss: 30.541495951120268\n",
            "Epoch: 4758 / 5000\n",
            "w1: [25.6751996] w2: [-23.42861241] bias: [16.32495195] loss: 30.54082495127458\n",
            "Epoch: 4759 / 5000\n",
            "w1: [25.68941621] w2: [-23.41314144] bias: [16.35239307] loss: 30.552519867644413\n",
            "Epoch: 4760 / 5000\n",
            "w1: [25.68770061] w2: [-23.39934389] bias: [16.35779446] loss: 30.555843452591514\n",
            "Epoch: 4761 / 5000\n",
            "w1: [25.68005173] w2: [-23.3898115] bias: [16.35886536] loss: 30.556243742595786\n",
            "Epoch: 4762 / 5000\n",
            "w1: [25.67704928] w2: [-23.3887109] bias: [16.35174283] loss: 30.5534533124762\n",
            "Epoch: 4763 / 5000\n",
            "w1: [25.66699471] w2: [-23.39615468] bias: [16.32726529] loss: 30.543783001296255\n",
            "Epoch: 4764 / 5000\n",
            "w1: [25.67744334] w2: [-23.40276665] bias: [16.32946501] loss: 30.54492953543864\n",
            "Epoch: 4765 / 5000\n",
            "w1: [25.66831814] w2: [-23.3957694] bias: [16.32444522] loss: 30.543202516288368\n",
            "Epoch: 4766 / 5000\n",
            "w1: [25.68149156] w2: [-23.40230327] bias: [16.33975355] loss: 30.548568604655088\n",
            "Epoch: 4767 / 5000\n",
            "w1: [25.68498167] w2: [-23.39231068] bias: [16.35070476] loss: 30.55383344161449\n",
            "Epoch: 4768 / 5000\n",
            "w1: [25.65204462] w2: [-23.4105008] bias: [16.29809176] loss: 30.534282064664144\n",
            "Epoch: 4769 / 5000\n",
            "w1: [25.65084892] w2: [-23.42098292] bias: [16.28347916] loss: 30.530909350944388\n",
            "Epoch: 4770 / 5000\n",
            "w1: [25.66087956] w2: [-23.4259552] bias: [16.29096965] loss: 30.53239427551976\n",
            "Epoch: 4771 / 5000\n",
            "w1: [25.66404384] w2: [-23.42539856] bias: [16.30411068] loss: 30.53519997563806\n",
            "Epoch: 4772 / 5000\n",
            "w1: [25.65179357] w2: [-23.43342138] bias: [16.28313414] loss: 30.53009819652464\n",
            "Epoch: 4773 / 5000\n",
            "w1: [25.66143795] w2: [-23.43620042] bias: [16.29045426] loss: 30.53161130880263\n",
            "Epoch: 4774 / 5000\n",
            "w1: [25.66849494] w2: [-23.43175744] bias: [16.30213756] loss: 30.534632457204605\n",
            "Epoch: 4775 / 5000\n",
            "w1: [25.66270595] w2: [-23.43180064] bias: [16.29352424] loss: 30.532547202685002\n",
            "Epoch: 4776 / 5000\n",
            "w1: [25.65426103] w2: [-23.44316915] bias: [16.2696469] loss: 30.527834850049466\n",
            "Epoch: 4777 / 5000\n",
            "w1: [25.64908126] w2: [-23.45014526] bias: [16.25890905] loss: 30.526267118034966\n",
            "Epoch: 4778 / 5000\n",
            "w1: [25.65440496] w2: [-23.45548032] bias: [16.26147536] loss: 30.52636461206643\n",
            "Epoch: 4779 / 5000\n",
            "w1: [25.63903348] w2: [-23.46202291] bias: [16.2329228] loss: 30.524535744139932\n",
            "Epoch: 4780 / 5000\n",
            "w1: [25.6415101] w2: [-23.46179895] bias: [16.24260696] loss: 30.524782569007375\n",
            "Epoch: 4781 / 5000\n",
            "w1: [25.62830636] w2: [-23.43922827] bias: [16.24450699] loss: 30.52564032086872\n",
            "Epoch: 4782 / 5000\n",
            "w1: [25.62869113] w2: [-23.45029557] bias: [16.23648841] loss: 30.52506963703038\n",
            "Epoch: 4783 / 5000\n",
            "w1: [25.62132224] w2: [-23.4486321] bias: [16.22663351] loss: 30.52521662684476\n",
            "Epoch: 4784 / 5000\n",
            "w1: [25.63402559] w2: [-23.44600335] bias: [16.24252281] loss: 30.525303450236994\n",
            "Epoch: 4785 / 5000\n",
            "w1: [25.63181586] w2: [-23.44411271] bias: [16.23857617] loss: 30.52523743080738\n",
            "Epoch: 4786 / 5000\n",
            "w1: [25.62472177] w2: [-23.45391472] bias: [16.21829364] loss: 30.525133993991005\n",
            "Epoch: 4787 / 5000\n",
            "w1: [25.62245214] w2: [-23.45655198] bias: [16.21021172] loss: 30.52547581799701\n",
            "Epoch: 4788 / 5000\n",
            "w1: [25.63721756] w2: [-23.45782973] bias: [16.22225556] loss: 30.524586190152267\n",
            "Epoch: 4789 / 5000\n",
            "w1: [25.6348614] w2: [-23.46988111] bias: [16.210478] loss: 30.524785266812774\n",
            "Epoch: 4790 / 5000\n",
            "w1: [25.63072135] w2: [-23.47702998] bias: [16.19794612] loss: 30.52568898878571\n",
            "Epoch: 4791 / 5000\n",
            "w1: [25.61458915] w2: [-23.49242174] bias: [16.164121] loss: 30.531402876219772\n",
            "Epoch: 4792 / 5000\n",
            "w1: [25.61577029] w2: [-23.4867215] bias: [16.16806953] loss: 30.53046525921154\n",
            "Epoch: 4793 / 5000\n",
            "w1: [25.61147208] w2: [-23.49492042] bias: [16.15195786] loss: 30.53405159676773\n",
            "Epoch: 4794 / 5000\n",
            "w1: [25.60697707] w2: [-23.48886324] bias: [16.14370306] loss: 30.536045300341314\n",
            "Epoch: 4795 / 5000\n",
            "w1: [25.61781054] w2: [-23.48318077] bias: [16.17215214] loss: 30.529559431578402\n",
            "Epoch: 4796 / 5000\n",
            "w1: [25.62738705] w2: [-23.48537886] bias: [16.1857713] loss: 30.527078840887963\n",
            "Epoch: 4797 / 5000\n",
            "w1: [25.61765232] w2: [-23.48832913] bias: [16.16781254] loss: 30.53035048847825\n",
            "Epoch: 4798 / 5000\n",
            "w1: [25.59741377] w2: [-23.50186198] bias: [16.12854674] loss: 30.541771059537478\n",
            "Epoch: 4799 / 5000\n",
            "w1: [25.59115958] w2: [-23.50416983] bias: [16.11727282] loss: 30.546091700710793\n",
            "Epoch: 4800 / 5000\n",
            "w1: [25.58902107] w2: [-23.50835357] bias: [16.10658041] loss: 30.55004329273128\n",
            "Epoch: 4801 / 5000\n",
            "w1: [25.59092515] w2: [-23.50793088] bias: [16.11345546] loss: 30.547536170783467\n",
            "Epoch: 4802 / 5000\n",
            "w1: [25.5985062] w2: [-23.49172351] bias: [16.15153368] loss: 30.535714233255607\n",
            "Epoch: 4803 / 5000\n",
            "w1: [25.58380105] w2: [-23.50082487] bias: [16.12790221] loss: 30.54416080730106\n",
            "Epoch: 4804 / 5000\n",
            "w1: [25.59641687] w2: [-23.48902666] bias: [16.15530333] loss: 30.53511173533719\n",
            "Epoch: 4805 / 5000\n",
            "w1: [25.59669935] w2: [-23.49326387] bias: [16.15085633] loss: 30.536175388664674\n",
            "Epoch: 4806 / 5000\n",
            "w1: [25.58962388] w2: [-23.50112575] bias: [16.13491499] loss: 30.541359387053344\n",
            "Epoch: 4807 / 5000\n",
            "w1: [25.57669123] w2: [-23.50497768] bias: [16.10985306] loss: 30.551133219300624\n",
            "Epoch: 4808 / 5000\n",
            "w1: [25.56483264] w2: [-23.50758641] bias: [16.09075121] loss: 30.560460795556597\n",
            "Epoch: 4809 / 5000\n",
            "w1: [25.56910295] w2: [-23.50917839] bias: [16.11451367] loss: 30.5514727117897\n",
            "Epoch: 4810 / 5000\n",
            "w1: [25.57219124] w2: [-23.50518097] bias: [16.1178002] loss: 30.549522270319258\n",
            "Epoch: 4811 / 5000\n",
            "w1: [25.59122672] w2: [-23.50665328] bias: [16.13416839] loss: 30.54163249947787\n",
            "Epoch: 4812 / 5000\n",
            "w1: [25.58446192] w2: [-23.5092695] bias: [16.11829436] loss: 30.547385397065636\n",
            "Epoch: 4813 / 5000\n",
            "w1: [25.57700628] w2: [-23.51263399] bias: [16.10988343] loss: 30.55168840834461\n",
            "Epoch: 4814 / 5000\n",
            "w1: [25.5746414] w2: [-23.51991898] bias: [16.09799496] loss: 30.5568484784253\n",
            "Epoch: 4815 / 5000\n",
            "w1: [25.60095699] w2: [-23.4945027] bias: [16.14618424] loss: 30.536633617330814\n",
            "Epoch: 4816 / 5000\n",
            "w1: [25.60179731] w2: [-23.49887939] bias: [16.14115266] loss: 30.537851560083205\n",
            "Epoch: 4817 / 5000\n",
            "w1: [25.5995823] w2: [-23.51059822] bias: [16.13560328] loss: 30.540174483155354\n",
            "Epoch: 4818 / 5000\n",
            "w1: [25.62310451] w2: [-23.50214831] bias: [16.16944461] loss: 30.529946702329248\n",
            "Epoch: 4819 / 5000\n",
            "w1: [25.64398462] w2: [-23.4990256] bias: [16.19462489] loss: 30.525219749351574\n",
            "Epoch: 4820 / 5000\n",
            "w1: [25.65296178] w2: [-23.49201648] bias: [16.21691079] loss: 30.523697994401154\n",
            "Epoch: 4821 / 5000\n",
            "w1: [25.6604275] w2: [-23.49617753] bias: [16.22366052] loss: 30.523358326554884\n",
            "Epoch: 4822 / 5000\n",
            "w1: [25.66104188] w2: [-23.49481091] bias: [16.22567116] loss: 30.523369379699666\n",
            "Epoch: 4823 / 5000\n",
            "w1: [25.66399137] w2: [-23.48835212] bias: [16.2360151] loss: 30.523653855461415\n",
            "Epoch: 4824 / 5000\n",
            "w1: [25.67088192] w2: [-23.4891808] bias: [16.24256252] loss: 30.523890829456928\n",
            "Epoch: 4825 / 5000\n",
            "w1: [25.66114336] w2: [-23.49835441] bias: [16.2237945] loss: 30.523310377005373\n",
            "Epoch: 4826 / 5000\n",
            "w1: [25.67054206] w2: [-23.49404865] bias: [16.23730747] loss: 30.523513146195064\n",
            "Epoch: 4827 / 5000\n",
            "w1: [25.6834789] w2: [-23.49398517] bias: [16.24588537] loss: 30.524021893594135\n",
            "Epoch: 4828 / 5000\n",
            "w1: [25.67849276] w2: [-23.49607681] bias: [16.22952241] loss: 30.52312883443664\n",
            "Epoch: 4829 / 5000\n",
            "w1: [25.67935089] w2: [-23.49422969] bias: [16.2425226] loss: 30.523763302927474\n",
            "Epoch: 4830 / 5000\n",
            "w1: [25.67368397] w2: [-23.50060266] bias: [16.22375857] loss: 30.522988291566385\n",
            "Epoch: 4831 / 5000\n",
            "w1: [25.66249085] w2: [-23.50139956] bias: [16.2098181] loss: 30.523432857194077\n",
            "Epoch: 4832 / 5000\n",
            "w1: [25.66122278] w2: [-23.49349163] bias: [16.21184691] loss: 30.523479630850463\n",
            "Epoch: 4833 / 5000\n",
            "w1: [25.66467062] w2: [-23.49288266] bias: [16.21409394] loss: 30.523326913211154\n",
            "Epoch: 4834 / 5000\n",
            "w1: [25.65321321] w2: [-23.50312843] bias: [16.18821601] loss: 30.525141406693407\n",
            "Epoch: 4835 / 5000\n",
            "w1: [25.65489107] w2: [-23.49699863] bias: [16.19473054] loss: 30.524505401398805\n",
            "Epoch: 4836 / 5000\n",
            "w1: [25.65324057] w2: [-23.50448508] bias: [16.18224221] loss: 30.525686146499506\n",
            "Epoch: 4837 / 5000\n",
            "w1: [25.65047263] w2: [-23.50891829] bias: [16.17810887] loss: 30.5264058732463\n",
            "Epoch: 4838 / 5000\n",
            "w1: [25.64934172] w2: [-23.51637645] bias: [16.16633257] loss: 30.52814397165878\n",
            "Epoch: 4839 / 5000\n",
            "w1: [25.64186159] w2: [-23.52495279] bias: [16.14556043] loss: 30.53273920140017\n",
            "Epoch: 4840 / 5000\n",
            "w1: [25.64098976] w2: [-23.52270553] bias: [16.14124902] loss: 30.533592145090562\n",
            "Epoch: 4841 / 5000\n",
            "w1: [25.63679571] w2: [-23.51779313] bias: [16.14252017] loss: 30.53365091545669\n",
            "Epoch: 4842 / 5000\n",
            "w1: [25.62764306] w2: [-23.52743632] bias: [16.11614775] loss: 30.54172868078721\n",
            "Epoch: 4843 / 5000\n",
            "w1: [25.63773926] w2: [-23.52369607] bias: [16.14485297] loss: 30.533346145834383\n",
            "Epoch: 4844 / 5000\n",
            "w1: [25.62791859] w2: [-23.53772777] bias: [16.1203449] loss: 30.541271873676248\n",
            "Epoch: 4845 / 5000\n",
            "w1: [25.6513816] w2: [-23.51969206] bias: [16.17520173] loss: 30.526898893461937\n",
            "Epoch: 4846 / 5000\n",
            "w1: [25.64037524] w2: [-23.5277437] bias: [16.15294655] loss: 30.531669149598468\n",
            "Epoch: 4847 / 5000\n",
            "w1: [25.6373839] w2: [-23.52900608] bias: [16.15069397] loss: 30.532509222082137\n",
            "Epoch: 4848 / 5000\n",
            "w1: [25.65148244] w2: [-23.5209153] bias: [16.17167134] loss: 30.527358127531567\n",
            "Epoch: 4849 / 5000\n",
            "w1: [25.65511401] w2: [-23.51502218] bias: [16.18248267] loss: 30.52569420980384\n",
            "Epoch: 4850 / 5000\n",
            "w1: [25.65130444] w2: [-23.50466325] bias: [16.18080521] loss: 30.525978647042223\n",
            "Epoch: 4851 / 5000\n",
            "w1: [25.65597356] w2: [-23.50824455] bias: [16.18046721] loss: 30.525708520248962\n",
            "Epoch: 4852 / 5000\n",
            "w1: [25.64877653] w2: [-23.51205869] bias: [16.17995018] loss: 30.526410126243327\n",
            "Epoch: 4853 / 5000\n",
            "w1: [25.6539681] w2: [-23.51040186] bias: [16.19211043] loss: 30.52486088429833\n",
            "Epoch: 4854 / 5000\n",
            "w1: [25.65983013] w2: [-23.50335334] bias: [16.20229752] loss: 30.52383513666631\n",
            "Epoch: 4855 / 5000\n",
            "w1: [25.67222796] w2: [-23.5096676] bias: [16.22081345] loss: 30.52287933593706\n",
            "Epoch: 4856 / 5000\n",
            "w1: [25.68210082] w2: [-23.51316584] bias: [16.22908672] loss: 30.52272840785252\n",
            "Epoch: 4857 / 5000\n",
            "w1: [25.68206208] w2: [-23.51867507] bias: [16.22257242] loss: 30.522540234975462\n",
            "Epoch: 4858 / 5000\n",
            "w1: [25.69837647] w2: [-23.52264578] bias: [16.23234169] loss: 30.522514027202142\n",
            "Epoch: 4859 / 5000\n",
            "w1: [25.70291895] w2: [-23.53088738] bias: [16.23939129] loss: 30.52266099477887\n",
            "Epoch: 4860 / 5000\n",
            "w1: [25.71225779] w2: [-23.53999255] bias: [16.24033329] loss: 30.522540363710185\n",
            "Epoch: 4861 / 5000\n",
            "w1: [25.73464247] w2: [-23.533062] bias: [16.27223614] loss: 30.526981797544597\n",
            "Epoch: 4862 / 5000\n",
            "w1: [25.73745031] w2: [-23.52655976] bias: [16.2807869] loss: 30.52894691051763\n",
            "Epoch: 4863 / 5000\n",
            "w1: [25.73844551] w2: [-23.52935056] bias: [16.28084273] loss: 30.52885389371224\n",
            "Epoch: 4864 / 5000\n",
            "w1: [25.74060392] w2: [-23.53323709] bias: [16.28635695] loss: 30.52976818831066\n",
            "Epoch: 4865 / 5000\n",
            "w1: [25.73893834] w2: [-23.54183424] bias: [16.27287371] loss: 30.526853870635346\n",
            "Epoch: 4866 / 5000\n",
            "w1: [25.74792975] w2: [-23.54605827] bias: [16.269645] loss: 30.52665578980505\n",
            "Epoch: 4867 / 5000\n",
            "w1: [25.750162] w2: [-23.5448217] bias: [16.29244805] loss: 30.530951110555414\n",
            "Epoch: 4868 / 5000\n",
            "w1: [25.75531162] w2: [-23.53359645] bias: [16.30120359] loss: 30.534139374406116\n",
            "Epoch: 4869 / 5000\n",
            "w1: [25.74041458] w2: [-23.54929534] bias: [16.27201809] loss: 30.52641663795125\n",
            "Epoch: 4870 / 5000\n",
            "w1: [25.72326837] w2: [-23.5551707] bias: [16.24557799] loss: 30.522611139146044\n",
            "Epoch: 4871 / 5000\n",
            "w1: [25.72605533] w2: [-23.57244265] bias: [16.23557566] loss: 30.52161095449244\n",
            "Epoch: 4872 / 5000\n",
            "w1: [25.7279646] w2: [-23.57640471] bias: [16.23026335] loss: 30.521321198370018\n",
            "Epoch: 4873 / 5000\n",
            "w1: [25.71749573] w2: [-23.58732714] bias: [16.20744316] loss: 30.521358951949704\n",
            "Epoch: 4874 / 5000\n",
            "w1: [25.71869105] w2: [-23.58128342] bias: [16.21422712] loss: 30.521194898645057\n",
            "Epoch: 4875 / 5000\n",
            "w1: [25.71080902] w2: [-23.59008663] bias: [16.19908831] loss: 30.52199745118562\n",
            "Epoch: 4876 / 5000\n",
            "w1: [25.70635149] w2: [-23.59326381] bias: [16.19767871] loss: 30.522349225834965\n",
            "Epoch: 4877 / 5000\n",
            "w1: [25.68943634] w2: [-23.60006999] bias: [16.16912236] loss: 30.52669089487756\n",
            "Epoch: 4878 / 5000\n",
            "w1: [25.70220087] w2: [-23.59966898] bias: [16.18916328] loss: 30.523353662319515\n",
            "Epoch: 4879 / 5000\n",
            "w1: [25.71027636] w2: [-23.60256176] bias: [16.19865653] loss: 30.52221434896451\n",
            "Epoch: 4880 / 5000\n",
            "w1: [25.7277867] w2: [-23.59011695] bias: [16.22917473] loss: 30.521101700123697\n",
            "Epoch: 4881 / 5000\n",
            "w1: [25.73301035] w2: [-23.58929797] bias: [16.23355413] loss: 30.521234967524585\n",
            "Epoch: 4882 / 5000\n",
            "w1: [25.713503] w2: [-23.59807203] bias: [16.21047101] loss: 30.52146823313374\n",
            "Epoch: 4883 / 5000\n",
            "w1: [25.69837223] w2: [-23.59975308] bias: [16.18730351] loss: 30.523790412900393\n",
            "Epoch: 4884 / 5000\n",
            "w1: [25.6913261] w2: [-23.6072659] bias: [16.16906609] loss: 30.526796123315314\n",
            "Epoch: 4885 / 5000\n",
            "w1: [25.71254999] w2: [-23.6038828] bias: [16.19485275] loss: 30.52235625244377\n",
            "Epoch: 4886 / 5000\n",
            "w1: [25.69946237] w2: [-23.5978476] bias: [16.18303842] loss: 30.524080865589703\n",
            "Epoch: 4887 / 5000\n",
            "w1: [25.6932716] w2: [-23.60194304] bias: [16.17459629] loss: 30.525672620294813\n",
            "Epoch: 4888 / 5000\n",
            "w1: [25.68680149] w2: [-23.60844907] bias: [16.16195887] loss: 30.52839569503042\n",
            "Epoch: 4889 / 5000\n",
            "w1: [25.70294756] w2: [-23.6048912] bias: [16.1808208] loss: 30.52423955556877\n",
            "Epoch: 4890 / 5000\n",
            "w1: [25.72272147] w2: [-23.60572913] bias: [16.20017031] loss: 30.521558155852414\n",
            "Epoch: 4891 / 5000\n",
            "w1: [25.7236069] w2: [-23.59481693] bias: [16.21441734] loss: 30.521045254623083\n",
            "Epoch: 4892 / 5000\n",
            "w1: [25.71961242] w2: [-23.58747085] bias: [16.21522017] loss: 30.521149961519058\n",
            "Epoch: 4893 / 5000\n",
            "w1: [25.72243651] w2: [-23.59219577] bias: [16.21079084] loss: 30.521131310838804\n",
            "Epoch: 4894 / 5000\n",
            "w1: [25.72883021] w2: [-23.57831673] bias: [16.22714547] loss: 30.52118745030311\n",
            "Epoch: 4895 / 5000\n",
            "w1: [25.73817607] w2: [-23.57376768] bias: [16.24145862] loss: 30.52203738682025\n",
            "Epoch: 4896 / 5000\n",
            "w1: [25.72584205] w2: [-23.57868103] bias: [16.21560586] loss: 30.52103594798592\n",
            "Epoch: 4897 / 5000\n",
            "w1: [25.71650447] w2: [-23.57916229] bias: [16.20628551] loss: 30.52139874126251\n",
            "Epoch: 4898 / 5000\n",
            "w1: [25.72579777] w2: [-23.58002334] bias: [16.21245263] loss: 30.521032587849664\n",
            "Epoch: 4899 / 5000\n",
            "w1: [25.73909035] w2: [-23.56174907] bias: [16.24911099] loss: 30.523048274008705\n",
            "Epoch: 4900 / 5000\n",
            "w1: [25.73675904] w2: [-23.55864222] bias: [16.24549868] loss: 30.52276627114271\n",
            "Epoch: 4901 / 5000\n",
            "w1: [25.71371435] w2: [-23.57122315] bias: [16.19879127] loss: 30.521715110808614\n",
            "Epoch: 4902 / 5000\n",
            "w1: [25.72680205] w2: [-23.55972591] bias: [16.22721055] loss: 30.521491373389342\n",
            "Epoch: 4903 / 5000\n",
            "w1: [25.71388216] w2: [-23.56472166] bias: [16.20419082] loss: 30.521517345363907\n",
            "Epoch: 4904 / 5000\n",
            "w1: [25.71308816] w2: [-23.56577889] bias: [16.20048897] loss: 30.521654193634724\n",
            "Epoch: 4905 / 5000\n",
            "w1: [25.69720013] w2: [-23.57388589] bias: [16.17867858] loss: 30.52408825592398\n",
            "Epoch: 4906 / 5000\n",
            "w1: [25.70321657] w2: [-23.57520516] bias: [16.19302924] loss: 30.522563715213504\n",
            "Epoch: 4907 / 5000\n",
            "w1: [25.69341023] w2: [-23.5721308] bias: [16.18055053] loss: 30.52414447876639\n",
            "Epoch: 4908 / 5000\n",
            "w1: [25.735946] w2: [-23.56138138] bias: [16.24934856] loss: 30.522998609822558\n",
            "Epoch: 4909 / 5000\n",
            "w1: [25.75813924] w2: [-23.55581453] bias: [16.28010832] loss: 30.52851859632678\n",
            "Epoch: 4910 / 5000\n",
            "w1: [25.75018297] w2: [-23.55706117] bias: [16.27921912] loss: 30.527737381687626\n",
            "Epoch: 4911 / 5000\n",
            "w1: [25.76749745] w2: [-23.54799115] bias: [16.30442556] loss: 30.53502674928106\n",
            "Epoch: 4912 / 5000\n",
            "w1: [25.77957469] w2: [-23.55457562] bias: [16.30509644] loss: 30.53597648527737\n",
            "Epoch: 4913 / 5000\n",
            "w1: [25.76927753] w2: [-23.55862785] bias: [16.28550904] loss: 30.530239454646708\n",
            "Epoch: 4914 / 5000\n",
            "w1: [25.77222544] w2: [-23.5597457] bias: [16.28645396] loss: 30.530607819543018\n",
            "Epoch: 4915 / 5000\n",
            "w1: [25.77492895] w2: [-23.55970403] bias: [16.28789965] loss: 30.531147846106776\n",
            "Epoch: 4916 / 5000\n",
            "w1: [25.77658502] w2: [-23.5641166] bias: [16.28298295] loss: 30.529991642350513\n",
            "Epoch: 4917 / 5000\n",
            "w1: [25.77927549] w2: [-23.55183021] bias: [16.29571168] loss: 30.53387165906751\n",
            "Epoch: 4918 / 5000\n",
            "w1: [25.79346647] w2: [-23.55846273] bias: [16.31401547] loss: 30.53969309526223\n",
            "Epoch: 4919 / 5000\n",
            "w1: [25.79512097] w2: [-23.55309486] bias: [16.31577978] loss: 30.540901754645546\n",
            "Epoch: 4920 / 5000\n",
            "w1: [25.79903257] w2: [-23.55707834] bias: [16.32714968] loss: 30.54451044407447\n",
            "Epoch: 4921 / 5000\n",
            "w1: [25.79590906] w2: [-23.55679177] bias: [16.31976566] loss: 30.541836103111486\n",
            "Epoch: 4922 / 5000\n",
            "w1: [25.80297974] w2: [-23.53727228] bias: [16.35034417] loss: 30.5553540840035\n",
            "Epoch: 4923 / 5000\n",
            "w1: [25.80908739] w2: [-23.53001259] bias: [16.3585259] loss: 30.56058068739063\n",
            "Epoch: 4924 / 5000\n",
            "w1: [25.82167994] w2: [-23.52175319] bias: [16.37976174] loss: 30.57356847089249\n",
            "Epoch: 4925 / 5000\n",
            "w1: [25.8275294] w2: [-23.52191951] bias: [16.3825374] loss: 30.57617566979324\n",
            "Epoch: 4926 / 5000\n",
            "w1: [25.81600469] w2: [-23.51974211] bias: [16.36784574] loss: 30.567253100631998\n",
            "Epoch: 4927 / 5000\n",
            "w1: [25.82944281] w2: [-23.52001129] bias: [16.3869737] loss: 30.57905354451852\n",
            "Epoch: 4928 / 5000\n",
            "w1: [25.82209717] w2: [-23.53166187] bias: [16.36749863] loss: 30.566729594826423\n",
            "Epoch: 4929 / 5000\n",
            "w1: [25.82124726] w2: [-23.52866537] bias: [16.36538421] loss: 30.566044703417102\n",
            "Epoch: 4930 / 5000\n",
            "w1: [25.80694387] w2: [-23.53265534] bias: [16.35386176] loss: 30.55798659593915\n",
            "Epoch: 4931 / 5000\n",
            "w1: [25.81827082] w2: [-23.51667041] bias: [16.38066379] loss: 30.57397474335404\n",
            "Epoch: 4932 / 5000\n",
            "w1: [25.81739008] w2: [-23.51628362] bias: [16.37894296] loss: 30.573035654831337\n",
            "Epoch: 4933 / 5000\n",
            "w1: [25.81180297] w2: [-23.51915725] bias: [16.36162488] loss: 30.563809373015804\n",
            "Epoch: 4934 / 5000\n",
            "w1: [25.79398431] w2: [-23.53435679] bias: [16.32158277] loss: 30.544302742476695\n",
            "Epoch: 4935 / 5000\n",
            "w1: [25.79380814] w2: [-23.53414438] bias: [16.31907959] loss: 30.5435223738342\n",
            "Epoch: 4936 / 5000\n",
            "w1: [25.7904722] w2: [-23.5228719] bias: [16.32450863] loss: 30.54589648278225\n",
            "Epoch: 4937 / 5000\n",
            "w1: [25.80533648] w2: [-23.50238216] bias: [16.37531624] loss: 30.570770588997785\n",
            "Epoch: 4938 / 5000\n",
            "w1: [25.79648833] w2: [-23.50772875] bias: [16.35658965] loss: 30.560273192711527\n",
            "Epoch: 4939 / 5000\n",
            "w1: [25.80131373] w2: [-23.50116357] bias: [16.37405966] loss: 30.569525975759873\n",
            "Epoch: 4940 / 5000\n",
            "w1: [25.790322] w2: [-23.51508972] bias: [16.34971756] loss: 30.555556343903532\n",
            "Epoch: 4941 / 5000\n",
            "w1: [25.7787414] w2: [-23.52010345] bias: [16.33063708] loss: 30.54643754858645\n",
            "Epoch: 4942 / 5000\n",
            "w1: [25.77733328] w2: [-23.52528267] bias: [16.31888374] loss: 30.54208035664316\n",
            "Epoch: 4943 / 5000\n",
            "w1: [25.77305185] w2: [-23.5323935] bias: [16.3035826] loss: 30.53669388512883\n",
            "Epoch: 4944 / 5000\n",
            "w1: [25.77483235] w2: [-23.5401476] bias: [16.29536174] loss: 30.534231830900765\n",
            "Epoch: 4945 / 5000\n",
            "w1: [25.78061028] w2: [-23.53157001] bias: [16.3025342] loss: 30.537354553089553\n",
            "Epoch: 4946 / 5000\n",
            "w1: [25.78067114] w2: [-23.53254442] bias: [16.30101071] loss: 30.536881441171882\n",
            "Epoch: 4947 / 5000\n",
            "w1: [25.78167897] w2: [-23.52606745] bias: [16.31739784] loss: 30.54214360743057\n",
            "Epoch: 4948 / 5000\n",
            "w1: [25.7735967] w2: [-23.53209638] bias: [16.30053382] loss: 30.536006407446852\n",
            "Epoch: 4949 / 5000\n",
            "w1: [25.77049346] w2: [-23.53423717] bias: [16.29408241] loss: 30.533948103880338\n",
            "Epoch: 4950 / 5000\n",
            "w1: [25.76450539] w2: [-23.53198348] bias: [16.28758702] loss: 30.53208631740956\n",
            "Epoch: 4951 / 5000\n",
            "w1: [25.77024321] w2: [-23.52876291] bias: [16.29684229] loss: 30.535008953151564\n",
            "Epoch: 4952 / 5000\n",
            "w1: [25.77921335] w2: [-23.51244914] bias: [16.3254295] loss: 30.545636533378044\n",
            "Epoch: 4953 / 5000\n",
            "w1: [25.77764826] w2: [-23.51128897] bias: [16.32166753] loss: 30.544352219667612\n",
            "Epoch: 4954 / 5000\n",
            "w1: [25.78247682] w2: [-23.51066877] bias: [16.3280961] loss: 30.54716599611329\n",
            "Epoch: 4955 / 5000\n",
            "w1: [25.77169141] w2: [-23.51669367] bias: [16.30854464] loss: 30.53922331381979\n",
            "Epoch: 4956 / 5000\n",
            "w1: [25.7900266] w2: [-23.50431076] bias: [16.33963742] loss: 30.553066504180602\n",
            "Epoch: 4957 / 5000\n",
            "w1: [25.79119692] w2: [-23.50795747] bias: [16.33413589] loss: 30.550873079740057\n",
            "Epoch: 4958 / 5000\n",
            "w1: [25.79912445] w2: [-23.48998579] bias: [16.35939863] loss: 30.564288740592954\n",
            "Epoch: 4959 / 5000\n",
            "w1: [25.80381885] w2: [-23.49686301] bias: [16.35490446] loss: 30.562411234666772\n",
            "Epoch: 4960 / 5000\n",
            "w1: [25.79090122] w2: [-23.49660664] bias: [16.33580935] loss: 30.552735694473945\n",
            "Epoch: 4961 / 5000\n",
            "w1: [25.80029696] w2: [-23.48552025] bias: [16.35368604] loss: 30.562740754498314\n",
            "Epoch: 4962 / 5000\n",
            "w1: [25.7786727] w2: [-23.49837992] bias: [16.31846131] loss: 30.544823510222688\n",
            "Epoch: 4963 / 5000\n",
            "w1: [25.78673847] w2: [-23.49063276] bias: [16.33394304] loss: 30.552080993105395\n",
            "Epoch: 4964 / 5000\n",
            "w1: [25.79033836] w2: [-23.48948642] bias: [16.33141648] loss: 30.551904804744392\n",
            "Epoch: 4965 / 5000\n",
            "w1: [25.79772331] w2: [-23.48104824] bias: [16.34688599] loss: 30.56008107156817\n",
            "Epoch: 4966 / 5000\n",
            "w1: [25.78624587] w2: [-23.48046751] bias: [16.33579649] loss: 30.553876848010958\n",
            "Epoch: 4967 / 5000\n",
            "w1: [25.78988205] w2: [-23.47269663] bias: [16.35219999] loss: 30.561851922906385\n",
            "Epoch: 4968 / 5000\n",
            "w1: [25.75935158] w2: [-23.48376583] bias: [16.30635297] loss: 30.540176321829456\n",
            "Epoch: 4969 / 5000\n",
            "w1: [25.75014539] w2: [-23.4878391] bias: [16.29049391] loss: 30.534769856265136\n",
            "Epoch: 4970 / 5000\n",
            "w1: [25.75939628] w2: [-23.48456406] bias: [16.30325148] loss: 30.539259237197207\n",
            "Epoch: 4971 / 5000\n",
            "w1: [25.74893169] w2: [-23.49082393] bias: [16.28459713] loss: 30.533090475384384\n",
            "Epoch: 4972 / 5000\n",
            "w1: [25.74685644] w2: [-23.48684156] bias: [16.27730388] loss: 30.531670680169686\n",
            "Epoch: 4973 / 5000\n",
            "w1: [25.75224135] w2: [-23.49199855] bias: [16.28016082] loss: 30.532341676706544\n",
            "Epoch: 4974 / 5000\n",
            "w1: [25.75280029] w2: [-23.49485025] bias: [16.28085369] loss: 30.532324934328887\n",
            "Epoch: 4975 / 5000\n",
            "w1: [25.76384837] w2: [-23.49907569] bias: [16.29147376] loss: 30.53546251146583\n",
            "Epoch: 4976 / 5000\n",
            "w1: [25.75586331] w2: [-23.49741206] bias: [16.2996983] loss: 30.536787691038008\n",
            "Epoch: 4977 / 5000\n",
            "w1: [25.75441872] w2: [-23.497218] bias: [16.29366807] loss: 30.535176821304933\n",
            "Epoch: 4978 / 5000\n",
            "w1: [25.76157067] w2: [-23.48479063] bias: [16.31169374] loss: 30.541864121745856\n",
            "Epoch: 4979 / 5000\n",
            "w1: [25.75925102] w2: [-23.49751774] bias: [16.29175759] loss: 30.53518675827971\n",
            "Epoch: 4980 / 5000\n",
            "w1: [25.76111423] w2: [-23.49454645] bias: [16.29463305] loss: 30.5363306967054\n",
            "Epoch: 4981 / 5000\n",
            "w1: [25.75819162] w2: [-23.49378599] bias: [16.28648664] loss: 30.534147909239376\n",
            "Epoch: 4982 / 5000\n",
            "w1: [25.76422007] w2: [-23.49192735] bias: [16.29752453] loss: 30.537632288884975\n",
            "Epoch: 4983 / 5000\n",
            "w1: [25.76002255] w2: [-23.50136588] bias: [16.28394342] loss: 30.53315520437596\n",
            "Epoch: 4984 / 5000\n",
            "w1: [25.7588003] w2: [-23.49381155] bias: [16.29331108] loss: 30.535823161606256\n",
            "Epoch: 4985 / 5000\n",
            "w1: [25.76213841] w2: [-23.48669964] bias: [16.3079804] loss: 30.540692070313913\n",
            "Epoch: 4986 / 5000\n",
            "w1: [25.77517014] w2: [-23.4839238] bias: [16.32913331] loss: 30.54934292062581\n",
            "Epoch: 4987 / 5000\n",
            "w1: [25.77881134] w2: [-23.48459093] bias: [16.34373199] loss: 30.555037947680304\n",
            "Epoch: 4988 / 5000\n",
            "w1: [25.76784782] w2: [-23.50089132] bias: [16.31820372] loss: 30.543005629686967\n",
            "Epoch: 4989 / 5000\n",
            "w1: [25.77367506] w2: [-23.50008668] bias: [16.32256965] loss: 30.54522760679824\n",
            "Epoch: 4990 / 5000\n",
            "w1: [25.78169124] w2: [-23.49935914] bias: [16.33389498] loss: 30.55024571477862\n",
            "Epoch: 4991 / 5000\n",
            "w1: [25.771534] w2: [-23.5104645] bias: [16.32256823] loss: 30.54386513986948\n",
            "Epoch: 4992 / 5000\n",
            "w1: [25.76983114] w2: [-23.51134882] bias: [16.31866401] loss: 30.54237393575291\n",
            "Epoch: 4993 / 5000\n",
            "w1: [25.75494891] w2: [-23.52135022] bias: [16.29041678] loss: 30.5326059223463\n",
            "Epoch: 4994 / 5000\n",
            "w1: [25.75990993] w2: [-23.50456887] bias: [16.30711191] loss: 30.53853208422124\n",
            "Epoch: 4995 / 5000\n",
            "w1: [25.76407041] w2: [-23.5037671] bias: [16.30848633] loss: 30.539468161462253\n",
            "Epoch: 4996 / 5000\n",
            "w1: [25.75461928] w2: [-23.51368579] bias: [16.28571355] loss: 30.532128210253713\n",
            "Epoch: 4997 / 5000\n",
            "w1: [25.75825481] w2: [-23.50880855] bias: [16.29186207] loss: 30.534202237420864\n",
            "Epoch: 4998 / 5000\n",
            "w1: [25.76129981] w2: [-23.49365508] bias: [16.3042536] loss: 30.53891754669199\n",
            "Epoch: 4999 / 5000\n",
            "w1: [25.75073757] w2: [-23.49666737] bias: [16.28946012] loss: 30.533884016013495\n",
            "Epoch: 5000 / 5000\n",
            "w1: [25.74844852] w2: [-23.49301619] bias: [16.30277783] loss: 30.537141110761834\n",
            "##### 최종 w1, w2, bias #######\n",
            "[25.74844852] [-23.49301619] [16.30277783]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "pCFPSUwV_Z3r",
        "outputId": "e088e978-f3b7-4aff-b2d3-545c0de9405e"
      },
      "cell_type": "code",
      "source": [
        "predicted = scaled_features[:, 0]*w1 + scaled_features[:, 1]*w2 + bias\n",
        "bostonDF['PREDICTED_PRICE_BATCH_RANDOM'] = predicted\n",
        "bostonDF.head(10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7a95a778-dfe9-4cfe-9ae1-3a98f359d73d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "      <th>PREDICTED_PRICE</th>\n",
              "      <th>KERAS_PREDICTED_PRICE</th>\n",
              "      <th>PREDICTED_PRICE_BATCH_RANDOM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>28.935533</td>\n",
              "      <td>28.981525</td>\n",
              "      <td>29.065791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>25.483093</td>\n",
              "      <td>25.506231</td>\n",
              "      <td>25.609247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>32.545474</td>\n",
              "      <td>32.637917</td>\n",
              "      <td>32.691135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>32.334142</td>\n",
              "      <td>32.416267</td>\n",
              "      <td>32.475157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>31.516284</td>\n",
              "      <td>31.602312</td>\n",
              "      <td>31.660917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.430</td>\n",
              "      <td>58.7</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.12</td>\n",
              "      <td>5.21</td>\n",
              "      <td>28.7</td>\n",
              "      <td>28.074722</td>\n",
              "      <td>28.109661</td>\n",
              "      <td>28.201319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.08829</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.012</td>\n",
              "      <td>66.6</td>\n",
              "      <td>5.5605</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>395.60</td>\n",
              "      <td>12.43</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.342942</td>\n",
              "      <td>21.327406</td>\n",
              "      <td>21.458623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.14455</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.172</td>\n",
              "      <td>96.1</td>\n",
              "      <td>5.9505</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>19.15</td>\n",
              "      <td>27.1</td>\n",
              "      <td>17.772340</td>\n",
              "      <td>17.749207</td>\n",
              "      <td>17.891678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.21124</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>5.631</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0821</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.63</td>\n",
              "      <td>29.93</td>\n",
              "      <td>16.5</td>\n",
              "      <td>8.129206</td>\n",
              "      <td>8.036671</td>\n",
              "      <td>8.234336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.17004</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.004</td>\n",
              "      <td>85.9</td>\n",
              "      <td>6.5921</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.71</td>\n",
              "      <td>17.10</td>\n",
              "      <td>18.9</td>\n",
              "      <td>18.276548</td>\n",
              "      <td>18.247183</td>\n",
              "      <td>18.391771</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a95a778-dfe9-4cfe-9ae1-3a98f359d73d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a95a778-dfe9-4cfe-9ae1-3a98f359d73d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a95a778-dfe9-4cfe-9ae1-3a98f359d73d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      CRIM    ZN  ...  KERAS_PREDICTED_PRICE  PREDICTED_PRICE_BATCH_RANDOM\n",
              "0  0.00632  18.0  ...              28.981525                     29.065791\n",
              "1  0.02731   0.0  ...              25.506231                     25.609247\n",
              "2  0.02729   0.0  ...              32.637917                     32.691135\n",
              "3  0.03237   0.0  ...              32.416267                     32.475157\n",
              "4  0.06905   0.0  ...              31.602312                     31.660917\n",
              "5  0.02985   0.0  ...              28.109661                     28.201319\n",
              "6  0.08829  12.5  ...              21.327406                     21.458623\n",
              "7  0.14455  12.5  ...              17.749207                     17.891678\n",
              "8  0.21124  12.5  ...               8.036671                      8.234336\n",
              "9  0.17004  12.5  ...              18.247183                     18.391771\n",
              "\n",
              "[10 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "4wbm0Ef5_Z3r"
      },
      "cell_type": "markdown",
      "source": [
        "### iteration 시에 순차적으로 일정한 batch 크기만큼의 데이터를 전체 학습데이터에 걸쳐서 가져오는 Mini-Batch GD 수행"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDJiG-nj_Z3r",
        "outputId": "f9ed3de1-d421-48a3-ed2b-4ca170f21805"
      },
      "cell_type": "code",
      "source": [
        "for batch_step in range(0, 506, 30):\n",
        "    print(batch_step)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "30\n",
            "60\n",
            "90\n",
            "120\n",
            "150\n",
            "180\n",
            "210\n",
            "240\n",
            "270\n",
            "300\n",
            "330\n",
            "360\n",
            "390\n",
            "420\n",
            "450\n",
            "480\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uni6dg1_Z3r",
        "outputId": "908a3b32-69d6-4231-cb71-1be4028f1ef6"
      },
      "cell_type": "code",
      "source": [
        "#슬라이싱할때 데이터 범위를 넘으면 아래와 같이 데이터가 506개이므로 506번째 데이터까지만 값을 반환\n",
        "bostonDF['PRICE'].values[480:510]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23. , 23.7, 25. , 21.8, 20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1,\n",
              "       13.6, 20.1, 21.8, 24.5, 23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4,\n",
              "       20.6, 23.9, 22. , 11.9])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9etTp6dw_Z3r"
      },
      "cell_type": "code",
      "source": [
        "# batch_gradient_descent()는 인자로 batch_size(배치 크기)를 입력 받음. \n",
        "def batch_gradient_descent(features, target, iter_epochs=1000, batch_size=30, verbose=True):\n",
        "    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n",
        "    # bias도 1차원 array로 변환하되 초기 값은 1로 설정. \n",
        "    np.random.seed = 2021\n",
        "    w1 = np.zeros((1,))\n",
        "    w2 = np.zeros((1,))\n",
        "    bias = np.zeros((1, ))\n",
        "    print('최초 w1, w2, bias:', w1, w2, bias)\n",
        "    \n",
        "    # learning_rate와 RM, LSTAT 피처 지정. 호출 시 numpy array형태로 RM과 LSTAT으로 된 2차원 feature가 입력됨.\n",
        "    learning_rate = 0.01\n",
        "    rm = features[:, 0]\n",
        "    lstat = features[:, 1]\n",
        "    \n",
        "    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행. \n",
        "    for i in range(iter_epochs):\n",
        "        # batch_size 만큼 데이터를 가져와서 weight/bias update를 수행하는 로직을 전체 데이터 건수만큼 반복\n",
        "        for batch_step in range(0, target.shape[0], batch_size):\n",
        "            # batch_size만큼 순차적인 데이터를 가져옴. \n",
        "            rm_batch = rm[batch_step:batch_step + batch_size]\n",
        "            lstat_batch = lstat[batch_step:batch_step + batch_size]\n",
        "            target_batch = target[batch_step:batch_step + batch_size]\n",
        "        \n",
        "            bias_update, w1_update, w2_update = get_update_weights_value_batch(bias, w1, w2, rm_batch, lstat_batch, target_batch, learning_rate)\n",
        "\n",
        "            # Batch GD로 구한 weight/bias의 update 적용. \n",
        "            w1 = w1 - w1_update\n",
        "            w2 = w2 - w2_update\n",
        "            bias = bias - bias_update\n",
        "        \n",
        "            if verbose:\n",
        "                print('Epoch:', i+1,'/', iter_epochs, 'batch step:', batch_step)\n",
        "                # Loss는 전체 학습 데이터 기반으로 구해야 함.\n",
        "                predicted = w1 * rm + w2*lstat + bias\n",
        "                diff = target - predicted\n",
        "                mse_loss = np.mean(np.square(diff))\n",
        "                print('w1:', w1, 'w2:', w2, 'bias:', bias, 'loss:', mse_loss)\n",
        "        \n",
        "    return w1, w2, bias"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "W8noc5-f_Z3s"
      },
      "cell_type": "code",
      "source": [
        "w1, w2, bias = batch_gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=1000, batch_size=30, verbose=True)\n",
        "print('##### 최종 w1, w2, bias #######')\n",
        "print(w1, w2, bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "xsM8AAij_Z3s",
        "outputId": "835fc4cc-0ace-4267-cf33-2947a72f39d7"
      },
      "cell_type": "code",
      "source": [
        "predicted = scaled_features[:, 0]*w1 + scaled_features[:, 1]*w2 + bias\n",
        "bostonDF['PREDICTED_PRICE_BATCH'] = predicted\n",
        "bostonDF.head(10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a4927c21-b29e-4c37-b3a1-f1b6303142fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "      <th>PREDICTED_PRICE</th>\n",
              "      <th>KERAS_PREDICTED_PRICE</th>\n",
              "      <th>PREDICTED_PRICE_BATCH_RANDOM</th>\n",
              "      <th>PREDICTED_PRICE_BATCH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>28.935533</td>\n",
              "      <td>28.981525</td>\n",
              "      <td>29.065791</td>\n",
              "      <td>28.830077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>25.483093</td>\n",
              "      <td>25.506231</td>\n",
              "      <td>25.609247</td>\n",
              "      <td>25.370027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>32.545474</td>\n",
              "      <td>32.637917</td>\n",
              "      <td>32.691135</td>\n",
              "      <td>32.508278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>32.334142</td>\n",
              "      <td>32.416267</td>\n",
              "      <td>32.475157</td>\n",
              "      <td>32.272631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>31.516284</td>\n",
              "      <td>31.602312</td>\n",
              "      <td>31.660917</td>\n",
              "      <td>31.477882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.430</td>\n",
              "      <td>58.7</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.12</td>\n",
              "      <td>5.21</td>\n",
              "      <td>28.7</td>\n",
              "      <td>28.074722</td>\n",
              "      <td>28.109661</td>\n",
              "      <td>28.201319</td>\n",
              "      <td>27.953052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.08829</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.012</td>\n",
              "      <td>66.6</td>\n",
              "      <td>5.5605</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>395.60</td>\n",
              "      <td>12.43</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.342942</td>\n",
              "      <td>21.327406</td>\n",
              "      <td>21.458623</td>\n",
              "      <td>21.190621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.14455</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.172</td>\n",
              "      <td>96.1</td>\n",
              "      <td>5.9505</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>19.15</td>\n",
              "      <td>27.1</td>\n",
              "      <td>17.772340</td>\n",
              "      <td>17.749207</td>\n",
              "      <td>17.891678</td>\n",
              "      <td>17.655029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.21124</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>5.631</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0821</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.63</td>\n",
              "      <td>29.93</td>\n",
              "      <td>16.5</td>\n",
              "      <td>8.129206</td>\n",
              "      <td>8.036671</td>\n",
              "      <td>8.234336</td>\n",
              "      <td>7.975749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.17004</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.004</td>\n",
              "      <td>85.9</td>\n",
              "      <td>6.5921</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.71</td>\n",
              "      <td>17.10</td>\n",
              "      <td>18.9</td>\n",
              "      <td>18.276548</td>\n",
              "      <td>18.247183</td>\n",
              "      <td>18.391771</td>\n",
              "      <td>18.134764</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4927c21-b29e-4c37-b3a1-f1b6303142fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4927c21-b29e-4c37-b3a1-f1b6303142fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4927c21-b29e-4c37-b3a1-f1b6303142fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      CRIM    ZN  ...  PREDICTED_PRICE_BATCH_RANDOM  PREDICTED_PRICE_BATCH\n",
              "0  0.00632  18.0  ...                     29.065791              28.830077\n",
              "1  0.02731   0.0  ...                     25.609247              25.370027\n",
              "2  0.02729   0.0  ...                     32.691135              32.508278\n",
              "3  0.03237   0.0  ...                     32.475157              32.272631\n",
              "4  0.06905   0.0  ...                     31.660917              31.477882\n",
              "5  0.02985   0.0  ...                     28.201319              27.953052\n",
              "6  0.08829  12.5  ...                     21.458623              21.190621\n",
              "7  0.14455  12.5  ...                     17.891678              17.655029\n",
              "8  0.21124  12.5  ...                      8.234336               7.975749\n",
              "9  0.17004  12.5  ...                     18.391771              18.134764\n",
              "\n",
              "[10 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "7vpTUP_F_Z3t"
      },
      "cell_type": "markdown",
      "source": [
        "### Mini BATCH GD를 Keras로 수행\n",
        "* Keras는 기본적으로 Mini Batch GD를 수행"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fSYGuHyQ_Z3t"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    # 단 하나의 units 설정. input_shape는 2차원, 회귀이므로 activation은 설정하지 않음. \n",
        "    # weight와 bias 초기화는 kernel_inbitializer와 bias_initializer를 이용. \n",
        "    Dense(1, input_shape=(2, ), activation=None, kernel_initializer='zeros', bias_initializer='ones')\n",
        "])\n",
        "# Adam optimizer를 이용하고 Loss 함수는 Mean Squared Error, 성능 측정 역시 MSE를 이용하여 학습 수행. \n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mse'])\n",
        "\n",
        "# Keras는 반드시 Batch GD를 적용함. batch_size가 None이면 32를 할당. \n",
        "model.fit(scaled_features, bostonDF['PRICE'].values, batch_size=30, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "QR5ffub4_Z3t",
        "outputId": "11c944e6-53a7-40dd-f5e4-678e27d9db5a"
      },
      "cell_type": "code",
      "source": [
        "predicted = model.predict(scaled_features)\n",
        "bostonDF['KERAS_PREDICTED_PRICE_BATCH'] = predicted\n",
        "bostonDF.head(10)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1aabacfc-dd61-4550-bf55-61ad6e1deed4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "      <th>PREDICTED_PRICE</th>\n",
              "      <th>KERAS_PREDICTED_PRICE</th>\n",
              "      <th>PREDICTED_PRICE_BATCH_RANDOM</th>\n",
              "      <th>PREDICTED_PRICE_BATCH</th>\n",
              "      <th>KERAS_PREDICTED_PRICE_BATCH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>28.935533</td>\n",
              "      <td>28.981525</td>\n",
              "      <td>29.065791</td>\n",
              "      <td>28.830077</td>\n",
              "      <td>28.978268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>25.483093</td>\n",
              "      <td>25.506231</td>\n",
              "      <td>25.609247</td>\n",
              "      <td>25.370027</td>\n",
              "      <td>25.503582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>32.545474</td>\n",
              "      <td>32.637917</td>\n",
              "      <td>32.691135</td>\n",
              "      <td>32.508278</td>\n",
              "      <td>32.642227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>32.334142</td>\n",
              "      <td>32.416267</td>\n",
              "      <td>32.475157</td>\n",
              "      <td>32.272631</td>\n",
              "      <td>32.417366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>31.516284</td>\n",
              "      <td>31.602312</td>\n",
              "      <td>31.660917</td>\n",
              "      <td>31.477882</td>\n",
              "      <td>31.606949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.02985</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.430</td>\n",
              "      <td>58.7</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.12</td>\n",
              "      <td>5.21</td>\n",
              "      <td>28.7</td>\n",
              "      <td>28.074722</td>\n",
              "      <td>28.109661</td>\n",
              "      <td>28.201319</td>\n",
              "      <td>27.953052</td>\n",
              "      <td>28.104607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.08829</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.012</td>\n",
              "      <td>66.6</td>\n",
              "      <td>5.5605</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>395.60</td>\n",
              "      <td>12.43</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.342942</td>\n",
              "      <td>21.327406</td>\n",
              "      <td>21.458623</td>\n",
              "      <td>21.190621</td>\n",
              "      <td>21.321388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.14455</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.172</td>\n",
              "      <td>96.1</td>\n",
              "      <td>5.9505</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>19.15</td>\n",
              "      <td>27.1</td>\n",
              "      <td>17.772340</td>\n",
              "      <td>17.749207</td>\n",
              "      <td>17.891678</td>\n",
              "      <td>17.655029</td>\n",
              "      <td>17.749651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.21124</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>5.631</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.0821</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.63</td>\n",
              "      <td>29.93</td>\n",
              "      <td>16.5</td>\n",
              "      <td>8.129206</td>\n",
              "      <td>8.036671</td>\n",
              "      <td>8.234336</td>\n",
              "      <td>7.975749</td>\n",
              "      <td>8.036789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.17004</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.004</td>\n",
              "      <td>85.9</td>\n",
              "      <td>6.5921</td>\n",
              "      <td>5.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>386.71</td>\n",
              "      <td>17.10</td>\n",
              "      <td>18.9</td>\n",
              "      <td>18.276548</td>\n",
              "      <td>18.247183</td>\n",
              "      <td>18.391771</td>\n",
              "      <td>18.134764</td>\n",
              "      <td>18.244057</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1aabacfc-dd61-4550-bf55-61ad6e1deed4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1aabacfc-dd61-4550-bf55-61ad6e1deed4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1aabacfc-dd61-4550-bf55-61ad6e1deed4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      CRIM    ZN  ...  PREDICTED_PRICE_BATCH  KERAS_PREDICTED_PRICE_BATCH\n",
              "0  0.00632  18.0  ...              28.830077                    28.978268\n",
              "1  0.02731   0.0  ...              25.370027                    25.503582\n",
              "2  0.02729   0.0  ...              32.508278                    32.642227\n",
              "3  0.03237   0.0  ...              32.272631                    32.417366\n",
              "4  0.06905   0.0  ...              31.477882                    31.606949\n",
              "5  0.02985   0.0  ...              27.953052                    28.104607\n",
              "6  0.08829  12.5  ...              21.190621                    21.321388\n",
              "7  0.14455  12.5  ...              17.655029                    17.749651\n",
              "8  0.21124  12.5  ...               7.975749                     8.036789\n",
              "9  0.17004  12.5  ...              18.134764                    18.244057\n",
              "\n",
              "[10 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1PCAeLAd_Z3t"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Gradient_Descent_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}