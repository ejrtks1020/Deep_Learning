{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejrtks1020/Deep_Learning/blob/main/CIFAR10_Pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "lRDnHEMkBkT-"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "US2YcsdqBkUC"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras의 Pretrained 모델 로딩 및 모델 구조 확인. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Wxd9sKQWBkUD"
      },
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.applications.vgg16 import VGG16\n",
        "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, ResNet50V2, Xception"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVzNY2_FBkUE",
        "outputId": "88c1aad5-a406-4062-c130-82396e985058"
      },
      "cell_type": "code",
      "source": [
        "model = VGG16()\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n",
            "553476096/553467096 [==============================] - 4s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYFhyJY6BkUF",
        "outputId": "9ea14afa-ae80-42fc-a702-351ae4a64337"
      },
      "cell_type": "code",
      "source": [
        "model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DgXuEXnHBkUF"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras의 Model 역시 Functional임. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z61V4ZXPBkUG",
        "outputId": "51cf3ee2-c452-4c23-9f2e-ba7b9a1c1668"
      },
      "cell_type": "code",
      "source": [
        "print('model:', model)\n",
        "print('model output:', model.output)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model: <keras.engine.functional.Functional object at 0x7f71dc102bd0>\n",
            "model output: KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 512), dtype=tf.float32, name=None), name='block5_pool/MaxPool:0', description=\"created by layer 'block5_pool'\")\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6jfW95cwBkUH"
      },
      "cell_type": "markdown",
      "source": [
        "### Pretrained 모델을 기반으로 CIFAR 10 분류 모델 재 생성. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Ly5s6BWOBkUI"
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExfZmHNvBkUJ",
        "outputId": "898b775a-5648-4f7b-ecdd-4cb490a5a986"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "# include_top=False로 기존 imagenet용 classifier 층들을 다 제거. weight는 전이학습을 위해 imagenet 학습된 weight를 초기 weight로 사용. \n",
        "#input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "#base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "\n",
        "base_model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "bm_output = base_model.output\n",
        "\n",
        "# base model의 output을 입력으로 CIFAR10용 Classification layer를 재 구성. \n",
        "x = GlobalAveragePooling2D()(bm_output)\n",
        "# x = Dropout(rate=0.5)(x)\n",
        "x = Dense(50, activation='relu', name='fc1')(x)\n",
        "# x = Dropout(rate=0.2)(x)\n",
        "output = Dense(10, activation='softmax', name='output')(x)\n",
        "\n",
        "#model = Model(inputs=input_tensor, outputs=output)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 50)                25650     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,740,848\n",
            "Trainable params: 14,740,848\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "OCs8Z-9_BkUJ"
      },
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리 및 ImageDataGenerator로 Augmentation 설정하고 학습용, 검증용 Generator 생성"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qp-qYr1BkUK",
        "outputId": "599310f9-d892-47c7-afb1-3083c796de1f"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random as python_random\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n",
        "def set_random_seed(seed_value):\n",
        "    np.random.seed(seed_value)\n",
        "    python_random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)\n",
        "\n",
        "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
        "def get_preprocessed_data(images, labels, scaling=True):\n",
        "    \n",
        "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
        "    if scaling:\n",
        "        images = np.array(images/255.0, dtype=np.float32)\n",
        "    else:\n",
        "        images = np.array(images, dtype=np.float32)\n",
        "        \n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
        "def get_preprocessed_ohe(images, labels):\n",
        "    images, labels = get_preprocessed_data(images, labels, scaling=False)\n",
        "    # OHE 적용 \n",
        "    oh_labels = to_categorical(labels)\n",
        "    return images, oh_labels\n",
        "\n",
        "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
        "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
        "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
        "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
        "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
        "    \n",
        "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
        "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
        "    \n",
        "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n",
        "\n",
        "\n",
        "# random seed는 2021로 고정.\n",
        "set_random_seed(2021)\n",
        "# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
        "\n",
        "(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
        "    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
        "\n",
        "print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "(42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "kwKlisVEBkUL"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    # rotation_range=20,\n",
        "    #zoom_range=(0.7, 0.9),\n",
        "    horizontal_flip=True,\n",
        "    #vertical_flip=True,\n",
        "    rescale=1/255.0\n",
        ")\n",
        "valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
        "flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pIKF3mK_BkUL"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras CNN 모델 생성 함수. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mQrYX9XCBkUM"
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "k9EANzEjBkUM"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "def create_model(verbose=False):\n",
        "    \n",
        "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    bm_output = base_model.output\n",
        "\n",
        "    x = GlobalAveragePooling2D()(bm_output)\n",
        "    #x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(50, activation='relu', name='fc1')(x)\n",
        "    #x = Dropout(rate=0.2)(x)\n",
        "    output = Dense(10, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    if verbose:\n",
        "        model.summary()\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlrieUE1BkUM",
        "outputId": "47c42a33-034d-4581-f989-fd1867b2397b"
      },
      "cell_type": "code",
      "source": [
        "vgg_model = create_model(verbose=True)\n",
        "vgg_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
        "# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 50)                25650     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,740,848\n",
            "Trainable params: 14,740,848\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJZyeaMvBkUM",
        "outputId": "3d274918-8c65-4d2c-d6d1-973ed1b3fa91"
      },
      "cell_type": "code",
      "source": [
        "# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\n",
        "tr_data_len = tr_images.shape[0]\n",
        "val_data_len = val_images.shape[0]\n",
        "history = vgg_model.fit(flow_tr_gen, epochs=40, \n",
        "                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n",
        "                    validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n",
        "                    callbacks=[rlr_cb, ely_cb])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "665/665 [==============================] - 27s 27ms/step - loss: 1.9656 - accuracy: 0.2147 - val_loss: 1.7965 - val_accuracy: 0.2768 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 1.5571 - accuracy: 0.3888 - val_loss: 1.3385 - val_accuracy: 0.4848 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 1.1424 - accuracy: 0.5877 - val_loss: 1.0576 - val_accuracy: 0.6396 - lr: 0.0010\n",
            "Epoch 4/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.9139 - accuracy: 0.6809 - val_loss: 0.8379 - val_accuracy: 0.7121 - lr: 0.0010\n",
            "Epoch 5/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.7948 - accuracy: 0.7276 - val_loss: 0.7659 - val_accuracy: 0.7395 - lr: 0.0010\n",
            "Epoch 6/40\n",
            "665/665 [==============================] - 18s 26ms/step - loss: 0.6880 - accuracy: 0.7680 - val_loss: 0.8062 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 7/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.6267 - accuracy: 0.7924 - val_loss: 0.6331 - val_accuracy: 0.7960 - lr: 0.0010\n",
            "Epoch 8/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.5637 - accuracy: 0.8147 - val_loss: 0.6451 - val_accuracy: 0.7935 - lr: 0.0010\n",
            "Epoch 9/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.5392 - accuracy: 0.8233 - val_loss: 0.6646 - val_accuracy: 0.7845 - lr: 0.0010\n",
            "Epoch 10/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.4840 - accuracy: 0.8402 - val_loss: 0.6052 - val_accuracy: 0.7989 - lr: 0.0010\n",
            "Epoch 11/40\n",
            "665/665 [==============================] - 18s 26ms/step - loss: 0.4465 - accuracy: 0.8533 - val_loss: 0.5888 - val_accuracy: 0.8144 - lr: 0.0010\n",
            "Epoch 12/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.4205 - accuracy: 0.8624 - val_loss: 0.5721 - val_accuracy: 0.8243 - lr: 0.0010\n",
            "Epoch 13/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.4048 - accuracy: 0.8681 - val_loss: 0.5785 - val_accuracy: 0.8211 - lr: 0.0010\n",
            "Epoch 14/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.3743 - accuracy: 0.8777 - val_loss: 0.6070 - val_accuracy: 0.8148 - lr: 0.0010\n",
            "Epoch 15/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.3702 - accuracy: 0.8790 - val_loss: 0.5777 - val_accuracy: 0.8184 - lr: 0.0010\n",
            "Epoch 16/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.3368 - accuracy: 0.8920 - val_loss: 0.6568 - val_accuracy: 0.8085 - lr: 0.0010\n",
            "Epoch 17/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.8938\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.3237 - accuracy: 0.8938 - val_loss: 0.5862 - val_accuracy: 0.8285 - lr: 0.0010\n",
            "Epoch 18/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.1860 - accuracy: 0.9405 - val_loss: 0.5606 - val_accuracy: 0.8525 - lr: 2.0000e-04\n",
            "Epoch 19/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.1420 - accuracy: 0.9551 - val_loss: 0.5752 - val_accuracy: 0.8507 - lr: 2.0000e-04\n",
            "Epoch 20/40\n",
            "665/665 [==============================] - 18s 26ms/step - loss: 0.1139 - accuracy: 0.9641 - val_loss: 0.6371 - val_accuracy: 0.8509 - lr: 2.0000e-04\n",
            "Epoch 21/40\n",
            "665/665 [==============================] - 18s 26ms/step - loss: 0.0942 - accuracy: 0.9702 - val_loss: 0.6850 - val_accuracy: 0.8511 - lr: 2.0000e-04\n",
            "Epoch 22/40\n",
            "665/665 [==============================] - 18s 26ms/step - loss: 0.0791 - accuracy: 0.9764 - val_loss: 0.7095 - val_accuracy: 0.8519 - lr: 2.0000e-04\n",
            "Epoch 23/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9803\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "665/665 [==============================] - 18s 26ms/step - loss: 0.0673 - accuracy: 0.9803 - val_loss: 0.7627 - val_accuracy: 0.8499 - lr: 2.0000e-04\n",
            "Epoch 24/40\n",
            "665/665 [==============================] - 17s 26ms/step - loss: 0.0487 - accuracy: 0.9868 - val_loss: 0.7784 - val_accuracy: 0.8524 - lr: 4.0000e-05\n",
            "Epoch 25/40\n",
            "665/665 [==============================] - 18s 26ms/step - loss: 0.0351 - accuracy: 0.9904 - val_loss: 0.8537 - val_accuracy: 0.8525 - lr: 4.0000e-05\n",
            "Epoch 26/40\n",
            "665/665 [==============================] - 17s 26ms/step - loss: 0.0295 - accuracy: 0.9922 - val_loss: 0.8879 - val_accuracy: 0.8524 - lr: 4.0000e-05\n",
            "Epoch 27/40\n",
            "665/665 [==============================] - 18s 26ms/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 0.9398 - val_accuracy: 0.8535 - lr: 4.0000e-05\n",
            "Epoch 28/40\n",
            "663/665 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9937\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "665/665 [==============================] - 17s 26ms/step - loss: 0.0233 - accuracy: 0.9937 - val_loss: 0.9816 - val_accuracy: 0.8491 - lr: 4.0000e-05\n",
            "Epoch 00028: early stopping\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I04TtzpOBkUN",
        "outputId": "863eed2b-a71c-4cdc-b029-c66093b58277"
      },
      "cell_type": "code",
      "source": [
        "test_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "flow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
        "vgg_model.evaluate(flow_test_gen)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 2s 10ms/step - loss: 1.0372 - accuracy: 0.8434\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.03719162940979, 0.8434000015258789]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nLQTgMKgBkUN",
        "outputId": "b97f8edc-b466-466b-f4ba-cc98094e14d1"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_history(history):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.yticks(np.arange(0, 1, 0.05))\n",
        "    plt.xticks(np.arange(0, 30, 2))\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='valid')\n",
        "    plt.legend()\n",
        "    \n",
        "show_history(history)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZgltMbHPBkUO"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qMqzaVNXBkUO"
      },
      "cell_type": "markdown",
      "source": [
        "### 지금까지의 로직들을 함수화 "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GazPjs_DBkUO"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "import random as python_random\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import Xception\n",
        "\n",
        "# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n",
        "def set_random_seed(seed_value):\n",
        "    np.random.seed(seed_value)\n",
        "    python_random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)\n",
        "\n",
        "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
        "def get_preprocessed_data(images, labels, scaling=True):\n",
        "    \n",
        "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
        "    if scaling:\n",
        "        images = np.array(images/255.0, dtype=np.float32)\n",
        "    else:\n",
        "        images = np.array(images, dtype=np.float32)\n",
        "        \n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
        "def get_preprocessed_ohe(images, labels):\n",
        "    images, labels = get_preprocessed_data(images, labels, scaling=False)\n",
        "    # OHE 적용 \n",
        "    oh_labels = to_categorical(labels)\n",
        "    return images, oh_labels\n",
        "\n",
        "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
        "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
        "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
        "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
        "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
        "    \n",
        "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
        "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
        "    \n",
        "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n",
        "\n",
        "# 입력 image의 크기를 resize 값 만큼 증가. CIFAR10의 이미지가 32x32로 작아서 마지막 feature map의 크기가 1로 되어 모델 성능이 좋지 않음. \n",
        "# 마지막 feature map의 크기를 2로 만들기 위해 resize를 64로 하여 입력 이미지 크기를 변경. 단 메모리를 크게 소비하므로 64이상은 kernel이 다운됨. \n",
        "def get_resized_images(images, resize=64):\n",
        "    image_cnt = images.shape[0]\n",
        "    resized_images = np.zeros((images.shape[0], resize, resize, 3))\n",
        "    for i in range(image_cnt):\n",
        "        resized_image = cv2.resize(images[i], (resize, resize))\n",
        "        resized_images[i] = resized_image\n",
        "    \n",
        "    return resized_images\n",
        "\n",
        "def create_model(model_name='vgg16', verbose=False):\n",
        "    \n",
        "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    if model_name == 'vgg16':\n",
        "        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == 'resnet50':\n",
        "        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == 'xception':\n",
        "        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    \n",
        "    bm_output = base_model.output\n",
        "\n",
        "    x = GlobalAveragePooling2D()(bm_output)\n",
        "    if model_name != 'vgg16':\n",
        "        x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(50, activation='relu', name='fc1')(x)\n",
        "    output = Dense(10, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    model.summary()\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "K4-aZ2B4BkUP"
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def do_cifar10_train_evaluation(image_size=IMAGE_SIZE, model_name='vgg16'):\n",
        "    set_random_seed(2021)\n",
        "    # CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
        "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "    (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
        "        get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
        "    print('데이터 세트 shape:', tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)\n",
        "    \n",
        "    # 만약 image_size가 32보다 크면 이미지 크기 재조정. \n",
        "    if image_size > 32:\n",
        "        tr_images = get_resized_images(tr_images)\n",
        "        val_images = get_resized_images(val_images)\n",
        "        test_images = get_resized_images(test_images)\n",
        "    \n",
        "    # 학습/검증/테스트용 ImageDataGenerator와 flow로 pipeline 생성. \n",
        "    train_generator = ImageDataGenerator(\n",
        "        horizontal_flip=True,\n",
        "        rescale=1/255.0\n",
        "    )\n",
        "    valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "    test_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "    flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    flow_test_gen = train_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    \n",
        "    # model_name 에 따른 모델 생성하고 모델 학습 및 검증 수행. \n",
        "    model = create_model(model_name=model_name, verbose=True)\n",
        "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
        "    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "    \n",
        "    tr_data_len = tr_images.shape[0]\n",
        "    val_data_len = val_images.shape[0]\n",
        "    history = model.fit(flow_tr_gen, epochs=40, \n",
        "                        steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n",
        "                        validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n",
        "                        callbacks=[rlr_cb, ely_cb])\n",
        "    # 테스트 데이터 세트로 모델 성능 검증 \n",
        "    evaluation_result = model.evaluate(flow_test_gen)\n",
        "    print('테스트 데이터 세트 evaluation 결과:', evaluation_result)\n",
        "    return history, evaluation_result\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyA8qtn_BkUP",
        "outputId": "6d61aa49-6705-4960-a758-41779a4b2965"
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7361"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O1ua_9VBkUP",
        "outputId": "c40314cf-045f-46de-c699-d42cc2753f99"
      },
      "cell_type": "code",
      "source": [
        "# 만약 image_size를 64로 하려면 반드시 RAM이 여유분이 충분히 있는지 확인\n",
        "history, evaluation_result = do_cifar10_train_evaluation(image_size=64, model_name='xception')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 세트 shape: (42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "83697664/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 15, 15, 32)   864         ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " block1_conv1_bn (BatchNormaliz  (None, 15, 15, 32)  128         ['block1_conv1[0][0]']           \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block1_conv1_act (Activation)  (None, 15, 15, 32)   0           ['block1_conv1_bn[0][0]']        \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 13, 13, 64)   18432       ['block1_conv1_act[0][0]']       \n",
            "                                                                                                  \n",
            " block1_conv2_bn (BatchNormaliz  (None, 13, 13, 64)  256         ['block1_conv2[0][0]']           \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block1_conv2_act (Activation)  (None, 13, 13, 64)   0           ['block1_conv2_bn[0][0]']        \n",
            "                                                                                                  \n",
            " block2_sepconv1 (SeparableConv  (None, 13, 13, 128)  8768       ['block1_conv2_act[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2_sepconv1_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2_sepconv2_act (Activatio  (None, 13, 13, 128)  0          ['block2_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block2_sepconv2 (SeparableConv  (None, 13, 13, 128)  17536      ['block2_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2_sepconv2_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 7, 7, 128)    8192        ['block1_conv2_act[0][0]']       \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 7, 7, 128)    0           ['block2_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 7, 7, 128)   512         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 7, 7, 128)    0           ['block2_pool[0][0]',            \n",
            "                                                                  'batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " block3_sepconv1_act (Activatio  (None, 7, 7, 128)   0           ['add[0][0]']                    \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block3_sepconv1 (SeparableConv  (None, 7, 7, 256)   33920       ['block3_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_sepconv1_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3_sepconv2_act (Activatio  (None, 7, 7, 256)   0           ['block3_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block3_sepconv2 (SeparableConv  (None, 7, 7, 256)   67840       ['block3_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_sepconv2_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 4, 4, 256)    32768       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['block3_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 4, 4, 256)    0           ['block3_pool[0][0]',            \n",
            "                                                                  'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " block4_sepconv1_act (Activatio  (None, 4, 4, 256)   0           ['add_1[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block4_sepconv1 (SeparableConv  (None, 4, 4, 728)   188672      ['block4_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4_sepconv1_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4_sepconv2_act (Activatio  (None, 4, 4, 728)   0           ['block4_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block4_sepconv2 (SeparableConv  (None, 4, 4, 728)   536536      ['block4_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4_sepconv2_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 2, 2, 728)    186368      ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 2, 2, 728)    0           ['block4_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 2, 2, 728)   2912        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 2, 2, 728)    0           ['block4_pool[0][0]',            \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " block5_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_2[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 2, 2, 728)    0           ['block5_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " block6_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_3[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 2, 2, 728)    0           ['block6_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " block7_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_4[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block7_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block7_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 2, 2, 728)    0           ['block7_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " block8_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_5[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block8_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block8_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 2, 2, 728)    0           ['block8_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " block9_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_6[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block9_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block9_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 2, 2, 728)    0           ['block9_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " block10_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_7[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block10_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block10_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 2, 2, 728)    0           ['block10_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " block11_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_8[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block11_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block11_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 2, 2, 728)    0           ['block11_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " block12_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_9[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block12_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block12_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 2, 2, 728)    0           ['block12_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " block13_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_10[0][0]']                 \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block13_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block13_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block13_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block13_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block13_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block13_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block13_sepconv2 (SeparableCon  (None, 2, 2, 1024)  752024      ['block13_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block13_sepconv2_bn (BatchNorm  (None, 2, 2, 1024)  4096        ['block13_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 1, 1, 1024)   745472      ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " block13_pool (MaxPooling2D)    (None, 1, 1, 1024)   0           ['block13_sepconv2_bn[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 1, 1, 1024)  4096        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 1, 1, 1024)   0           ['block13_pool[0][0]',           \n",
            "                                                                  'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " block14_sepconv1 (SeparableCon  (None, 1, 1, 1536)  1582080     ['add_11[0][0]']                 \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block14_sepconv1_bn (BatchNorm  (None, 1, 1, 1536)  6144        ['block14_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block14_sepconv1_act (Activati  (None, 1, 1, 1536)  0           ['block14_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block14_sepconv2 (SeparableCon  (None, 1, 1, 2048)  3159552     ['block14_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block14_sepconv2_bn (BatchNorm  (None, 1, 1, 2048)  8192        ['block14_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block14_sepconv2_act (Activati  (None, 1, 1, 2048)  0           ['block14_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['block14_sepconv2_act[0][0]']   \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['global_average_pooling2d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " fc1 (Dense)                    (None, 50)           102450      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 10)           510         ['fc1[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,964,440\n",
            "Trainable params: 20,909,912\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "665/665 [==============================] - 58s 80ms/step - loss: 0.7516 - accuracy: 0.7539 - val_loss: 0.6585 - val_accuracy: 0.8088 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "665/665 [==============================] - 53s 79ms/step - loss: 0.4016 - accuracy: 0.8702 - val_loss: 0.4684 - val_accuracy: 0.8600 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "665/665 [==============================] - 53s 79ms/step - loss: 0.3158 - accuracy: 0.8962 - val_loss: 0.5715 - val_accuracy: 0.8345 - lr: 0.0010\n",
            "Epoch 4/40\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.2524 - accuracy: 0.9171 - val_loss: 0.5934 - val_accuracy: 0.8297 - lr: 0.0010\n",
            "Epoch 5/40\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.2178 - accuracy: 0.9283 - val_loss: 0.3490 - val_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 6/40\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.1765 - accuracy: 0.9415 - val_loss: 0.3236 - val_accuracy: 0.8972 - lr: 0.0010\n",
            "Epoch 7/40\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.1534 - accuracy: 0.9510 - val_loss: 0.3196 - val_accuracy: 0.9023 - lr: 0.0010\n",
            "Epoch 8/40\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.1320 - accuracy: 0.9566 - val_loss: 0.6722 - val_accuracy: 0.8420 - lr: 0.0010\n",
            "Epoch 9/40\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.1449 - accuracy: 0.9543 - val_loss: 0.3392 - val_accuracy: 0.8993 - lr: 0.0010\n",
            "Epoch 10/40\n",
            "665/665 [==============================] - 53s 79ms/step - loss: 0.1099 - accuracy: 0.9640 - val_loss: 0.6248 - val_accuracy: 0.8445 - lr: 0.0010\n",
            "Epoch 11/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.1088 - accuracy: 0.9654 - val_loss: 0.4096 - val_accuracy: 0.8879 - lr: 0.0010\n",
            "Epoch 12/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.1253 - accuracy: 0.9603 - val_loss: 0.3168 - val_accuracy: 0.9124 - lr: 0.0010\n",
            "Epoch 13/40\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.0961 - accuracy: 0.9689 - val_loss: 0.3011 - val_accuracy: 0.9173 - lr: 0.0010\n",
            "Epoch 14/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0682 - accuracy: 0.9786 - val_loss: 0.3386 - val_accuracy: 0.9080 - lr: 0.0010\n",
            "Epoch 15/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0796 - accuracy: 0.9744 - val_loss: 0.3177 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 16/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0642 - accuracy: 0.9793 - val_loss: 0.6464 - val_accuracy: 0.8372 - lr: 0.0010\n",
            "Epoch 17/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0682 - accuracy: 0.9781 - val_loss: 0.3012 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 18/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9793\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.3907 - val_accuracy: 0.9045 - lr: 0.0010\n",
            "Epoch 19/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.2607 - val_accuracy: 0.9356 - lr: 2.0000e-04\n",
            "Epoch 20/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.2705 - val_accuracy: 0.9367 - lr: 2.0000e-04\n",
            "Epoch 21/40\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.2950 - val_accuracy: 0.9403 - lr: 2.0000e-04\n",
            "Epoch 22/40\n",
            "665/665 [==============================] - 52s 79ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.3176 - val_accuracy: 0.9381 - lr: 2.0000e-04\n",
            "Epoch 23/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.3162 - val_accuracy: 0.9375 - lr: 2.0000e-04\n",
            "Epoch 24/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9983\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.3245 - val_accuracy: 0.9365 - lr: 2.0000e-04\n",
            "Epoch 25/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.3106 - val_accuracy: 0.9392 - lr: 4.0000e-05\n",
            "Epoch 26/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.3157 - val_accuracy: 0.9403 - lr: 4.0000e-05\n",
            "Epoch 27/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.3171 - val_accuracy: 0.9411 - lr: 4.0000e-05\n",
            "Epoch 28/40\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.3266 - val_accuracy: 0.9389 - lr: 4.0000e-05\n",
            "Epoch 29/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "665/665 [==============================] - 52s 78ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.3304 - val_accuracy: 0.9403 - lr: 4.0000e-05\n",
            "Epoch 00029: early stopping\n",
            "157/157 [==============================] - 4s 22ms/step - loss: 0.3657 - accuracy: 0.9343\n",
            "테스트 데이터 세트 evaluation 결과: [0.36568307876586914, 0.9343000054359436]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4IEAqNDBkUQ",
        "outputId": "a457007b-326d-4da5-f3b0-5390e5849967"
      },
      "cell_type": "code",
      "source": [
        "print('테스트 데이터세트 검증 결과:', evaluation_result)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터세트 검증 결과: [0.36568307876586914, 0.9343000054359436]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "16cGiqVZBkUQ",
        "outputId": "f03683ab-7e6e-47d3-c89f-a0f5e5c2f79b"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_history(history):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.yticks(np.arange(0, 1, 0.05))\n",
        "    plt.xticks(np.arange(0, 30, 2))\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='valid')\n",
        "    plt.legend()\n",
        "    \n",
        "show_history(history)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3ftLv1daBkUQ"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "CIFAR10_Pretrained.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}